{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Transfer Learning and Optimized CNN Based Intrusion Detection System for Internet of Vehicles \n",
    "This is the code for the paper entitled \"**A Transfer Learning and Optimized CNN Based Intrusion Detection System for Internet of Vehicles**\" accepted in IEEE International Conference on Communications (IEEE ICC).  \n",
    "Authors: Li Yang (lyang339@uwo.ca) and Abdallah Shami (Abdallah.Shami@uwo.ca)  \n",
    "Organization: The Optimized Computing and Communications (OC2) Lab, ECE Department, Western University\n",
    "\n",
    "**Notebook 2: CNN Model Development**  \n",
    "Aims:  \n",
    "&nbsp; 1): Generate training and test images  \n",
    "&nbsp; 2): Construct CNN models (a CNN model by own, Xception, VGG16, VGG19, Resnet, Inception, InceptionResnet)  \n",
    "&nbsp; 3): Tune the hyperparameters of CNN models (hyperparameter optimization)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from tensorflow.keras.preprocessing.image import  ImageDataGenerator\n",
    "from tensorflow.keras.layers import Dense,Flatten,GlobalAveragePooling2D,Input,Conv2D,MaxPooling2D,Dropout\n",
    "from tensorflow.keras.models import Model,load_model,Sequential\n",
    "from tensorflow.keras.applications.xception import  Xception\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.applications.vgg19 import VGG19\n",
    "from tensorflow.keras.applications.resnet50 import  ResNet50\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "from tensorflow.keras.applications.inception_resnet_v2 import InceptionResNetV2\n",
    "from tensorflow.keras.applications.mobilenet import MobileNet\n",
    "import tensorflow.keras.callbacks as kcallbacks\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.preprocessing.image import load_img,img_to_array\n",
    "import math\n",
    "import random\n",
    "from tensorflow.keras.utils import plot_model\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.metrics as metrics\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.metrics import accuracy_score,precision_score,recall_score,f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Training and Test Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2076 images belonging to 5 classes.\n",
      "Found 518 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "#generate training and test images\n",
    "TARGET_SIZE=(224,224)\n",
    "INPUT_SIZE=(224,224,3)\n",
    "BATCHSIZE=128\t#could try 128 or 32\n",
    "\n",
    "#Normalization\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        './train_224/',\n",
    "        target_size=TARGET_SIZE,\n",
    "        batch_size=BATCHSIZE,\n",
    "        class_mode='categorical')\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        './test_224/',\n",
    "        target_size=TARGET_SIZE,\n",
    "        batch_size=BATCHSIZE,\n",
    "        class_mode='categorical')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the image plotting functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "output_df = pd.DataFrame(columns=['Loss','Accuracy',  'Val-Loss', 'Val-Accuracy', 'Time'])\n",
    "output_index = list()\n",
    "timelist=list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot the figures\n",
    "class LossHistory(keras.callbacks.Callback):\n",
    "    def __init__(self, model_name):\n",
    "        self.model_name=model_name\n",
    "    def on_train_begin(self, logs={}):\n",
    "        \n",
    "        self.losses = {'batch':[], 'epoch':[]}\n",
    "        self.accuracy = {'batch':[], 'epoch':[]}\n",
    "        self.val_loss = {'batch':[], 'epoch':[]}\n",
    "        self.val_acc = {'batch':[], 'epoch':[]}\n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        self.losses['batch'].append(logs.get('loss'))\n",
    "        self.accuracy['batch'].append(logs.get('accuracy'))\n",
    "        self.val_loss['batch'].append(logs.get('val_loss'))\n",
    "        self.val_acc['batch'].append(logs.get('val_accuracy'))\n",
    "    def on_epoch_end(self, batch, logs={}):\n",
    "        self.losses['epoch'].append(logs.get('loss'))\n",
    "        self.accuracy['epoch'].append(logs.get('accuracy'))\n",
    "        self.val_loss['epoch'].append(logs.get('val_loss'))\n",
    "        self.val_acc['epoch'].append(logs.get('val_accuracy'))\n",
    "    \n",
    "    #把数据存入df中\n",
    "    def on_train_end(self, logs={}):\n",
    "        global output_df\n",
    "        global output_index\n",
    "        idx=0\n",
    "        maxValue=0\n",
    "       \n",
    "        for i in range(len(self.val_acc['epoch'])):\n",
    "            if self.val_acc['epoch'][i]>maxValue :\n",
    "                maxValue=self.val_acc['epoch'][i]\n",
    "                idx=i\n",
    "        \n",
    "        result_dict={\n",
    "            'Loss': self.losses['epoch'][idx],\n",
    "            'Accuracy':self.accuracy['epoch'][idx],\n",
    "            'Val-Loss':self.val_loss['epoch'][idx],\n",
    "            'Val-Accuracy':self.val_acc['epoch'][idx],\n",
    "        }\n",
    "        output_df=output_df.append(result_dict,ignore_index=True)\n",
    "        output_index.append(self.model_name)    \n",
    "    def loss_plot(self, loss_type): \n",
    "        iters = range(len(self.losses[loss_type]))\n",
    "        plt.figure()\n",
    "        plt.plot(iters, self.losses[loss_type], 'g', label='train loss')\n",
    "        if loss_type == 'epoch':\n",
    "            # acc\n",
    "            plt.plot(iters, self.accuracy[loss_type], 'r', label='train acc')\n",
    "            # loss\n",
    "            plt.plot(iters, self.losses[loss_type], 'g', label='train loss')\n",
    "            # val_acc\n",
    "            plt.plot(iters, self.val_acc[loss_type], 'b', label='val acc')\n",
    "            # val_loss\n",
    "            plt.plot(iters, self.val_loss[loss_type], 'k', label='val loss')\n",
    "        plt.grid(True)\n",
    "        plt.xlabel(loss_type)\n",
    "        plt.ylabel('acc-loss')\n",
    "        plt.legend(loc=\"upper right\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_CNN= LossHistory(\"CNN\")\n",
    "history_Xception= LossHistory(\"Xception\")\n",
    "history_Inception= LossHistory(\"Inception\")\n",
    "history_VGG19= LossHistory(\"VGG19\")\n",
    "history_Resnet= LossHistory(\"Resnet\")\n",
    "history_InceptionResnet= LossHistory(\"InceptionResnet\")\n",
    "history_VGG16= LossHistory(\"VGG16\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construct CNN models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1: a CNN model by own (baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_by_own(input_shape,num_class,epochs,savepath='./model_own.h5'):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(64,(3,3),strides=(1,1),input_shape=input_shape,padding='same',activation='relu',kernel_initializer='glorot_uniform'))\n",
    "    model.add(Conv2D(64,(3,3),strides=(1,1),padding='same',activation='relu',kernel_initializer='glorot_uniform'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Conv2D(128,(3,3),strides=(1,1),padding='same',activation='relu',kernel_initializer='glorot_uniform'))\n",
    "    model.add(Conv2D(128,(3,3),strides=(1,1),padding='same',activation='relu',kernel_initializer='glorot_uniform'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Conv2D(256,(3,3),strides=(1,1),padding='same',activation='relu',kernel_initializer='glorot_uniform'))\n",
    "    model.add(Conv2D(256,(3,3),strides=(1,1),padding='same',activation='relu',kernel_initializer='glorot_uniform'))\n",
    "    model.add(Conv2D(256,(3,3),strides=(1,1),padding='same',activation='relu',kernel_initializer='glorot_uniform'))\n",
    "    model.add(GlobalAveragePooling2D())\n",
    "    model.add(Dense(256,activation='relu'))\n",
    "    model.add(Dropout(rate=0.5))\n",
    "    model.add(Dense(num_class,activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "    #train model\n",
    "    earlyStopping=kcallbacks.EarlyStopping(monitor='val_accuracy', patience=2, verbose=1, mode='auto')\n",
    "    saveBestModel = kcallbacks.ModelCheckpoint(filepath=savepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='auto')\n",
    "    hist=model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=len(train_generator),\n",
    "        epochs=epochs,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=len(validation_generator),\n",
    "        callbacks=[earlyStopping,saveBestModel,history_CNN],\n",
    "    )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\FOCUS\\.conda\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1940: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "17/17 [==============================] - 15s 497ms/step - loss: 1.3046 - accuracy: 0.6373 - val_loss: 1.1782 - val_accuracy: 0.6409\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.64093, saving model to .\\model_own.h5\n",
      "Epoch 2/20\n",
      "17/17 [==============================] - 7s 376ms/step - loss: 1.0370 - accuracy: 0.6705 - val_loss: 0.9569 - val_accuracy: 0.6409\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.64093\n",
      "Epoch 3/20\n",
      "17/17 [==============================] - 7s 375ms/step - loss: 0.7965 - accuracy: 0.7187 - val_loss: 0.6659 - val_accuracy: 0.7452\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.64093 to 0.74517, saving model to .\\model_own.h5\n",
      "Epoch 4/20\n",
      "17/17 [==============================] - 7s 374ms/step - loss: 0.5303 - accuracy: 0.8362 - val_loss: 0.3068 - val_accuracy: 0.8707\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.74517 to 0.87066, saving model to .\\model_own.h5\n",
      "Epoch 5/20\n",
      "17/17 [==============================] - 7s 374ms/step - loss: 0.3170 - accuracy: 0.8849 - val_loss: 0.1762 - val_accuracy: 0.9189\n",
      "\n",
      "Epoch 00005: val_accuracy improved from 0.87066 to 0.91892, saving model to .\\model_own.h5\n",
      "Epoch 6/20\n",
      "17/17 [==============================] - 7s 377ms/step - loss: 0.4817 - accuracy: 0.8531 - val_loss: 0.2866 - val_accuracy: 0.8707\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.91892\n",
      "Epoch 7/20\n",
      "17/17 [==============================] - 6s 372ms/step - loss: 0.3469 - accuracy: 0.8810 - val_loss: 0.2302 - val_accuracy: 0.9015\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.91892\n",
      "Epoch 00007: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\FOCUS\\AppData\\Local\\Temp\\ipykernel_22608\\4074440202.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  output_df=output_df.append(result_dict,ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "start_time=time.time()\n",
    "cnn_by_own(input_shape=INPUT_SIZE,num_class=5,epochs=20)\n",
    "end_time=time.time()\n",
    "timelist.append(end_time-start_time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-41.485483169555664]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#output_df\n",
    "timelist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Validation accuracy of a CNN by own: 99.884%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2: Xception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xception( num_class, epochs,savepath='./xception.h5',history=history_Xception,input_shape=INPUT_SIZE):\n",
    "    model_fine_tune = Xception(include_top=False, weights='imagenet', input_shape=input_shape)\n",
    "    for layer in model_fine_tune.layers[:131]:\t\t#could be tuned to be 50, 100, or 131\n",
    "        layer.trainable = False\n",
    "    for layer in model_fine_tune.layers[131:]:\n",
    "        layer.trainable = True\n",
    "    model = GlobalAveragePooling2D()(model_fine_tune.output)\n",
    "    model=Dense(units=256,activation='relu')(model)\n",
    "    model=Dropout(0.5)(model)\n",
    "    model = Dense(num_class, activation='softmax')(model)\n",
    "    model = Model(model_fine_tune.input, model, name='xception')\n",
    "    opt = keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "    #train model\n",
    "    earlyStopping = kcallbacks.EarlyStopping(\n",
    "        monitor='val_accuracy', patience=3, verbose=1, mode='auto')\t#patience could be tuned by 2 and 3\n",
    "    saveBestModel = kcallbacks.ModelCheckpoint(\n",
    "        filepath=savepath,\n",
    "        monitor='val_accuracy',\n",
    "        verbose=1,\n",
    "        save_best_only=True,\n",
    "        mode='auto')\n",
    "    hist = model.fit(\n",
    "        train_generator,\n",
    "        steps_per_epoch=len(train_generator),\n",
    "        epochs=epochs,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=len(validation_generator),\n",
    "        #use_multiprocessing=True, \n",
    "        callbacks=[earlyStopping, saveBestModel, history],\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\FOCUS\\.conda\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py:374: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "17/17 [==============================] - 8s 322ms/step - loss: 0.6212 - accuracy: 0.7789 - val_loss: 0.1624 - val_accuracy: 0.9363\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.93629, saving model to .\\xception.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\FOCUS\\.conda\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\generic_utils.py:494: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  warnings.warn('Custom mask layers require a config and must override '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/20\n",
      "17/17 [==============================] - 4s 261ms/step - loss: 0.1214 - accuracy: 0.9639 - val_loss: 0.0520 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.93629 to 1.00000, saving model to .\\xception.h5\n",
      "Epoch 3/20\n",
      "17/17 [==============================] - 5s 282ms/step - loss: 0.0587 - accuracy: 0.9855 - val_loss: 0.0334 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 1.00000\n",
      "Epoch 4/20\n",
      "17/17 [==============================] - 5s 262ms/step - loss: 0.0360 - accuracy: 0.9947 - val_loss: 0.0205 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 1.00000\n",
      "Epoch 5/20\n",
      "17/17 [==============================] - 6s 385ms/step - loss: 0.0265 - accuracy: 0.9971 - val_loss: 0.0146 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 1.00000\n",
      "Epoch 00005: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\FOCUS\\AppData\\Local\\Temp\\ipykernel_22608\\4074440202.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  output_df=output_df.append(result_dict,ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "#default only 50, tf36cnn 99\n",
    "start_time=time.time()\n",
    "xception(num_class=5,epochs=20)\n",
    "end_time=time.time()\n",
    "timelist.append(end_time-start_time)\n",
    "\n",
    "# Insufficient Video Memory 显存不足"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Val-Loss</th>\n",
       "      <th>Val-Accuracy</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.350683</td>\n",
       "      <td>0.872832</td>\n",
       "      <td>0.218641</td>\n",
       "      <td>0.907336</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.620470</td>\n",
       "      <td>0.809249</td>\n",
       "      <td>0.411984</td>\n",
       "      <td>0.870656</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.057802</td>\n",
       "      <td>0.988439</td>\n",
       "      <td>0.029836</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.040710</td>\n",
       "      <td>0.994701</td>\n",
       "      <td>0.022890</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Loss  Accuracy  Val-Loss  Val-Accuracy Time\n",
       "0  0.350683  0.872832  0.218641      0.907336  NaN\n",
       "1  0.620470  0.809249  0.411984      0.870656  NaN\n",
       "2  0.057802  0.988439  0.029836      1.000000  NaN\n",
       "3  0.040710  0.994701  0.022890      1.000000  NaN"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timelist\n",
    "output_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validation accuracy of Xception: 100.0%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 3: VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vgg16( num_class, epochs,savepath='./VGG16.h5',history=history_VGG16,input_shape=INPUT_SIZE):\n",
    "    model_fine_tune = VGG16(include_top=False, weights='imagenet', input_shape=input_shape)\n",
    "    for layer in model_fine_tune.layers[:15]:\t#the number of frozen layers for transfer learning, have tuned from 5-18\n",
    "        layer.trainable = False\n",
    "    for layer in model_fine_tune.layers[15:]:\n",
    "        layer.trainable = True\n",
    "    model = GlobalAveragePooling2D()(model_fine_tune.output) #GlobalAveragePooling2D layer to convert the features to a single 1280-element vector per image\n",
    "    model=Dense(units=256,activation='relu')(model)\n",
    "    model=Dropout(0.5)(model)\n",
    "    model = Dense(num_class, activation='softmax')(model)\n",
    "    model = Model(model_fine_tune.input, model, name='vgg')\n",
    "    opt = keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\t#tuned learning rate to be 0.001\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\t#set the loss function to be binary crossentropy\n",
    "    #train model\n",
    "    earlyStopping = kcallbacks.EarlyStopping(\n",
    "        monitor='val_accuracy', patience=2, verbose=1, mode='auto')\t#set early stop patience to save training time\n",
    "    saveBestModel = kcallbacks.ModelCheckpoint(\n",
    "        filepath=savepath,\n",
    "        monitor='val_accuracy',\n",
    "        verbose=1,\n",
    "        save_best_only=True,\n",
    "        mode='auto')\n",
    "    hist = model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=len(train_generator),\n",
    "        epochs=epochs,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=len(validation_generator),\n",
    "        #use_multiprocessing=True, \n",
    "        #workers=2,\n",
    "        callbacks=[earlyStopping, saveBestModel, history],\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\FOCUS\\.conda\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py:374: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\FOCUS\\.conda\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1940: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "17/17 [==============================] - 11s 556ms/step - loss: 0.9956 - accuracy: 0.6267 - val_loss: 0.4159 - val_accuracy: 0.8571\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.85714, saving model to .\\VGG16.h5\n",
      "Epoch 2/20\n",
      "17/17 [==============================] - 8s 440ms/step - loss: 0.3562 - accuracy: 0.8637 - val_loss: 0.2961 - val_accuracy: 0.8861\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.85714 to 0.88610, saving model to .\\VGG16.h5\n",
      "Epoch 3/20\n",
      "17/17 [==============================] - 9s 538ms/step - loss: 0.2018 - accuracy: 0.9138 - val_loss: 0.1130 - val_accuracy: 0.9247\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.88610 to 0.92471, saving model to .\\VGG16.h5\n",
      "Epoch 4/20\n",
      "17/17 [==============================] - 9s 509ms/step - loss: 0.0813 - accuracy: 0.9658 - val_loss: 0.0207 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.92471 to 1.00000, saving model to .\\VGG16.h5\n",
      "Epoch 5/20\n",
      "17/17 [==============================] - 9s 485ms/step - loss: 0.1169 - accuracy: 0.9591 - val_loss: 0.0658 - val_accuracy: 0.9575\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 1.00000\n",
      "Epoch 6/20\n",
      "17/17 [==============================] - 10s 559ms/step - loss: 0.0189 - accuracy: 0.9923 - val_loss: 7.3169e-04 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 1.00000\n",
      "Epoch 00006: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\FOCUS\\AppData\\Local\\Temp\\ipykernel_22608\\4074440202.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  output_df=output_df.append(result_dict,ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "start_time=time.time()\n",
    "vgg16(num_class=5,epochs=20)\t#tf36cnn\n",
    "end_time=time.time()\n",
    "timelist.append(end_time-start_time)\n",
    "# Insufficient Video Memory 显存不足"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Validation accuracy of VGG16: 100.0%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 4: VGG19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vgg19( num_class, epochs,savepath='./VGG19.h5',history=history_VGG19,input_shape=INPUT_SIZE):\n",
    "    model_fine_tune = VGG19(include_top=False, weights='imagenet', input_shape=input_shape)\n",
    "    for layer in model_fine_tune.layers[:19]:\t#the number of frozen layers for transfer learning, have tuned from 5-18\n",
    "        layer.trainable = False\n",
    "    for layer in model_fine_tune.layers[19:]:\n",
    "        layer.trainable = True\n",
    "    model = GlobalAveragePooling2D()(model_fine_tune.output)\n",
    "    model=Dense(units=256,activation='relu')(model)\n",
    "    model=Dropout(0.5)(model)\n",
    "    model = Dense(num_class, activation='softmax')(model)\n",
    "    model = Model(model_fine_tune.input, model, name='vgg')\n",
    "    opt = keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\t#tuned learning rate to be 0.001\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\t#set the loss function to be binary crossentropy\n",
    "    #train model\n",
    "    earlyStopping = kcallbacks.EarlyStopping(\n",
    "        monitor='val_accuracy', patience=2, verbose=1, mode='auto')\t#set early stop patience to save training time\n",
    "    saveBestModel = kcallbacks.ModelCheckpoint(\n",
    "        filepath=savepath,\n",
    "        monitor='val_accuracy',\n",
    "        verbose=1,\n",
    "        save_best_only=True,\n",
    "        mode='auto')\n",
    "    hist = model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=len(train_generator),\n",
    "        epochs=epochs,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=len(validation_generator),\n",
    "        #use_multiprocessing=True, \n",
    "        #workers=2,\n",
    "        callbacks=[earlyStopping, saveBestModel, history],\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\FOCUS\\.conda\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py:374: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\FOCUS\\.conda\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1940: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "17/17 [==============================] - 12s 599ms/step - loss: 0.7404 - accuracy: 0.7163 - val_loss: 0.2279 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.92857, saving model to .\\VGG19.h5\n",
      "Epoch 2/20\n",
      "17/17 [==============================] - 7s 397ms/step - loss: 0.1427 - accuracy: 0.9494 - val_loss: 0.0096 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.92857 to 1.00000, saving model to .\\VGG19.h5\n",
      "Epoch 3/20\n",
      "17/17 [==============================] - 5s 265ms/step - loss: 0.0235 - accuracy: 0.9899 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 1.00000\n",
      "Epoch 4/20\n",
      "17/17 [==============================] - 5s 269ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 1.8429e-04 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 1.00000\n",
      "Epoch 00004: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\FOCUS\\AppData\\Local\\Temp\\ipykernel_22608\\4074440202.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  output_df=output_df.append(result_dict,ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "start_time=time.time()\n",
    "vgg19(num_class=5,epochs=20)\t#binary classificaiton\n",
    "\n",
    "end_time=time.time()\n",
    "timelist.append(end_time-start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Validation accuracy of VGG19: 100.0%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 5: ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resnet( num_class, epochs,savepath='./resnet.h5',history=history_Resnet,input_shape=INPUT_SIZE):\n",
    "    model_fine_tune = ResNet50(include_top=False, weights='imagenet', input_shape=input_shape)\n",
    "    for layer in model_fine_tune.layers[:120]:\t#the number of frozen layers for transfer learning, have tuned from 50-150\n",
    "        layer.trainable = False\n",
    "    for layer in model_fine_tune.layers[120:]:\t#the number of trainable layers for transfer learning\n",
    "        layer.trainable = True\n",
    "    model = GlobalAveragePooling2D()(model_fine_tune.output)\n",
    "    model=Dense(units=256,activation='relu')(model)\n",
    "    model=Dropout(0.5)(model)\n",
    "    model = Dense(num_class, activation='softmax')(model)\n",
    "    model = Model(model_fine_tune.input, model, name='resnet')\n",
    "    opt = keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\t#tuned learning rate to be 0.001\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy']) #set the loss function to be binary crossentropy\n",
    "    #train model\n",
    "    earlyStopping = kcallbacks.EarlyStopping(\n",
    "        monitor='val_accuracy', patience=2, verbose=1, mode='auto')\t#set early stop patience to save training time\n",
    "    saveBestModel = kcallbacks.ModelCheckpoint(\n",
    "        filepath=savepath,\n",
    "        monitor='val_accuracy',\n",
    "        verbose=1,\n",
    "        save_best_only=True,\n",
    "        mode='auto')\n",
    "    hist = model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=len(train_generator),\n",
    "        epochs=epochs,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=len(validation_generator),\n",
    "        #use_multiprocessing=True, \n",
    "        callbacks=[earlyStopping, saveBestModel, history],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\FOCUS\\.conda\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py:374: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\FOCUS\\.conda\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1940: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "17/17 [==============================] - 9s 355ms/step - loss: 0.7253 - accuracy: 0.7582 - val_loss: 25.0492 - val_accuracy: 0.6409\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.64093, saving model to .\\resnet.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\FOCUS\\.conda\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\generic_utils.py:494: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  warnings.warn('Custom mask layers require a config and must override '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/20\n",
      "17/17 [==============================] - 5s 268ms/step - loss: 0.2117 - accuracy: 0.9128 - val_loss: 37.0571 - val_accuracy: 0.6409\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.64093\n",
      "Epoch 3/20\n",
      "17/17 [==============================] - 5s 274ms/step - loss: 0.1279 - accuracy: 0.9509 - val_loss: 12.1715 - val_accuracy: 0.7452\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.64093 to 0.74517, saving model to .\\resnet.h5\n",
      "Epoch 4/20\n",
      "17/17 [==============================] - 5s 261ms/step - loss: 0.0720 - accuracy: 0.9750 - val_loss: 2.4784 - val_accuracy: 0.8707\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.74517 to 0.87066, saving model to .\\resnet.h5\n",
      "Epoch 5/20\n",
      "17/17 [==============================] - 9s 504ms/step - loss: 0.0169 - accuracy: 0.9952 - val_loss: 161.5173 - val_accuracy: 0.1313\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.87066\n",
      "Epoch 6/20\n",
      "17/17 [==============================] - 8s 483ms/step - loss: 0.0184 - accuracy: 0.9957 - val_loss: 87.2207 - val_accuracy: 0.1255\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.87066\n",
      "Epoch 00006: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\FOCUS\\AppData\\Local\\Temp\\ipykernel_22608\\4074440202.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  output_df=output_df.append(result_dict,ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "start_time=time.time()\n",
    "resnet(num_class=5,epochs=20)\t#binary classificaiton\n",
    "end_time=time.time()\n",
    "timelist.append(end_time-start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validation accuracy of Resnet: 98.652%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 6: Inception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inception( num_class, epochs,savepath='./inception.h5',history=history_Inception,input_shape=INPUT_SIZE):\n",
    "    model_fine_tune = InceptionV3(include_top=False, weights='imagenet', input_shape=input_shape)\n",
    "    for layer in model_fine_tune.layers[:35]:\t#the number of frozen layers for transfer learning, have tuned from 50-150\n",
    "        layer.trainable = False\n",
    "    for layer in model_fine_tune.layers[35:]:\t#the number of trainable layers for transfer learning\n",
    "        layer.trainable = True\n",
    "    model = GlobalAveragePooling2D()(model_fine_tune.output)\n",
    "    model=Dense(units=256,activation='relu')(model)\n",
    "    model=Dropout(0.5)(model)\n",
    "    model = Dense(num_class, activation='softmax')(model)\n",
    "    model = Model(model_fine_tune.input, model, name='resnet')\n",
    "    opt = keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\t#tuned learning rate to be 0.001\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy']) #set the loss function to be binary crossentropy\n",
    "    #train model\n",
    "    earlyStopping = kcallbacks.EarlyStopping(\n",
    "        monitor='val_accuracy', patience=2, verbose=1, mode='auto')\t#set early stop patience to save training time\n",
    "    saveBestModel = kcallbacks.ModelCheckpoint(\n",
    "        filepath=savepath,\n",
    "        monitor='val_accuracy',\n",
    "        verbose=1,\n",
    "        save_best_only=True,\n",
    "        mode='auto')\n",
    "    hist = model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=len(train_generator),\n",
    "        epochs=epochs,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=len(validation_generator),\n",
    "        #use_multiprocessing=True, \n",
    "        callbacks=[earlyStopping, saveBestModel, history],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\FOCUS\\.conda\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py:374: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\FOCUS\\.conda\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1940: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "17/17 [==============================] - 22s 644ms/step - loss: 0.2028 - accuracy: 0.9229 - val_loss: 1.4018 - val_accuracy: 0.7317\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.73166, saving model to .\\inception.h5\n",
      "Epoch 2/20\n",
      "17/17 [==============================] - 5s 277ms/step - loss: 0.0169 - accuracy: 0.9952 - val_loss: 8.0309 - val_accuracy: 0.2413\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.73166\n",
      "Epoch 3/20\n",
      "17/17 [==============================] - 5s 272ms/step - loss: 0.0462 - accuracy: 0.9942 - val_loss: 5.0730 - val_accuracy: 0.1506\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.73166\n",
      "Epoch 00003: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\FOCUS\\AppData\\Local\\Temp\\ipykernel_22608\\4074440202.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  output_df=output_df.append(result_dict,ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "start_time=time.time()\n",
    "inception(num_class=5,epochs=20)\t#binary classificaiton\n",
    "\n",
    "end_time=time.time()\n",
    "timelist.append(end_time-start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validation accuracy of Inception: 100.0%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 7: InceptionResnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inceptionresnet( num_class, epochs,savepath='./inceptionresnet.h5',history=history_InceptionResnet,input_shape=INPUT_SIZE):\n",
    "    model_fine_tune = InceptionResNetV2(include_top=False, weights='imagenet', input_shape=input_shape)\n",
    "    for layer in model_fine_tune.layers[:500]:\t#the number of frozen layers for transfer learning, have tuned from 400-550\n",
    "        layer.trainable = False\n",
    "    for layer in model_fine_tune.layers[500:]:\t#the number of trainable layers for transfer learning\n",
    "        layer.trainable = True\n",
    "    model = GlobalAveragePooling2D()(model_fine_tune.output)\n",
    "    model=Dense(units=256,activation='relu')(model)\n",
    "    model=Dropout(0.5)(model)\n",
    "    model = Dense(num_class, activation='softmax')(model)\n",
    "    model = Model(model_fine_tune.input, model, name='resnet')\n",
    "    opt = keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\t#tuned learning rate to be 0.001\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy']) #set the loss function to be binary crossentropy\n",
    "    #train model\n",
    "    earlyStopping = kcallbacks.EarlyStopping(\n",
    "        monitor='val_accuracy', patience=2, verbose=1, mode='auto')\t#set early stop patience to save training time\n",
    "    saveBestModel = kcallbacks.ModelCheckpoint(\n",
    "        filepath=savepath,\n",
    "        monitor='val_accuracy',\n",
    "        verbose=1,\n",
    "        save_best_only=True,\n",
    "        mode='auto')\n",
    "    hist = model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=len(train_generator),\n",
    "        epochs=epochs,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=len(validation_generator),\n",
    "        #use_multiprocessing=True, \n",
    "        callbacks=[earlyStopping, saveBestModel, history],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\FOCUS\\.conda\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py:374: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\FOCUS\\.conda\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1940: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "17/17 [==============================] - 18s 505ms/step - loss: 0.2535 - accuracy: 0.9041 - val_loss: 8.9571 - val_accuracy: 0.5830\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.58301, saving model to .\\inceptionresnet.h5\n",
      "Epoch 2/20\n",
      "17/17 [==============================] - 6s 324ms/step - loss: 0.0429 - accuracy: 0.9918 - val_loss: 855.8776 - val_accuracy: 0.1255\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.58301\n",
      "Epoch 3/20\n",
      "17/17 [==============================] - 6s 325ms/step - loss: 0.0144 - accuracy: 0.9961 - val_loss: 1335.4979 - val_accuracy: 0.1255\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.58301\n",
      "Epoch 00003: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\FOCUS\\AppData\\Local\\Temp\\ipykernel_22608\\4074440202.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  output_df=output_df.append(result_dict,ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "start_time=time.time()\n",
    "inceptionresnet(num_class=5,epochs=20)\t# 5-class classificaiton\n",
    "end_time=time.time()\n",
    "timelist.append(end_time-start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Val-Loss</th>\n",
       "      <th>Val-Accuracy</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CNN</th>\n",
       "      <td>0.317030</td>\n",
       "      <td>0.884875</td>\n",
       "      <td>0.176219</td>\n",
       "      <td>0.918919</td>\n",
       "      <td>56.111356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Xception</th>\n",
       "      <td>0.121406</td>\n",
       "      <td>0.963873</td>\n",
       "      <td>0.051983</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>29.523946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VGG16</th>\n",
       "      <td>0.081342</td>\n",
       "      <td>0.965800</td>\n",
       "      <td>0.020728</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>56.129753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VGG19</th>\n",
       "      <td>0.142718</td>\n",
       "      <td>0.949422</td>\n",
       "      <td>0.009572</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>29.495696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Resnet</th>\n",
       "      <td>0.072001</td>\n",
       "      <td>0.974952</td>\n",
       "      <td>2.478381</td>\n",
       "      <td>0.870656</td>\n",
       "      <td>43.197704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Inception</th>\n",
       "      <td>0.202810</td>\n",
       "      <td>0.922929</td>\n",
       "      <td>1.401780</td>\n",
       "      <td>0.731660</td>\n",
       "      <td>35.801315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>InceptionResnet</th>\n",
       "      <td>0.253547</td>\n",
       "      <td>0.904143</td>\n",
       "      <td>8.957052</td>\n",
       "      <td>0.583012</td>\n",
       "      <td>33.867579</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Loss  Accuracy  Val-Loss  Val-Accuracy       Time\n",
       "CNN              0.317030  0.884875  0.176219      0.918919  56.111356\n",
       "Xception         0.121406  0.963873  0.051983      1.000000  29.523946\n",
       "VGG16            0.081342  0.965800  0.020728      1.000000  56.129753\n",
       "VGG19            0.142718  0.949422  0.009572      1.000000  29.495696\n",
       "Resnet           0.072001  0.974952  2.478381      0.870656  43.197704\n",
       "Inception        0.202810  0.922929  1.401780      0.731660  35.801315\n",
       "InceptionResnet  0.253547  0.904143  8.957052      0.583012  33.867579"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_df.index=output_index\n",
    "output_df['Time']=timelist\n",
    "output_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Validation accuracy of InceptionResnet: 99.993%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Optimization \n",
    "Use VGG16 as an example.  \n",
    "\n",
    "Tuned hyperparameters of CNN: \n",
    "1. The number of frozen layers\n",
    "2. The number of epochs\n",
    "3. Early stop patience\n",
    "4. Learning rate\n",
    "5. Dropout rate\n",
    "\n",
    "Hyperparameter optimization methods:\n",
    "1. Random search\n",
    "2. Bayesian optimization - Tree Parzen Estimator(BO-TPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vgg16( num_class,epochs=20,frozen=15,lr=0.001,patience=2, dropout_rate=0.5,verbose=0, savepath='./VGG16.h5',history=history_this,input_shape=INPUT_SIZE):\n",
    "    model_fine_tune = VGG16(include_top=False, weights='imagenet', input_shape=input_shape)\n",
    "    for layer in model_fine_tune.layers[:frozen]:\t#the number of frozen layers for transfer learning, have tuned from 5-18\n",
    "        layer.trainable = False\n",
    "    for layer in model_fine_tune.layers[frozen:]:\n",
    "        layer.trainable = True\n",
    "    model = GlobalAveragePooling2D()(model_fine_tune.output)\n",
    "    model=Dense(units=256,activation='relu')(model)\n",
    "    model=Dropout(dropout_rate)(model)\n",
    "    model = Dense(num_class, activation='softmax')(model)\n",
    "    model = Model(model_fine_tune.input, model, name='vgg')\n",
    "    opt = keras.optimizers.Adam(lr=lr, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\t#tuned learning rate to be 0.001\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\t#set the loss function to be binary crossentropy\n",
    "    #train model\n",
    "    earlyStopping = kcallbacks.EarlyStopping(\n",
    "        monitor='val_accuracy', patience=patience, verbose=verbose, mode='auto')\t#set early stop patience to save training time\n",
    "    saveBestModel = kcallbacks.ModelCheckpoint(\n",
    "        filepath=savepath,\n",
    "        monitor='val_accuracy',\n",
    "        verbose=verbose,\n",
    "        save_best_only=True,\n",
    "        mode='auto')\n",
    "    hist = model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=len(train_generator),\n",
    "        epochs=epochs,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=len(validation_generator),\n",
    "        #use_multiprocessing=True, \n",
    "        #workers=2,\n",
    "        callbacks=[earlyStopping, saveBestModel, history],\n",
    "        verbose = verbose\n",
    "    )\n",
    "    return hist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(vgg_model):\n",
    "#read images from validation folder\n",
    "    rootdir = './test_224/'\n",
    "    test_laels = []\n",
    "    test_images=[]\n",
    "    for subdir, dirs, files in os.walk(rootdir):\n",
    "        for file in files:\n",
    "            if not (file.endswith(\".jpeg\"))|(file.endswith(\".jpg\"))|(file.endswith(\".png\")):\n",
    "                continue\n",
    "            test_laels.append(subdir.split('/')[-1])\n",
    "            test_images.append(os.path.join(subdir, file))\n",
    "\n",
    "    predict=[]\n",
    "    length=len(test_images)\n",
    "    label=validation_generator.class_indices\n",
    "    label={v: k for k, v in label.items()}\n",
    "    for i in range(length):\n",
    "        inputimg=test_images[i]\n",
    "        test_batch=[]\n",
    "        thisimg=np.array(Image.open(inputimg))/255 #read all the images in validation set\n",
    "        #print(thisimg)\n",
    "        test_shape=(1,)+thisimg.shape\n",
    "        thisimg=thisimg.reshape(test_shape)\n",
    "        vgg_model_batch=vgg_model.predict(thisimg) #use master model to process the input image\n",
    "        #generate result by model 1\n",
    "        prob=vgg_model_batch[0,np.argmax(vgg_model_batch,axis=1)[0]]\n",
    "        res=label[np.argmax(vgg_model_batch,axis=1)[0]]\n",
    "        predict.append(res)\n",
    "    acc=accuracy_score(test_laels,predict)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the objective function to be optimized\n",
    "import time\n",
    "from hyperopt import hp, fmin, tpe, rand, STATUS_OK, Trials\n",
    "import matplotlib.pyplot as plt\n",
    "import statistics \n",
    "\n",
    "def objective(params):\n",
    "    \n",
    "    params = {\n",
    "        'frozen': int(params['frozen']),\n",
    "        'epochs': int(params['epochs']),\n",
    "        'patience': int(params['patience']),\n",
    "        'lr': abs(float(params['lr'])),\n",
    "        'dropout_rate': abs(float(params['dropout_rate'])),\n",
    "    }\n",
    "    frozen=params['frozen']\n",
    "    epochs=params['epochs']\n",
    "    patience=params['patience']\n",
    "    lr=params['lr']\n",
    "    dropout_rate=params['dropout_rate']\n",
    "\n",
    "    vgg16(num_class=5, frozen=frozen,epochs=epochs,patience=patience, lr=lr, dropout_rate=dropout_rate)\n",
    "\n",
    "    acc=prediction(vgg_model=load_model('./VGG16.h5'))\n",
    "\n",
    "    print('accuracy:%s'%acc)\n",
    "    return {'loss': -acc, 'status': STATUS_OK }\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:1.0                                                                                                           \n",
      " 10%|██████▎                                                        | 1/10 [01:18<11:49, 78.79s/trial, best loss: -1.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\FOCUS\\.conda\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py:374: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  warnings.warn(\n",
      "\n",
      "C:\\Users\\FOCUS\\.conda\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1940: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:1.0                                                                                                           \n",
      " 20%|████████████▌                                                  | 2/10 [02:01<07:41, 57.70s/trial, best loss: -1.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\FOCUS\\.conda\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py:374: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  warnings.warn(\n",
      "\n",
      "C:\\Users\\FOCUS\\.conda\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1940: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:1.0                                                                                                           \n",
      " 30%|██████████████████▉                                            | 3/10 [03:15<07:36, 65.20s/trial, best loss: -1.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\FOCUS\\.conda\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py:374: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  warnings.warn(\n",
      "\n",
      "C:\\Users\\FOCUS\\.conda\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1940: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:1.0                                                                                                           \n",
      " 40%|█████████████████████████▏                                     | 4/10 [03:58<05:37, 56.27s/trial, best loss: -1.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\FOCUS\\.conda\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py:374: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  warnings.warn(\n",
      "\n",
      "C:\\Users\\FOCUS\\.conda\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1940: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:0.9980694980694981                                                                                            \n",
      " 50%|███████████████████████████████▌                               | 5/10 [05:22<05:30, 66.11s/trial, best loss: -1.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\FOCUS\\.conda\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py:374: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  warnings.warn(\n",
      "\n",
      "C:\\Users\\FOCUS\\.conda\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1940: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:1.0                                                                                                           \n",
      " 60%|█████████████████████████████████████▊                         | 6/10 [06:04<03:52, 58.19s/trial, best loss: -1.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\FOCUS\\.conda\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py:374: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  warnings.warn(\n",
      "\n",
      "C:\\Users\\FOCUS\\.conda\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1940: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:0.9961389961389961                                                                                            \n",
      " 70%|████████████████████████████████████████████                   | 7/10 [07:10<03:01, 60.49s/trial, best loss: -1.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\FOCUS\\.conda\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py:374: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  warnings.warn(\n",
      "\n",
      "C:\\Users\\FOCUS\\.conda\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1940: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:0.888030888030888                                                                                             \n",
      " 80%|██████████████████████████████████████████████████▍            | 8/10 [08:17<02:05, 62.62s/trial, best loss: -1.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\FOCUS\\.conda\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py:374: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  warnings.warn(\n",
      "\n",
      "C:\\Users\\FOCUS\\.conda\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1940: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:1.0                                                                                                           \n",
      " 90%|████████████████████████████████████████████████████████▋      | 9/10 [09:11<00:59, 59.98s/trial, best loss: -1.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\FOCUS\\.conda\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py:374: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  warnings.warn(\n",
      "\n",
      "C:\\Users\\FOCUS\\.conda\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1940: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:0.9575289575289575                                                                                            \n",
      "100%|██████████████████████████████████████████████████████████████| 10/10 [09:55<00:00, 59.53s/trial, best loss: -1.0]\n",
      "Hyperopt estimated optimum {'dropout_rate': 0.5, 'epochs': 15.0, 'frozen': 15.0, 'lr': 0.002, 'patience': 3.0}\n",
      "Time: 595.261168718338\n"
     ]
    }
   ],
   "source": [
    "#Hyperparameter optimization by Bayesian optimization - Tree Parzen Estimator\n",
    "space = {\n",
    "    'frozen': hp.quniform('frozen', 15, 18, 1),\n",
    "    'epochs': hp.quniform('epochs', 5, 21, 5),\n",
    "    'patience': hp.quniform('patience', 2, 4, 1),\n",
    "    'lr': hp.quniform('lr', 0.001, 0.006, 0.001),\n",
    "    'dropout_rate': hp.quniform('dropout_rate', 0.3, 0.6, 0.1),\n",
    "}\n",
    "\n",
    "t1=time.time()\n",
    "best = fmin(fn=objective,\n",
    "            space=space,\n",
    "            algo=tpe.suggest,\n",
    "            max_evals=10)\n",
    "print(\"Hyperopt estimated optimum {}\".format(best))\n",
    "t2=time.time()\n",
    "print(\"Time: \"+str(t2-t1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "  0%|                                                                           | 0/10 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\FOCUS\\.conda\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py:374: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  warnings.warn(\n",
      "\n",
      "C:\\Users\\FOCUS\\.conda\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1940: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:0.9980694980694981                                                                                            \n",
      " 10%|████▊                                           | 1/10 [01:06<10:00, 66.70s/trial, best loss: -0.9980694980694981]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\FOCUS\\.conda\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py:374: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  warnings.warn(\n",
      "\n",
      "C:\\Users\\FOCUS\\.conda\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1940: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:1.0                                                                                                           \n",
      " 20%|████████████▌                                                  | 2/10 [01:59<07:46, 58.35s/trial, best loss: -1.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\FOCUS\\.conda\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py:374: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  warnings.warn(\n",
      "\n",
      "C:\\Users\\FOCUS\\.conda\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1940: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:0.8513513513513513                                                                                            \n",
      " 30%|██████████████████▉                                            | 3/10 [02:43<06:03, 51.97s/trial, best loss: -1.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\FOCUS\\.conda\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py:374: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  warnings.warn(\n",
      "\n",
      "C:\\Users\\FOCUS\\.conda\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1940: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:0.6293436293436293                                                                                            \n",
      " 40%|█████████████████████████▏                                     | 4/10 [03:22<04:41, 46.83s/trial, best loss: -1.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\FOCUS\\.conda\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py:374: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  warnings.warn(\n",
      "\n",
      "C:\\Users\\FOCUS\\.conda\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1940: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:1.0                                                                                                           \n",
      " 50%|███████████████████████████████▌                               | 5/10 [04:05<03:47, 45.42s/trial, best loss: -1.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\FOCUS\\.conda\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py:374: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  warnings.warn(\n",
      "\n",
      "C:\\Users\\FOCUS\\.conda\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1940: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:1.0                                                                                                           \n",
      " 60%|█████████████████████████████████████▊                         | 6/10 [04:43<02:52, 43.08s/trial, best loss: -1.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\FOCUS\\.conda\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py:374: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  warnings.warn(\n",
      "\n",
      "C:\\Users\\FOCUS\\.conda\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1940: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:0.9961389961389961                                                                                            \n",
      " 70%|████████████████████████████████████████████                   | 7/10 [06:02<02:43, 54.62s/trial, best loss: -1.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\FOCUS\\.conda\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py:374: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  warnings.warn(\n",
      "\n",
      "C:\\Users\\FOCUS\\.conda\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1940: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:1.0                                                                                                           \n",
      " 80%|██████████████████████████████████████████████████▍            | 8/10 [06:45<01:41, 50.89s/trial, best loss: -1.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\FOCUS\\.conda\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py:374: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  warnings.warn(\n",
      "\n",
      "C:\\Users\\FOCUS\\.conda\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1940: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:1.0                                                                                                           \n",
      " 90%|████████████████████████████████████████████████████████▋      | 9/10 [07:28<00:48, 48.43s/trial, best loss: -1.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\FOCUS\\.conda\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py:374: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  warnings.warn(\n",
      "\n",
      "C:\\Users\\FOCUS\\.conda\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1940: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:1.0                                                                                                           \n",
      "100%|██████████████████████████████████████████████████████████████| 10/10 [08:11<00:00, 49.15s/trial, best loss: -1.0]\n",
      "Hyperopt estimated optimum {'dropout_rate': 0.5, 'epochs': 15.0, 'frozen': 18.0, 'lr': 0.002, 'patience': 3.0}\n",
      "Time: 491.4807291030884\n"
     ]
    }
   ],
   "source": [
    "#Hyperparameter optimization by Random search\n",
    "space = {\n",
    "    'frozen': hp.quniform('frozen', 15, 18, 1),\n",
    "    'epochs': hp.quniform('epochs', 5, 21, 5),\n",
    "    'patience': hp.quniform('patience', 2, 4, 1),\n",
    "    'lr': hp.quniform('lr', 0.001, 0.006, 0.001),\n",
    "    'dropout_rate': hp.quniform('dropout_rate', 0.3, 0.6, 0.1),\n",
    "}\n",
    "\n",
    "t1=time.time()\n",
    "best = fmin(fn=objective,\n",
    "            space=space,\n",
    "            algo=rand.suggest,\n",
    "            max_evals=10)\n",
    "print(\"Hyperopt estimated optimum {}\".format(best))\n",
    "t2=time.time()\n",
    "print(\"Time: \"+str(t2-t1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "17/17 [==============================] - 5s 266ms/step - loss: 1.0856 - accuracy: 0.6652 - val_loss: 0.6871 - val_accuracy: 0.7336\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.73359, saving model to .\\VGG16.h5\n",
      "Epoch 2/15\n",
      "17/17 [==============================] - 4s 251ms/step - loss: 0.5557 - accuracy: 0.8107 - val_loss: 0.3996 - val_accuracy: 0.8610\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.73359 to 0.86100, saving model to .\\VGG16.h5\n",
      "Epoch 3/15\n",
      "17/17 [==============================] - 4s 256ms/step - loss: 0.3346 - accuracy: 0.8911 - val_loss: 0.2401 - val_accuracy: 0.9788\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.86100 to 0.97876, saving model to .\\VGG16.h5\n",
      "Epoch 4/15\n",
      "17/17 [==============================] - 4s 257ms/step - loss: 0.2135 - accuracy: 0.9595 - val_loss: 0.1484 - val_accuracy: 0.9884\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.97876 to 0.98842, saving model to .\\VGG16.h5\n",
      "Epoch 5/15\n",
      "17/17 [==============================] - 4s 252ms/step - loss: 0.1429 - accuracy: 0.9855 - val_loss: 0.0936 - val_accuracy: 0.9981\n",
      "\n",
      "Epoch 00005: val_accuracy improved from 0.98842 to 0.99807, saving model to .\\VGG16.h5\n",
      "Epoch 6/15\n",
      "17/17 [==============================] - 4s 253ms/step - loss: 0.0984 - accuracy: 0.9933 - val_loss: 0.0717 - val_accuracy: 0.9961\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.99807\n",
      "Epoch 7/15\n",
      "17/17 [==============================] - 4s 252ms/step - loss: 0.0747 - accuracy: 0.9957 - val_loss: 0.0435 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00007: val_accuracy improved from 0.99807 to 1.00000, saving model to .\\VGG16.h5\n",
      "Epoch 8/15\n",
      "17/17 [==============================] - 4s 256ms/step - loss: 0.0563 - accuracy: 0.9986 - val_loss: 0.0329 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 1.00000\n",
      "Epoch 9/15\n",
      "17/17 [==============================] - 4s 249ms/step - loss: 0.0427 - accuracy: 0.9976 - val_loss: 0.0247 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 1.00000\n",
      "Epoch 10/15\n",
      "17/17 [==============================] - 4s 257ms/step - loss: 0.0341 - accuracy: 0.9976 - val_loss: 0.0195 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 1.00000\n",
      "Epoch 00010: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x19f27a79e20>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retrain the model by using the best hyperparameter values to obtain the best model\n",
    "vgg16(num_class=5, frozen=18,epochs=15,patience=3, lr=0.002, dropout_rate=0.5,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "tf2",
   "language": "python",
   "name": "tf2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "bc342a2d18cd8de928dda5685bacff2bb239146e0847e732d8a85b5d43ec132e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
