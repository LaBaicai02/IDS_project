{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Transfer Learning and Optimized CNN Based Intrusion Detection System for Internet of Vehicles \n",
    "This is the code for the paper entitled \"**A Transfer Learning and Optimized CNN Based Intrusion Detection System for Internet of Vehicles**\" accepted in IEEE International Conference on Communications (IEEE ICC).  \n",
    "Authors: Li Yang (lyang339@uwo.ca) and Abdallah Shami (Abdallah.Shami@uwo.ca)  \n",
    "Organization: The Optimized Computing and Communications (OC2) Lab, ECE Department, Western University\n",
    "\n",
    "**Notebook 2: CNN Model Development**  \n",
    "Aims:  \n",
    "&nbsp; 1): Generate training and test images  \n",
    "&nbsp; 2): Construct CNN models (a CNN model by own, Xception, VGG16, VGG19, Resnet, Inception, InceptionResnet)  \n",
    "&nbsp; 3): Tune the hyperparameters of CNN models (hyperparameter optimization)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from tensorflow.keras.preprocessing.image import  ImageDataGenerator\n",
    "from tensorflow.keras.layers import Dense,Flatten,GlobalAveragePooling2D,Input,Conv2D,MaxPooling2D,Dropout\n",
    "from tensorflow.keras.models import Model,load_model,Sequential\n",
    "from tensorflow.keras.applications.xception import  Xception\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.applications.vgg19 import VGG19\n",
    "from tensorflow.keras.applications.resnet50 import  ResNet50\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "from tensorflow.keras.applications.inception_resnet_v2 import InceptionResNetV2\n",
    "from tensorflow.keras.applications.mobilenet import MobileNet\n",
    "import tensorflow.keras.callbacks as kcallbacks\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.preprocessing.image import load_img,img_to_array\n",
    "import math\n",
    "import random\n",
    "from tensorflow.keras.utils import plot_model\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.metrics as metrics\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.metrics import accuracy_score,precision_score,recall_score,f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Training and Test Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2076 images belonging to 5 classes.\n",
      "Found 518 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "#generate training and test images\n",
    "TARGET_SIZE=(224,224)\n",
    "INPUT_SIZE=(224,224,3)\n",
    "BATCHSIZE=128\t#could try 128 or 32\n",
    "\n",
    "#Normalization\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        './train_224/',\n",
    "        target_size=TARGET_SIZE,\n",
    "        batch_size=BATCHSIZE,\n",
    "        class_mode='categorical')\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        './test_224/',\n",
    "        target_size=TARGET_SIZE,\n",
    "        batch_size=BATCHSIZE,\n",
    "        class_mode='categorical')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the image plotting functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "output_df = pd.DataFrame(columns=['Loss','Accuracy',  'Val-Loss', 'Val-Accuracy', 'Time'])\n",
    "output_index = list()\n",
    "timelist=list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot the figures\n",
    "class LossHistory(keras.callbacks.Callback):\n",
    "    def __init__(self, model_name):\n",
    "        self.model_name=model_name\n",
    "    def on_train_begin(self, logs={}):\n",
    "        \n",
    "        self.losses = {'batch':[], 'epoch':[]}\n",
    "        self.accuracy = {'batch':[], 'epoch':[]}\n",
    "        self.val_loss = {'batch':[], 'epoch':[]}\n",
    "        self.val_acc = {'batch':[], 'epoch':[]}\n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        self.losses['batch'].append(logs.get('loss'))\n",
    "        self.accuracy['batch'].append(logs.get('accuracy'))\n",
    "        self.val_loss['batch'].append(logs.get('val_loss'))\n",
    "        self.val_acc['batch'].append(logs.get('val_accuracy'))\n",
    "    def on_epoch_end(self, batch, logs={}):\n",
    "        self.losses['epoch'].append(logs.get('loss'))\n",
    "        self.accuracy['epoch'].append(logs.get('accuracy'))\n",
    "        self.val_loss['epoch'].append(logs.get('val_loss'))\n",
    "        self.val_acc['epoch'].append(logs.get('val_accuracy'))\n",
    "    \n",
    "    #把数据存入df中\n",
    "    def on_train_end(self, logs={}):\n",
    "        global output_df\n",
    "        global output_index\n",
    "        idx=0\n",
    "        maxValue=0\n",
    "       \n",
    "        for i in range(len(self.val_acc['epoch'])):\n",
    "            if self.val_acc['epoch'][i]>maxValue :\n",
    "                maxValue=self.val_acc['epoch'][i]\n",
    "                idx=i\n",
    "        \n",
    "        result_dict={\n",
    "            'Loss': self.losses['epoch'][idx],\n",
    "            'Accuracy':self.accuracy['epoch'][idx],\n",
    "            'Val-Loss':self.val_loss['epoch'][idx],\n",
    "            'Val-Accuracy':self.val_acc['epoch'][idx],\n",
    "        }\n",
    "        output_df=output_df.append(result_dict,ignore_index=True)\n",
    "        output_index.append(self.model_name)    \n",
    "    def loss_plot(self, loss_type): \n",
    "        iters = range(len(self.losses[loss_type]))\n",
    "        plt.figure()\n",
    "        plt.plot(iters, self.losses[loss_type], 'g', label='train loss')\n",
    "        if loss_type == 'epoch':\n",
    "            # acc\n",
    "            plt.plot(iters, self.accuracy[loss_type], 'r', label='train acc')\n",
    "            # loss\n",
    "            plt.plot(iters, self.losses[loss_type], 'g', label='train loss')\n",
    "            # val_acc\n",
    "            plt.plot(iters, self.val_acc[loss_type], 'b', label='val acc')\n",
    "            # val_loss\n",
    "            plt.plot(iters, self.val_loss[loss_type], 'k', label='val loss')\n",
    "        plt.grid(True)\n",
    "        plt.xlabel(loss_type)\n",
    "        plt.ylabel('acc-loss')\n",
    "        plt.legend(loc=\"upper right\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_CNN= LossHistory(\"CNN\")\n",
    "history_Xception= LossHistory(\"Xception\")\n",
    "history_Inception= LossHistory(\"Inception\")\n",
    "history_VGG19= LossHistory(\"VGG19\")\n",
    "history_Resnet= LossHistory(\"Resnet\")\n",
    "history_InceptionResnet= LossHistory(\"InceptionResnet\")\n",
    "history_VGG16= LossHistory(\"VGG16\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construct CNN models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1: a CNN model by own (baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_by_own(input_shape,num_class,epochs,savepath='./model_own.h5'):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(64,(3,3),strides=(1,1),input_shape=input_shape,padding='same',activation='relu',kernel_initializer='glorot_uniform'))\n",
    "    model.add(Conv2D(64,(3,3),strides=(1,1),padding='same',activation='relu',kernel_initializer='glorot_uniform'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Conv2D(128,(3,3),strides=(1,1),padding='same',activation='relu',kernel_initializer='glorot_uniform'))\n",
    "    model.add(Conv2D(128,(3,3),strides=(1,1),padding='same',activation='relu',kernel_initializer='glorot_uniform'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Conv2D(256,(3,3),strides=(1,1),padding='same',activation='relu',kernel_initializer='glorot_uniform'))\n",
    "    model.add(Conv2D(256,(3,3),strides=(1,1),padding='same',activation='relu',kernel_initializer='glorot_uniform'))\n",
    "    model.add(Conv2D(256,(3,3),strides=(1,1),padding='same',activation='relu',kernel_initializer='glorot_uniform'))\n",
    "    model.add(GlobalAveragePooling2D())\n",
    "    model.add(Dense(256,activation='relu'))\n",
    "    model.add(Dropout(rate=0.5))\n",
    "    model.add(Dense(num_class,activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "    #train model\n",
    "    earlyStopping=kcallbacks.EarlyStopping(monitor='val_accuracy', patience=2, verbose=1, mode='auto')\n",
    "    saveBestModel = kcallbacks.ModelCheckpoint(filepath=savepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='auto')\n",
    "    hist=model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=len(train_generator),\n",
    "        epochs=epochs,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=len(validation_generator),\n",
    "        callbacks=[earlyStopping,saveBestModel,history_CNN],\n",
    "    )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\FOCUS\\.conda\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1940: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      " 6/17 [=========>....................] - ETA: 3s - loss: 1.4205 - accuracy: 0.5990WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1327s vs `on_train_batch_end` time: 0.1873s). Check your callbacks.\n",
      "17/17 [==============================] - 17s 591ms/step - loss: 1.2860 - accuracy: 0.6469 - val_loss: 1.2220 - val_accuracy: 0.6293\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.62934, saving model to .\\model_own.h5\n",
      "Epoch 2/20\n",
      "17/17 [==============================] - 9s 492ms/step - loss: 1.0426 - accuracy: 0.6734 - val_loss: 1.0297 - val_accuracy: 0.6293\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.62934\n",
      "Epoch 3/20\n",
      "17/17 [==============================] - 9s 549ms/step - loss: 0.8042 - accuracy: 0.7100 - val_loss: 0.8117 - val_accuracy: 0.7336\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.62934 to 0.73359, saving model to .\\model_own.h5\n",
      "Epoch 4/20\n",
      "17/17 [==============================] - 10s 559ms/step - loss: 0.5388 - accuracy: 0.8232 - val_loss: 0.4045 - val_accuracy: 0.8514\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.73359 to 0.85135, saving model to .\\model_own.h5\n",
      "Epoch 5/20\n",
      "17/17 [==============================] - 8s 444ms/step - loss: 0.4767 - accuracy: 0.8319 - val_loss: 3.4378 - val_accuracy: 0.6351\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.85135\n",
      "Epoch 6/20\n",
      "17/17 [==============================] - 9s 507ms/step - loss: 1.1482 - accuracy: 0.7182 - val_loss: 0.8505 - val_accuracy: 0.7046\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.85135\n",
      "Epoch 00006: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\FOCUS\\AppData\\Local\\Temp\\ipykernel_24312\\4074440202.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  output_df=output_df.append(result_dict,ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "start_time=time.time()\n",
    "cnn_by_own(input_shape=INPUT_SIZE,num_class=5,epochs=20)\n",
    "end_time=time.time()\n",
    "timelist.append(end_time-start_time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[62.87252902984619]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#output_df\n",
    "timelist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Validation accuracy of a CNN by own: 99.884%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2: Xception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xception( num_class, epochs,savepath='./xception.h5',history=history_Xception,input_shape=INPUT_SIZE):\n",
    "    model_fine_tune = Xception(include_top=False, weights='imagenet', input_shape=input_shape)\n",
    "    for layer in model_fine_tune.layers[:131]:\t\t#could be tuned to be 50, 100, or 131\n",
    "        layer.trainable = False\n",
    "    for layer in model_fine_tune.layers[131:]:\n",
    "        layer.trainable = True\n",
    "    model = GlobalAveragePooling2D()(model_fine_tune.output)\n",
    "    model=Dense(units=256,activation='relu')(model)\n",
    "    model=Dropout(0.5)(model)\n",
    "    model = Dense(num_class, activation='softmax')(model)\n",
    "    model = Model(model_fine_tune.input, model, name='xception')\n",
    "    opt = keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "    #train model\n",
    "    earlyStopping = kcallbacks.EarlyStopping(\n",
    "        monitor='val_accuracy', patience=3, verbose=1, mode='auto')\t#patience could be tuned by 2 and 3\n",
    "    saveBestModel = kcallbacks.ModelCheckpoint(\n",
    "        filepath=savepath,\n",
    "        monitor='val_accuracy',\n",
    "        verbose=1,\n",
    "        save_best_only=True,\n",
    "        mode='auto')\n",
    "    hist = model.fit(\n",
    "        train_generator,\n",
    "        steps_per_epoch=len(train_generator),\n",
    "        epochs=epochs,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=len(validation_generator),\n",
    "        #use_multiprocessing=True, \n",
    "        callbacks=[earlyStopping, saveBestModel, history],\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\FOCUS\\.conda\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py:374: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "17/17 [==============================] - 15s 647ms/step - loss: 0.5334 - accuracy: 0.8112 - val_loss: 0.1811 - val_accuracy: 0.9112\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.91120, saving model to .\\xception.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\FOCUS\\.conda\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\generic_utils.py:494: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  warnings.warn('Custom mask layers require a config and must override '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/20\n",
      "17/17 [==============================] - 8s 464ms/step - loss: 0.1089 - accuracy: 0.9716 - val_loss: 0.0662 - val_accuracy: 0.9923\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.91120 to 0.99228, saving model to .\\xception.h5\n",
      "Epoch 3/20\n",
      "17/17 [==============================] - 8s 493ms/step - loss: 0.0513 - accuracy: 0.9908 - val_loss: 0.0358 - val_accuracy: 0.9981\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.99228 to 0.99807, saving model to .\\xception.h5\n",
      "Epoch 4/20\n",
      "17/17 [==============================] - 8s 503ms/step - loss: 0.0342 - accuracy: 0.9937 - val_loss: 0.0256 - val_accuracy: 0.9981\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.99807\n",
      "Epoch 5/20\n",
      "17/17 [==============================] - 8s 435ms/step - loss: 0.0246 - accuracy: 0.9957 - val_loss: 0.0184 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00005: val_accuracy improved from 0.99807 to 1.00000, saving model to .\\xception.h5\n",
      "Epoch 6/20\n",
      "17/17 [==============================] - 7s 391ms/step - loss: 0.0178 - accuracy: 0.9986 - val_loss: 0.0153 - val_accuracy: 0.9981\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 1.00000\n",
      "Epoch 7/20\n",
      "17/17 [==============================] - 8s 477ms/step - loss: 0.0135 - accuracy: 0.9976 - val_loss: 0.0119 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 1.00000\n",
      "Epoch 8/20\n",
      "17/17 [==============================] - 7s 420ms/step - loss: 0.0118 - accuracy: 0.9986 - val_loss: 0.0116 - val_accuracy: 0.9981\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 1.00000\n",
      "Epoch 00008: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\FOCUS\\AppData\\Local\\Temp\\ipykernel_24312\\4074440202.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  output_df=output_df.append(result_dict,ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "#default only 50, tf36cnn 99\n",
    "start_time=time.time()\n",
    "xception(num_class=5,epochs=20)\n",
    "end_time=time.time()\n",
    "timelist.append(end_time-start_time)\n",
    "\n",
    "# Insufficient Video Memory 显存不足"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Val-Loss</th>\n",
       "      <th>Val-Accuracy</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.538788</td>\n",
       "      <td>0.823218</td>\n",
       "      <td>0.404459</td>\n",
       "      <td>0.851351</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.024583</td>\n",
       "      <td>0.995665</td>\n",
       "      <td>0.018440</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Loss  Accuracy  Val-Loss  Val-Accuracy Time\n",
       "0  0.538788  0.823218  0.404459      0.851351  NaN\n",
       "1  0.024583  0.995665  0.018440      1.000000  NaN"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timelist\n",
    "output_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validation accuracy of Xception: 100.0%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 3: VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vgg16( num_class, epochs,savepath='./VGG16.h5',history=history_VGG16,input_shape=INPUT_SIZE):\n",
    "    model_fine_tune = VGG16(include_top=False, weights='imagenet', input_shape=input_shape)\n",
    "    for layer in model_fine_tune.layers[:15]:\t#the number of frozen layers for transfer learning, have tuned from 5-18\n",
    "        layer.trainable = False\n",
    "    for layer in model_fine_tune.layers[15:]:\n",
    "        layer.trainable = True\n",
    "    model = GlobalAveragePooling2D()(model_fine_tune.output) #GlobalAveragePooling2D layer to convert the features to a single 1280-element vector per image\n",
    "    model=Dense(units=256,activation='relu')(model)\n",
    "    model=Dropout(0.5)(model)\n",
    "    model = Dense(num_class, activation='softmax')(model)\n",
    "    model = Model(model_fine_tune.input, model, name='vgg')\n",
    "    opt = keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\t#tuned learning rate to be 0.001\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\t#set the loss function to be binary crossentropy\n",
    "    #train model\n",
    "    earlyStopping = kcallbacks.EarlyStopping(\n",
    "        monitor='val_accuracy', patience=2, verbose=1, mode='auto')\t#set early stop patience to save training time\n",
    "    saveBestModel = kcallbacks.ModelCheckpoint(\n",
    "        filepath=savepath,\n",
    "        monitor='val_accuracy',\n",
    "        verbose=1,\n",
    "        save_best_only=True,\n",
    "        mode='auto')\n",
    "    hist = model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=len(train_generator),\n",
    "        epochs=epochs,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=len(validation_generator),\n",
    "        #use_multiprocessing=True, \n",
    "        #workers=2,\n",
    "        callbacks=[earlyStopping, saveBestModel, history],\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\FOCUS\\.conda\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py:374: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\FOCUS\\.conda\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1940: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "17/17 [==============================] - 9s 443ms/step - loss: 1.1853 - accuracy: 0.5679 - val_loss: 0.5329 - val_accuracy: 0.7336\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.73359, saving model to .\\VGG16.h5\n",
      "Epoch 2/20\n",
      "17/17 [==============================] - 8s 501ms/step - loss: 0.3745 - accuracy: 0.8261 - val_loss: 0.3549 - val_accuracy: 0.8514\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.73359 to 0.85135, saving model to .\\VGG16.h5\n",
      "Epoch 3/20\n",
      "17/17 [==============================] - 8s 473ms/step - loss: 0.2581 - accuracy: 0.8897 - val_loss: 0.1797 - val_accuracy: 0.9247\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.85135 to 0.92471, saving model to .\\VGG16.h5\n",
      "Epoch 4/20\n",
      "17/17 [==============================] - 6s 379ms/step - loss: 0.1340 - accuracy: 0.9359 - val_loss: 0.0899 - val_accuracy: 0.9363\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.92471 to 0.93629, saving model to .\\VGG16.h5\n",
      "Epoch 5/20\n",
      "17/17 [==============================] - 7s 413ms/step - loss: 0.0679 - accuracy: 0.9687 - val_loss: 0.0165 - val_accuracy: 0.9981\n",
      "\n",
      "Epoch 00005: val_accuracy improved from 0.93629 to 0.99807, saving model to .\\VGG16.h5\n",
      "Epoch 6/20\n",
      "17/17 [==============================] - 6s 378ms/step - loss: 0.0109 - accuracy: 0.9990 - val_loss: 0.0250 - val_accuracy: 0.9884\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.99807\n",
      "Epoch 7/20\n",
      "17/17 [==============================] - 6s 341ms/step - loss: 0.0476 - accuracy: 0.9851 - val_loss: 0.0128 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00007: val_accuracy improved from 0.99807 to 1.00000, saving model to .\\VGG16.h5\n",
      "Epoch 8/20\n",
      "17/17 [==============================] - 10s 588ms/step - loss: 0.0108 - accuracy: 0.9966 - val_loss: 1.7643e-04 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 1.00000\n",
      "Epoch 9/20\n",
      "17/17 [==============================] - 10s 548ms/step - loss: 0.0549 - accuracy: 0.9875 - val_loss: 4.6317 - val_accuracy: 0.7432\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 1.00000\n",
      "Epoch 00009: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\FOCUS\\AppData\\Local\\Temp\\ipykernel_24312\\4074440202.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  output_df=output_df.append(result_dict,ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "start_time=time.time()\n",
    "vgg16(num_class=5,epochs=20)\t#tf36cnn\n",
    "end_time=time.time()\n",
    "timelist.append(end_time-start_time)\n",
    "# Insufficient Video Memory 显存不足"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Validation accuracy of VGG16: 100.0%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 4: VGG19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vgg19( num_class, epochs,savepath='./VGG19.h5',history=history_VGG19,input_shape=INPUT_SIZE):\n",
    "    model_fine_tune = VGG19(include_top=False, weights='imagenet', input_shape=input_shape)\n",
    "    for layer in model_fine_tune.layers[:19]:\t#the number of frozen layers for transfer learning, have tuned from 5-18\n",
    "        layer.trainable = False\n",
    "    for layer in model_fine_tune.layers[19:]:\n",
    "        layer.trainable = True\n",
    "    model = GlobalAveragePooling2D()(model_fine_tune.output)\n",
    "    model=Dense(units=256,activation='relu')(model)\n",
    "    model=Dropout(0.5)(model)\n",
    "    model = Dense(num_class, activation='softmax')(model)\n",
    "    model = Model(model_fine_tune.input, model, name='vgg')\n",
    "    opt = keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\t#tuned learning rate to be 0.001\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\t#set the loss function to be binary crossentropy\n",
    "    #train model\n",
    "    earlyStopping = kcallbacks.EarlyStopping(\n",
    "        monitor='val_accuracy', patience=2, verbose=1, mode='auto')\t#set early stop patience to save training time\n",
    "    saveBestModel = kcallbacks.ModelCheckpoint(\n",
    "        filepath=savepath,\n",
    "        monitor='val_accuracy',\n",
    "        verbose=1,\n",
    "        save_best_only=True,\n",
    "        mode='auto')\n",
    "    hist = model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=len(train_generator),\n",
    "        epochs=epochs,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=len(validation_generator),\n",
    "        #use_multiprocessing=True, \n",
    "        #workers=2,\n",
    "        callbacks=[earlyStopping, saveBestModel, history],\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\FOCUS\\.conda\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py:374: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\FOCUS\\.conda\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1940: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "17/17 [==============================] - 8s 451ms/step - loss: 0.6981 - accuracy: 0.7567 - val_loss: 0.2374 - val_accuracy: 0.9151\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.91506, saving model to .\\VGG19.h5\n",
      "Epoch 2/20\n",
      "17/17 [==============================] - 8s 459ms/step - loss: 0.1326 - accuracy: 0.9509 - val_loss: 0.0310 - val_accuracy: 0.9923\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.91506 to 0.99228, saving model to .\\VGG19.h5\n",
      "Epoch 3/20\n",
      "17/17 [==============================] - 8s 488ms/step - loss: 0.0163 - accuracy: 0.9966 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.99228 to 1.00000, saving model to .\\VGG19.h5\n",
      "Epoch 4/20\n",
      "17/17 [==============================] - 7s 433ms/step - loss: 0.0117 - accuracy: 0.9952 - val_loss: 0.0114 - val_accuracy: 0.9961\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 1.00000\n",
      "Epoch 5/20\n",
      "17/17 [==============================] - 9s 538ms/step - loss: 0.0074 - accuracy: 0.9976 - val_loss: 0.0039 - val_accuracy: 0.9981\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 1.00000\n",
      "Epoch 00005: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\FOCUS\\AppData\\Local\\Temp\\ipykernel_24312\\4074440202.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  output_df=output_df.append(result_dict,ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "start_time=time.time()\n",
    "vgg19(num_class=5,epochs=20)\t#binary classificaiton\n",
    "\n",
    "end_time=time.time()\n",
    "timelist.append(end_time-start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Validation accuracy of VGG19: 100.0%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 5: ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resnet( num_class, epochs,savepath='./resnet.h5',history=history_Resnet,input_shape=INPUT_SIZE):\n",
    "    model_fine_tune = ResNet50(include_top=False, weights='imagenet', input_shape=input_shape)\n",
    "    for layer in model_fine_tune.layers[:120]:\t#the number of frozen layers for transfer learning, have tuned from 50-150\n",
    "        layer.trainable = False\n",
    "    for layer in model_fine_tune.layers[120:]:\t#the number of trainable layers for transfer learning\n",
    "        layer.trainable = True\n",
    "    model = GlobalAveragePooling2D()(model_fine_tune.output)\n",
    "    model=Dense(units=256,activation='relu')(model)\n",
    "    model=Dropout(0.5)(model)\n",
    "    model = Dense(num_class, activation='softmax')(model)\n",
    "    model = Model(model_fine_tune.input, model, name='resnet')\n",
    "    opt = keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\t#tuned learning rate to be 0.001\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy']) #set the loss function to be binary crossentropy\n",
    "    #train model\n",
    "    earlyStopping = kcallbacks.EarlyStopping(\n",
    "        monitor='val_accuracy', patience=2, verbose=1, mode='auto')\t#set early stop patience to save training time\n",
    "    saveBestModel = kcallbacks.ModelCheckpoint(\n",
    "        filepath=savepath,\n",
    "        monitor='val_accuracy',\n",
    "        verbose=1,\n",
    "        save_best_only=True,\n",
    "        mode='auto')\n",
    "    hist = model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=len(train_generator),\n",
    "        epochs=epochs,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=len(validation_generator),\n",
    "        #use_multiprocessing=True, \n",
    "        callbacks=[earlyStopping, saveBestModel, history],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\FOCUS\\.conda\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py:374: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\FOCUS\\.conda\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1940: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "17/17 [==============================] - 15s 552ms/step - loss: 0.5916 - accuracy: 0.7962 - val_loss: 27.8509 - val_accuracy: 0.6293\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.62934, saving model to .\\resnet.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\FOCUS\\.conda\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\generic_utils.py:494: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  warnings.warn('Custom mask layers require a config and must override '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/20\n",
      "17/17 [==============================] - 8s 491ms/step - loss: 0.1762 - accuracy: 0.9340 - val_loss: 375.7351 - val_accuracy: 0.6293\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.62934\n",
      "Epoch 3/20\n",
      "17/17 [==============================] - 8s 477ms/step - loss: 0.0571 - accuracy: 0.9831 - val_loss: 219.4151 - val_accuracy: 0.6293\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.62934\n",
      "Epoch 00003: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\FOCUS\\AppData\\Local\\Temp\\ipykernel_24312\\4074440202.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  output_df=output_df.append(result_dict,ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "start_time=time.time()\n",
    "resnet(num_class=5,epochs=20)\t#binary classificaiton\n",
    "end_time=time.time()\n",
    "timelist.append(end_time-start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validation accuracy of Resnet: 98.652%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 6: Inception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inception( num_class, epochs,savepath='./inception.h5',history=history_Inception,input_shape=INPUT_SIZE):\n",
    "    model_fine_tune = InceptionV3(include_top=False, weights='imagenet', input_shape=input_shape)\n",
    "    for layer in model_fine_tune.layers[:35]:\t#the number of frozen layers for transfer learning, have tuned from 50-150\n",
    "        layer.trainable = False\n",
    "    for layer in model_fine_tune.layers[35:]:\t#the number of trainable layers for transfer learning\n",
    "        layer.trainable = True\n",
    "    model = GlobalAveragePooling2D()(model_fine_tune.output)\n",
    "    model=Dense(units=256,activation='relu')(model)\n",
    "    model=Dropout(0.5)(model)\n",
    "    model = Dense(num_class, activation='softmax')(model)\n",
    "    model = Model(model_fine_tune.input, model, name='resnet')\n",
    "    opt = keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\t#tuned learning rate to be 0.001\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy']) #set the loss function to be binary crossentropy\n",
    "    #train model\n",
    "    earlyStopping = kcallbacks.EarlyStopping(\n",
    "        monitor='val_accuracy', patience=2, verbose=1, mode='auto')\t#set early stop patience to save training time\n",
    "    saveBestModel = kcallbacks.ModelCheckpoint(\n",
    "        filepath=savepath,\n",
    "        monitor='val_accuracy',\n",
    "        verbose=1,\n",
    "        save_best_only=True,\n",
    "        mode='auto')\n",
    "    hist = model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=len(train_generator),\n",
    "        epochs=epochs,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=len(validation_generator),\n",
    "        #use_multiprocessing=True, \n",
    "        callbacks=[earlyStopping, saveBestModel, history],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\FOCUS\\.conda\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py:374: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\FOCUS\\.conda\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1940: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "17/17 [==============================] - 20s 647ms/step - loss: 0.2157 - accuracy: 0.9181 - val_loss: 93.6425 - val_accuracy: 0.1178\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.11776, saving model to .\\inception.h5\n",
      "Epoch 2/20\n",
      "17/17 [==============================] - 7s 417ms/step - loss: 0.0054 - accuracy: 0.9990 - val_loss: 20.8857 - val_accuracy: 0.1178\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.11776\n",
      "Epoch 3/20\n",
      "17/17 [==============================] - 7s 431ms/step - loss: 0.0306 - accuracy: 0.9933 - val_loss: 648.3719 - val_accuracy: 0.0927\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.11776\n",
      "Epoch 00003: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\FOCUS\\AppData\\Local\\Temp\\ipykernel_24312\\4074440202.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  output_df=output_df.append(result_dict,ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "start_time=time.time()\n",
    "inception(num_class=5,epochs=20)\t#binary classificaiton\n",
    "\n",
    "end_time=time.time()\n",
    "timelist.append(end_time-start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validation accuracy of Inception: 100.0%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 7: InceptionResnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inceptionresnet( num_class, epochs,savepath='./inceptionresnet.h5',history=history_InceptionResnet,input_shape=INPUT_SIZE):\n",
    "    model_fine_tune = InceptionResNetV2(include_top=False, weights='imagenet', input_shape=input_shape)\n",
    "    for layer in model_fine_tune.layers[:500]:\t#the number of frozen layers for transfer learning, have tuned from 400-550\n",
    "        layer.trainable = False\n",
    "    for layer in model_fine_tune.layers[500:]:\t#the number of trainable layers for transfer learning\n",
    "        layer.trainable = True\n",
    "    model = GlobalAveragePooling2D()(model_fine_tune.output)\n",
    "    model=Dense(units=256,activation='relu')(model)\n",
    "    model=Dropout(0.5)(model)\n",
    "    model = Dense(num_class, activation='softmax')(model)\n",
    "    model = Model(model_fine_tune.input, model, name='resnet')\n",
    "    opt = keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\t#tuned learning rate to be 0.001\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy']) #set the loss function to be binary crossentropy\n",
    "    #train model\n",
    "    earlyStopping = kcallbacks.EarlyStopping(\n",
    "        monitor='val_accuracy', patience=2, verbose=1, mode='auto')\t#set early stop patience to save training time\n",
    "    saveBestModel = kcallbacks.ModelCheckpoint(\n",
    "        filepath=savepath,\n",
    "        monitor='val_accuracy',\n",
    "        verbose=1,\n",
    "        save_best_only=True,\n",
    "        mode='auto')\n",
    "    hist = model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=len(train_generator),\n",
    "        epochs=epochs,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=len(validation_generator),\n",
    "        #use_multiprocessing=True, \n",
    "        callbacks=[earlyStopping, saveBestModel, history],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\FOCUS\\.conda\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py:374: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\FOCUS\\.conda\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1940: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "17/17 [==============================] - 29s 726ms/step - loss: 0.2587 - accuracy: 0.8979 - val_loss: 16.7388 - val_accuracy: 0.1178\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.11776, saving model to .\\inceptionresnet.h5\n",
      "Epoch 2/20\n",
      "17/17 [==============================] - 7s 397ms/step - loss: 0.0456 - accuracy: 0.9880 - val_loss: 2046.1426 - val_accuracy: 0.1178\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.11776\n",
      "Epoch 3/20\n",
      "17/17 [==============================] - 7s 413ms/step - loss: 0.0382 - accuracy: 0.9913 - val_loss: 412.5530 - val_accuracy: 0.1178\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.11776\n",
      "Epoch 00003: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\FOCUS\\AppData\\Local\\Temp\\ipykernel_24312\\4074440202.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  output_df=output_df.append(result_dict,ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "start_time=time.time()\n",
    "inceptionresnet(num_class=5,epochs=20)\t# 5-class classificaiton\n",
    "end_time=time.time()\n",
    "timelist.append(end_time-start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Val-Loss</th>\n",
       "      <th>Val-Accuracy</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CNN</th>\n",
       "      <td>0.538788</td>\n",
       "      <td>0.823218</td>\n",
       "      <td>0.404459</td>\n",
       "      <td>0.851351</td>\n",
       "      <td>62.872529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Xception</th>\n",
       "      <td>0.024583</td>\n",
       "      <td>0.995665</td>\n",
       "      <td>0.018440</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>72.575298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VGG16</th>\n",
       "      <td>0.047557</td>\n",
       "      <td>0.985067</td>\n",
       "      <td>0.012819</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>72.610340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VGG19</th>\n",
       "      <td>0.016341</td>\n",
       "      <td>0.996628</td>\n",
       "      <td>0.001514</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>42.434800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Resnet</th>\n",
       "      <td>0.591554</td>\n",
       "      <td>0.796243</td>\n",
       "      <td>27.850935</td>\n",
       "      <td>0.629344</td>\n",
       "      <td>34.710129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Inception</th>\n",
       "      <td>0.215743</td>\n",
       "      <td>0.918112</td>\n",
       "      <td>93.642540</td>\n",
       "      <td>0.117761</td>\n",
       "      <td>38.585505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>InceptionResnet</th>\n",
       "      <td>0.258689</td>\n",
       "      <td>0.897880</td>\n",
       "      <td>16.738848</td>\n",
       "      <td>0.117761</td>\n",
       "      <td>53.245782</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Loss  Accuracy   Val-Loss  Val-Accuracy       Time\n",
       "CNN              0.538788  0.823218   0.404459      0.851351  62.872529\n",
       "Xception         0.024583  0.995665   0.018440      1.000000  72.575298\n",
       "VGG16            0.047557  0.985067   0.012819      1.000000  72.610340\n",
       "VGG19            0.016341  0.996628   0.001514      1.000000  42.434800\n",
       "Resnet           0.591554  0.796243  27.850935      0.629344  34.710129\n",
       "Inception        0.215743  0.918112  93.642540      0.117761  38.585505\n",
       "InceptionResnet  0.258689  0.897880  16.738848      0.117761  53.245782"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_df.index=output_index\n",
    "output_df['Time']=timelist\n",
    "output_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Validation accuracy of InceptionResnet: 99.993%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Optimization \n",
    "Use VGG16 as an example.  \n",
    "\n",
    "Tuned hyperparameters of CNN: \n",
    "1. The number of frozen layers\n",
    "2. The number of epochs\n",
    "3. Early stop patience\n",
    "4. Learning rate\n",
    "5. Dropout rate\n",
    "\n",
    "Hyperparameter optimization methods:\n",
    "1. Random search\n",
    "2. Bayesian optimization - Tree Parzen Estimator(BO-TPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def vgg16( num_class,epochs=20,frozen=15,lr=0.001,patience=2, dropout_rate=0.5,verbose=0, savepath='./VGG16.h5',history=history_VGG16,input_shape=INPUT_SIZE):\n",
    "#     model_fine_tune = VGG16(include_top=False, weights='imagenet', input_shape=input_shape)\n",
    "#     for layer in model_fine_tune.layers[:frozen]:\t#the number of frozen layers for transfer learning, have tuned from 5-18\n",
    "#         layer.trainable = False\n",
    "#     for layer in model_fine_tune.layers[frozen:]:\n",
    "#         layer.trainable = True\n",
    "#     model = GlobalAveragePooling2D()(model_fine_tune.output)\n",
    "#     model=Dense(units=256,activation='relu')(model)\n",
    "#     model=Dropout(dropout_rate)(model)\n",
    "#     model = Dense(num_class, activation='softmax')(model)\n",
    "#     model = Model(model_fine_tune.input, model, name='vgg')\n",
    "#     opt = keras.optimizers.Adam(lr=lr, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\t#tuned learning rate to be 0.001\n",
    "#     model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\t#set the loss function to be binary crossentropy\n",
    "#     #train model\n",
    "#     earlyStopping = kcallbacks.EarlyStopping(\n",
    "#         monitor='val_accuracy', patience=patience, verbose=verbose, mode='auto')\t#set early stop patience to save training time\n",
    "#     saveBestModel = kcallbacks.ModelCheckpoint(\n",
    "#         filepath=savepath,\n",
    "#         monitor='val_accuracy',\n",
    "#         verbose=verbose,\n",
    "#         save_best_only=True,\n",
    "#         mode='auto')\n",
    "#     hist = model.fit_generator(\n",
    "#         train_generator,\n",
    "#         steps_per_epoch=len(train_generator),\n",
    "#         epochs=epochs,\n",
    "#         validation_data=validation_generator,\n",
    "#         validation_steps=len(validation_generator),\n",
    "#         #use_multiprocessing=True, \n",
    "#         #workers=2,\n",
    "#         callbacks=[earlyStopping, saveBestModel, history],\n",
    "#         verbose = verbose\n",
    "#     )\n",
    "#     return hist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def prediction(vgg_model):\n",
    "# #read images from validation folder\n",
    "#     rootdir = './test_224/'\n",
    "#     test_laels = []\n",
    "#     test_images=[]\n",
    "#     for subdir, dirs, files in os.walk(rootdir):\n",
    "#         for file in files:\n",
    "#             if not (file.endswith(\".jpeg\"))|(file.endswith(\".jpg\"))|(file.endswith(\".png\")):\n",
    "#                 continue\n",
    "#             test_laels.append(subdir.split('/')[-1])\n",
    "#             test_images.append(os.path.join(subdir, file))\n",
    "\n",
    "#     predict=[]\n",
    "#     length=len(test_images)\n",
    "#     label=validation_generator.class_indices\n",
    "#     label={v: k for k, v in label.items()}\n",
    "#     for i in range(length):\n",
    "#         inputimg=test_images[i]\n",
    "#         test_batch=[]\n",
    "#         thisimg=np.array(Image.open(inputimg))/255 #read all the images in validation set\n",
    "#         #print(thisimg)\n",
    "#         test_shape=(1,)+thisimg.shape\n",
    "#         thisimg=thisimg.reshape(test_shape)\n",
    "#         vgg_model_batch=vgg_model.predict(thisimg) #use master model to process the input image\n",
    "#         #generate result by model 1\n",
    "#         prob=vgg_model_batch[0,np.argmax(vgg_model_batch,axis=1)[0]]\n",
    "#         res=label[np.argmax(vgg_model_batch,axis=1)[0]]\n",
    "#         predict.append(res)\n",
    "#     acc=accuracy_score(test_laels,predict)\n",
    "#     return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #define the objective function to be optimized\n",
    "# import time\n",
    "# from hyperopt import hp, fmin, tpe, rand, STATUS_OK, Trials\n",
    "# import matplotlib.pyplot as plt\n",
    "# import statistics \n",
    "\n",
    "# def objective(params):\n",
    "    \n",
    "#     params = {\n",
    "#         'frozen': int(params['frozen']),\n",
    "#         'epochs': int(params['epochs']),\n",
    "#         'patience': int(params['patience']),\n",
    "#         'lr': abs(float(params['lr'])),\n",
    "#         'dropout_rate': abs(float(params['dropout_rate'])),\n",
    "#     }\n",
    "#     frozen=params['frozen']\n",
    "#     epochs=params['epochs']\n",
    "#     patience=params['patience']\n",
    "#     lr=params['lr']\n",
    "#     dropout_rate=params['dropout_rate']\n",
    "\n",
    "#     vgg16(num_class=5, frozen=frozen,epochs=epochs,patience=patience, lr=lr, dropout_rate=dropout_rate)\n",
    "\n",
    "#     acc=prediction(vgg_model=load_model('./VGG16.h5'))\n",
    "\n",
    "#     print('accuracy:%s'%acc)\n",
    "#     return {'loss': -acc, 'status': STATUS_OK }\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Hyperparameter optimization by Bayesian optimization - Tree Parzen Estimator\n",
    "# space = {\n",
    "#     'frozen': hp.quniform('frozen', 15, 18, 1),\n",
    "#     'epochs': hp.quniform('epochs', 5, 21, 5),\n",
    "#     'patience': hp.quniform('patience', 2, 4, 1),\n",
    "#     'lr': hp.quniform('lr', 0.001, 0.006, 0.001),\n",
    "#     'dropout_rate': hp.quniform('dropout_rate', 0.3, 0.6, 0.1),\n",
    "# }\n",
    "\n",
    "# t1=time.time()\n",
    "# best = fmin(fn=objective,\n",
    "#             space=space,\n",
    "#             algo=tpe.suggest,\n",
    "#             max_evals=10)\n",
    "# print(\"Hyperopt estimated optimum {}\".format(best))\n",
    "# t2=time.time()\n",
    "# print(\"Time: \"+str(t2-t1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Hyperparameter optimization by Random search\n",
    "# space = {\n",
    "#     'frozen': hp.quniform('frozen', 15, 18, 1),\n",
    "#     'epochs': hp.quniform('epochs', 5, 21, 5),\n",
    "#     'patience': hp.quniform('patience', 2, 4, 1),\n",
    "#     'lr': hp.quniform('lr', 0.001, 0.006, 0.001),\n",
    "#     'dropout_rate': hp.quniform('dropout_rate', 0.3, 0.6, 0.1),\n",
    "# }\n",
    "\n",
    "# t1=time.time()\n",
    "# best = fmin(fn=objective,\n",
    "#             space=space,\n",
    "#             algo=rand.suggest,\n",
    "#             max_evals=10)\n",
    "# print(\"Hyperopt estimated optimum {}\".format(best))\n",
    "# t2=time.time()\n",
    "# print(\"Time: \"+str(t2-t1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Retrain the model by using the best hyperparameter values to obtain the best model\n",
    "# vgg16(num_class=5, frozen=18,epochs=15,patience=3, lr=0.002, dropout_rate=0.5,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Save the result to file\n",
    "import datetime\n",
    "output_df.to_excel('result-{}.xlsx'.format(datetime.datetime.now().strftime('%y%m%d-%H%M%S')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "tf2",
   "language": "python",
   "name": "tf2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "bc342a2d18cd8de928dda5685bacff2bb239146e0847e732d8a85b5d43ec132e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
