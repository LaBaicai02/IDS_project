{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Transfer Learning and Optimized CNN Based Intrusion Detection System for Internet of Vehicles \n",
    "This is the code for the paper entitled \"**A Transfer Learning and Optimized CNN Based Intrusion Detection System for Internet of Vehicles**\" accepted in IEEE International Conference on Communications (IEEE ICC).  \n",
    "Authors: Li Yang (lyang339@uwo.ca) and Abdallah Shami (Abdallah.Shami@uwo.ca)  \n",
    "Organization: The Optimized Computing and Communications (OC2) Lab, ECE Department, Western University\n",
    "\n",
    "**Notebook 2: CNN Model Development**  \n",
    "Aims:  \n",
    "&nbsp; 1): Generate training and test images  \n",
    "&nbsp; 2): Construct CNN models (a CNN model by own, Xception, VGG16, VGG19, Resnet, Inception, InceptionResnet)  \n",
    "&nbsp; 3): Tune the hyperparameters of CNN models (hyperparameter optimization)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score,precision_score,recall_score,f1_score,precision_recall_fscore_support\n",
    "from tensorflow.keras.applications.inception_resnet_v2 import InceptionResNetV2\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "from tensorflow.keras.applications.mobilenet import MobileNet\n",
    "from tensorflow.keras.applications.resnet50 import  ResNet50\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.applications.vgg19 import VGG19\n",
    "from tensorflow.keras.applications.xception import  Xception\n",
    "from tensorflow.keras.layers import Dense,Flatten,GlobalAveragePooling2D,Input,Conv2D,MaxPooling2D,Dropout\n",
    "from tensorflow.keras.models import Model,load_model,Sequential\n",
    "from tensorflow.keras.preprocessing.image import  ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing.image import load_img,img_to_array\n",
    "from tensorflow.keras.utils import plot_model\n",
    "import datetime\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "import seaborn as sns\n",
    "import sklearn.metrics as metrics\n",
    "import tensorflow.keras as keras\n",
    "import tensorflow.keras.callbacks as kcallbacks\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Training and Test Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5588 images belonging to 10 classes.\n",
      "Found 1396 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "#generate training and test images\n",
    "TARGET_SIZE=(224,224)\n",
    "INPUT_SIZE=(224,224,3)\n",
    "BATCHSIZE=128\t#could try 128 or 32\n",
    "\n",
    "train_rootdir = './train_224/'\n",
    "test_rootdir = './test_224/'\n",
    "\n",
    "#Normalization\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        train_rootdir,\n",
    "        target_size=TARGET_SIZE,\n",
    "        batch_size=BATCHSIZE,\n",
    "        class_mode='categorical')\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        test_rootdir,\n",
    "        target_size=TARGET_SIZE,\n",
    "        batch_size=BATCHSIZE,\n",
    "        class_mode='categorical')\n",
    "num_class = train_generator.num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels = []\n",
    "test_images=[]\n",
    "for subdir, dirs, files in os.walk(test_rootdir):\n",
    "    for file in files:\n",
    "        if not (file.endswith(\".jpeg\"))|(file.endswith(\".jpg\"))|(file.endswith(\".png\")):\n",
    "            continue\n",
    "        test_labels.append(subdir.split('/')[-1])\n",
    "        test_images.append(os.path.join(subdir, file))\n",
    "\n",
    "label=validation_generator.class_indices\n",
    "label={v: k for k, v in label.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the output dir\n",
    "output_dir = 'output/CNN_based/2-output-{}'.format(datetime.datetime.now().strftime('%y%m%d-%H%M%S'))\n",
    "img_dir = os.path.join(output_dir, 'img')\n",
    "os.makedirs(img_dir)\n",
    "# Prepare the log file\n",
    "log_file = open(os.path.join(output_dir, 'classification_report-{}'.format(datetime.datetime.now().strftime('%y%m%d-%H%M%S'))), 'w+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prediction(model, test_images=test_images, label=label, batch_size=BATCHSIZE, verbose='auto'):\n",
    "    predict=[]\n",
    "    length=len(test_images)\n",
    "    for i in range(((length-1)//batch_size)+1):\n",
    "        inputimg=test_images[batch_size*i:batch_size*(i+1)]\n",
    "        test_batch=[]\n",
    "        for path in inputimg:\n",
    "            thisimg=np.array(Image.open(path))/255\n",
    "            test_batch.append(thisimg)\n",
    "        # thisimg=np.array(Image.open(inputimg))/255 #read all the images in validation set\n",
    "        #print(thisimg)\n",
    "        # test_shape=(1,)+thisimg.shape\n",
    "        # thisimg=thisimg.reshape(test_shape)\n",
    "        model_batch=model.predict(np.array(test_batch), verbose=verbose) #use master model to process the input image\n",
    "        #generate result by model 1\n",
    "        # prob=model_batch[0,np.argmax(model_batch,axis=1)[0]]\n",
    "        predict_batch=list(np.argmax(model_batch,axis=1))\n",
    "        predict_batch=[label[con] for con in predict_batch]\n",
    "        predict.extend(predict_batch)\n",
    "    return predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the image plotting functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot the figures\n",
    "#when extra_data enabled please put this callback before early_stopping in case of any problem\n",
    "class LossHistory(keras.callbacks.Callback):\n",
    "    def __init__(self, need_extra_data:bool=True, test_images=test_images, test_labels=test_labels, label=label):\n",
    "        # Enable the recording of precision, recall, f1-score, prediction time (only epoch-wise)\n",
    "        self.extra_data = need_extra_data\n",
    "        if need_extra_data:\n",
    "            self.test_images = test_images\n",
    "            self.test_labels = test_labels\n",
    "            self.label = label\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.losses = {'batch':[], 'epoch':[]}\n",
    "        self.accuracy = {'batch':[], 'epoch':[]}\n",
    "        self.val_loss = {'batch':[], 'epoch':[]}\n",
    "        self.val_accuracy = {'batch':[], 'epoch':[]}\n",
    "        # need extra data --> reset recording list\n",
    "        # These matrics only make sense over the entire epoch\n",
    "        if self.extra_data:\n",
    "            self.precision = []\n",
    "            self.recall = []\n",
    "            self.f1_score = []\n",
    "            self.predict_time = []\n",
    "            # Record prediction -> for generating report\n",
    "            self.prediction = []\n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        self.losses['batch'].append(logs.get('loss'))\n",
    "        self.accuracy['batch'].append(logs.get('accuracy'))\n",
    "        self.val_loss['batch'].append(logs.get('val_loss'))\n",
    "        self.val_accuracy['batch'].append(logs.get('val_accuracy'))\n",
    "    def on_epoch_end(self, batch, logs={}):\n",
    "        self.losses['epoch'].append(logs.get('loss'))\n",
    "        self.accuracy['epoch'].append(logs.get('accuracy'))\n",
    "        self.val_loss['epoch'].append(logs.get('val_loss'))\n",
    "        self.val_accuracy['epoch'].append(logs.get('val_accuracy'))\n",
    "        # need extra data --> calculate and record\n",
    "        if self.extra_data:\n",
    "            # Get prediciton\n",
    "            temp = self.model.stop_training\n",
    "            start_time = time.time()\n",
    "            y_pred = get_prediction(model=self.model, test_images=self.test_images, label=self.label, verbose='auto')\n",
    "            end_time = time.time()\n",
    "            self.model.stop_training = temp\n",
    "            # Calculate extra data\n",
    "            precision,recall,fscore,_= precision_recall_fscore_support(self.test_labels, y_pred, average='weighted', zero_division=0)\n",
    "            # Record\n",
    "            self.precision.append(precision)\n",
    "            self.recall.append(recall)\n",
    "            self.f1_score.append(fscore)\n",
    "            self.predict_time.append((end_time-start_time)/len(y_pred))\n",
    "            # Save prediction\n",
    "            self.prediction.append(y_pred)\n",
    "    def loss_plot(self, loss_type):\n",
    "        iters = range(len(self.losses[loss_type]))\n",
    "        plt.figure()\n",
    "        # plt.plot(iters, self.losses[loss_type], 'g', label='train loss')\n",
    "        if loss_type == 'epoch':\n",
    "            # acc\n",
    "            plt.plot(iters, self.accuracy[loss_type], 'r', label='train acc')\n",
    "            # loss\n",
    "            plt.plot(iters, self.losses[loss_type], 'g', label='train loss')\n",
    "            # val_acc\n",
    "            plt.plot(iters, self.val_accuracy[loss_type], 'b', label='val acc')\n",
    "            # val_loss\n",
    "            plt.plot(iters, self.val_loss[loss_type], 'k', label='val loss')\n",
    "        else:\n",
    "            plt.plot(iters, self.losses[loss_type], 'g', label='train loss')\n",
    "        plt.grid(True)\n",
    "        plt.xlabel(loss_type)\n",
    "        plt.ylabel('acc-loss')\n",
    "        plt.legend(loc=\"upper right\")\n",
    "        plt.show()\n",
    "    def get_best(self, target_type:str='epoch', need_extra_data:bool=True):\n",
    "        # Get the index of the best record\n",
    "        max_index = self.accuracy[target_type].index(max(self.accuracy[target_type]))\n",
    "        # Return the accuracy, loss, val_acc, val_loss of the best record\n",
    "        temp={\n",
    "            'accuracy': self.accuracy[target_type][max_index], \n",
    "            'loss': self.losses[target_type][max_index], \n",
    "            'val_accuracy': self.val_accuracy[target_type][max_index], \n",
    "            'val_loss': self.val_loss[target_type][max_index]\n",
    "            }\n",
    "        # Add extra data if needed and available\n",
    "        if self.extra_data and need_extra_data and target_type=='epoch':\n",
    "            temp['precision']=self.precision[max_index]\n",
    "            temp['recall']=self.recall[max_index]\n",
    "            temp['f1-score']=self.f1_score[max_index]\n",
    "            temp['predict_time_per_image']=self.predict_time[max_index]\n",
    "        return temp\n",
    "    def generate_report(self, name:str, img_dir=img_dir, log_file=log_file, epoch='best', figsize=(18,14), log_classification_report:bool=True, save_img:bool=True, print_classifiaction_report:bool=True, display_confusion_matrix:bool=True):\n",
    "        if not self.extra_data:\n",
    "            raise Exception('Prediction record unavailable')\n",
    "        # Get prediction\n",
    "        if epoch=='best': epoch=self.accuracy['epoch'].index(max(self.accuracy['epoch']))\n",
    "        elif epoch=='worst': epoch=self.accuracy['epoch'].index(min(self.accuracy['epoch']))\n",
    "        else: epoch-=1\n",
    "        y_pred = self.prediction[epoch]\n",
    "        # Generate classification report\n",
    "        report_str = classification_report(self.test_labels,y_pred,zero_division=0)\n",
    "        if log_classification_report and log_file.writable(): log_file.write('******{}******\\n'.format(name)+report_str+'\\n')\n",
    "        if print_classifiaction_report: print(report_str)\n",
    "        # Generate confusion matrix\n",
    "        cm=confusion_matrix(self.test_labels,y_pred)\n",
    "        f,ax=plt.subplots(figsize=figsize)\n",
    "        sns.heatmap(cm,annot=True,linewidth=0.5,linecolor=\"red\",fmt=\".0f\",ax=ax)\n",
    "        ax.set_xticklabels(self.label.values())\n",
    "        ax.set_yticklabels(self.label.values())\n",
    "        plt.xlabel(\"y_pred\")\n",
    "        plt.ylabel(\"y_true\")\n",
    "        if save_img: plt.savefig(os.path.join(img_dir, '{}.pdf'.format(name)))\n",
    "        if display_confusion_matrix: plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "history_this = LossHistory(need_extra_data=True)\n",
    "history_hpo = LossHistory(need_extra_data=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the processing time measurement functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Measure the running time of model training\n",
    "class TimeMeasurement(keras.callbacks.Callback):\n",
    "    def __init__(self):\n",
    "        self.start_time=None\n",
    "        self.stop_time=None\n",
    "    # Start timing when trainning starts\n",
    "    def on_train_begin(self, logs=None):\n",
    "        self.start_time=time.time()\n",
    "        self.stop_time=None\n",
    "    # Stop timing when trainning ends\n",
    "    def on_train_end(self, logs=None):\n",
    "        self.stop_time=time.time()\n",
    "        if self.start_time is None: print(\"Time Measuring Failed\")\n",
    "    # Get processing time\n",
    "    def get_processing_time(self):\n",
    "        if (self.start_time is None or self.stop_time is None): raise Exception(\"Wrong Time Measurement\")\n",
    "        else: return self.stop_time-self.start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "timer = TimeMeasurement()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the output sheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class output_sheet:\n",
    "    def __init__(self, columns:list=['accuracy', 'loss', 'val_accuracy', 'val_loss', 'precision', 'recall', 'f1-score', 'hpo_time', 'train_time', 'predict_time_per_image']):\n",
    "        self.output_df = pd.DataFrame(columns=columns)\n",
    "        # self.output_index = list()\n",
    "    def add(self, item:str, **values:dict):\n",
    "        # self.output_df = self.output_df.append(values, ignore_index=True)\n",
    "        temp = pd.DataFrame(values, columns=self.output_df.columns.to_list(), index=[item])\n",
    "        self.output_df = pd.concat([self.output_df, temp], axis=0)\n",
    "        # self.output_index.append(item)\n",
    "    # def apply_index(self):\n",
    "    #     self.output_df.index = self.output_index\n",
    "    def to_excel(self, path=None):\n",
    "        if path is None: path=os.path.join(output_dir, '2-result-{}.xlsx'.format(datetime.datetime.now().strftime('%y%m%d-%H%M%S')))\n",
    "        # self.apply_index()\n",
    "        self.output_df.to_excel(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = output_sheet(columns=['accuracy', 'loss', 'val_accuracy', 'val_loss', 'precision', 'recall', 'f1-score', 'hpo_time', 'train_time', 'predict_time_per_image'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construct CNN models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1: a CNN model by own (baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_by_own(input_shape,num_class,epochs,savepath='./model_own.h5',history=history_this,timer=timer):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(64,(3,3),strides=(1,1),input_shape=input_shape,padding='same',activation='relu',kernel_initializer='glorot_uniform'))\n",
    "    model.add(Conv2D(64,(3,3),strides=(1,1),padding='same',activation='relu',kernel_initializer='glorot_uniform'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Conv2D(128,(3,3),strides=(1,1),padding='same',activation='relu',kernel_initializer='glorot_uniform'))\n",
    "    model.add(Conv2D(128,(3,3),strides=(1,1),padding='same',activation='relu',kernel_initializer='glorot_uniform'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Conv2D(256,(3,3),strides=(1,1),padding='same',activation='relu',kernel_initializer='glorot_uniform'))\n",
    "    model.add(Conv2D(256,(3,3),strides=(1,1),padding='same',activation='relu',kernel_initializer='glorot_uniform'))\n",
    "    model.add(Conv2D(256,(3,3),strides=(1,1),padding='same',activation='relu',kernel_initializer='glorot_uniform'))\n",
    "    model.add(GlobalAveragePooling2D())\n",
    "    model.add(Dense(256,activation='relu'))\n",
    "    model.add(Dropout(rate=0.5))\n",
    "    model.add(Dense(num_class,activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "    #train model\n",
    "    earlyStopping=kcallbacks.EarlyStopping(monitor='val_accuracy', patience=2, verbose=1, mode='auto')\n",
    "    saveBestModel = kcallbacks.ModelCheckpoint(filepath=savepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='auto')\n",
    "    hist=model.fit(\n",
    "        train_generator,\n",
    "        steps_per_epoch=len(train_generator),\n",
    "        epochs=epochs,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=len(validation_generator),\n",
    "        callbacks=[history, timer, earlyStopping, saveBestModel],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Software\\anaconda3\\envs\\IDSml_cnn_2\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1940: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": " OOM when allocating tensor with shape[128,64,224,224] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node sequential/conv2d/Relu (defined at C:\\Users\\xht30\\AppData\\Local\\Temp\\ipykernel_51316\\1467547391.py:20) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n [Op:__inference_train_function_1241]\n\nFunction call stack:\ntrain_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [13], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m cnn_by_own(input_shape\u001b[39m=\u001b[39;49mINPUT_SIZE,num_class\u001b[39m=\u001b[39;49mnum_class,epochs\u001b[39m=\u001b[39;49m\u001b[39m20\u001b[39;49m)\n\u001b[0;32m      2\u001b[0m history_this\u001b[39m.\u001b[39mloss_plot(\u001b[39m'\u001b[39m\u001b[39mepoch\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      3\u001b[0m history_this\u001b[39m.\u001b[39mloss_plot(\u001b[39m'\u001b[39m\u001b[39mbatch\u001b[39m\u001b[39m'\u001b[39m)\n",
      "Cell \u001b[1;32mIn [12], line 20\u001b[0m, in \u001b[0;36mcnn_by_own\u001b[1;34m(input_shape, num_class, epochs, savepath, history, timer)\u001b[0m\n\u001b[0;32m     18\u001b[0m earlyStopping\u001b[39m=\u001b[39mkcallbacks\u001b[39m.\u001b[39mEarlyStopping(monitor\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mval_acc\u001b[39m\u001b[39m'\u001b[39m, patience\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m, verbose\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, mode\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mauto\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     19\u001b[0m saveBestModel \u001b[39m=\u001b[39m kcallbacks\u001b[39m.\u001b[39mModelCheckpoint(filepath\u001b[39m=\u001b[39msavepath, monitor\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mval_acc\u001b[39m\u001b[39m'\u001b[39m, verbose\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, save_best_only\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, mode\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mauto\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m---> 20\u001b[0m hist\u001b[39m=\u001b[39mmodel\u001b[39m.\u001b[39;49mfit_generator(\n\u001b[0;32m     21\u001b[0m     train_generator,\n\u001b[0;32m     22\u001b[0m     steps_per_epoch\u001b[39m=\u001b[39;49m\u001b[39mlen\u001b[39;49m(train_generator),\n\u001b[0;32m     23\u001b[0m     epochs\u001b[39m=\u001b[39;49mepochs,\n\u001b[0;32m     24\u001b[0m     validation_data\u001b[39m=\u001b[39;49mvalidation_generator,\n\u001b[0;32m     25\u001b[0m     validation_steps\u001b[39m=\u001b[39;49m\u001b[39mlen\u001b[39;49m(validation_generator),\n\u001b[0;32m     26\u001b[0m     callbacks\u001b[39m=\u001b[39;49m[history, timer, earlyStopping, saveBestModel],\n\u001b[0;32m     27\u001b[0m )\n",
      "File \u001b[1;32md:\\Software\\anaconda3\\envs\\IDSml_cnn_2\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1943\u001b[0m, in \u001b[0;36mModel.fit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   1934\u001b[0m \u001b[39m\"\"\"Fits the model on data yielded batch-by-batch by a Python generator.\u001b[39;00m\n\u001b[0;32m   1935\u001b[0m \n\u001b[0;32m   1936\u001b[0m \u001b[39mDEPRECATED:\u001b[39;00m\n\u001b[0;32m   1937\u001b[0m \u001b[39m  `Model.fit` now supports generators, so there is no longer any need to use\u001b[39;00m\n\u001b[0;32m   1938\u001b[0m \u001b[39m  this endpoint.\u001b[39;00m\n\u001b[0;32m   1939\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1940\u001b[0m warnings\u001b[39m.\u001b[39mwarn(\u001b[39m'\u001b[39m\u001b[39m`Model.fit_generator` is deprecated and \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m   1941\u001b[0m               \u001b[39m'\u001b[39m\u001b[39mwill be removed in a future version. \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m   1942\u001b[0m               \u001b[39m'\u001b[39m\u001b[39mPlease use `Model.fit`, which supports generators.\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m-> 1943\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfit(\n\u001b[0;32m   1944\u001b[0m     generator,\n\u001b[0;32m   1945\u001b[0m     steps_per_epoch\u001b[39m=\u001b[39;49msteps_per_epoch,\n\u001b[0;32m   1946\u001b[0m     epochs\u001b[39m=\u001b[39;49mepochs,\n\u001b[0;32m   1947\u001b[0m     verbose\u001b[39m=\u001b[39;49mverbose,\n\u001b[0;32m   1948\u001b[0m     callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[0;32m   1949\u001b[0m     validation_data\u001b[39m=\u001b[39;49mvalidation_data,\n\u001b[0;32m   1950\u001b[0m     validation_steps\u001b[39m=\u001b[39;49mvalidation_steps,\n\u001b[0;32m   1951\u001b[0m     validation_freq\u001b[39m=\u001b[39;49mvalidation_freq,\n\u001b[0;32m   1952\u001b[0m     class_weight\u001b[39m=\u001b[39;49mclass_weight,\n\u001b[0;32m   1953\u001b[0m     max_queue_size\u001b[39m=\u001b[39;49mmax_queue_size,\n\u001b[0;32m   1954\u001b[0m     workers\u001b[39m=\u001b[39;49mworkers,\n\u001b[0;32m   1955\u001b[0m     use_multiprocessing\u001b[39m=\u001b[39;49muse_multiprocessing,\n\u001b[0;32m   1956\u001b[0m     shuffle\u001b[39m=\u001b[39;49mshuffle,\n\u001b[0;32m   1957\u001b[0m     initial_epoch\u001b[39m=\u001b[39;49minitial_epoch)\n",
      "File \u001b[1;32md:\\Software\\anaconda3\\envs\\IDSml_cnn_2\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1183\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1176\u001b[0m \u001b[39mwith\u001b[39;00m trace\u001b[39m.\u001b[39mTrace(\n\u001b[0;32m   1177\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m   1178\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[0;32m   1179\u001b[0m     step_num\u001b[39m=\u001b[39mstep,\n\u001b[0;32m   1180\u001b[0m     batch_size\u001b[39m=\u001b[39mbatch_size,\n\u001b[0;32m   1181\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[0;32m   1182\u001b[0m   callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1183\u001b[0m   tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[0;32m   1184\u001b[0m   \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[0;32m   1185\u001b[0m     context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[1;32md:\\Software\\anaconda3\\envs\\IDSml_cnn_2\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:889\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    886\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    888\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 889\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[0;32m    891\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    892\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32md:\\Software\\anaconda3\\envs\\IDSml_cnn_2\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:950\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    946\u001b[0m     \u001b[39mpass\u001b[39;00m  \u001b[39m# Fall through to cond-based initialization.\u001b[39;00m\n\u001b[0;32m    947\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    948\u001b[0m     \u001b[39m# Lifting succeeded, so variables are initialized and we can run the\u001b[39;00m\n\u001b[0;32m    949\u001b[0m     \u001b[39m# stateless function.\u001b[39;00m\n\u001b[1;32m--> 950\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_stateless_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[0;32m    951\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    952\u001b[0m   _, _, _, filtered_flat_args \u001b[39m=\u001b[39m \\\n\u001b[0;32m    953\u001b[0m       \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn\u001b[39m.\u001b[39m_function_spec\u001b[39m.\u001b[39mcanonicalize_function_inputs(  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    954\u001b[0m           \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n",
      "File \u001b[1;32md:\\Software\\anaconda3\\envs\\IDSml_cnn_2\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3023\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3020\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m   3021\u001b[0m   (graph_function,\n\u001b[0;32m   3022\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 3023\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[0;32m   3024\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[1;32md:\\Software\\anaconda3\\envs\\IDSml_cnn_2\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1960\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1956\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1957\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1958\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1959\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1960\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[0;32m   1961\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[0;32m   1962\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1963\u001b[0m     args,\n\u001b[0;32m   1964\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1965\u001b[0m     executing_eagerly)\n\u001b[0;32m   1966\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[1;32md:\\Software\\anaconda3\\envs\\IDSml_cnn_2\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:591\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    589\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[0;32m    590\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 591\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[0;32m    592\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[0;32m    593\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[0;32m    594\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[0;32m    595\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[0;32m    596\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[0;32m    597\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    598\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    599\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[0;32m    600\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    603\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[0;32m    604\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32md:\\Software\\anaconda3\\envs\\IDSml_cnn_2\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:59\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     58\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 59\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[0;32m     60\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     62\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m:  OOM when allocating tensor with shape[128,64,224,224] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node sequential/conv2d/Relu (defined at C:\\Users\\xht30\\AppData\\Local\\Temp\\ipykernel_51316\\1467547391.py:20) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n [Op:__inference_train_function_1241]\n\nFunction call stack:\ntrain_function\n"
     ]
    }
   ],
   "source": [
    "cnn_by_own(input_shape=INPUT_SIZE,num_class=num_class,epochs=20)\n",
    "history_this.loss_plot('epoch')\n",
    "history_this.loss_plot('batch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validation accuracy of a CNN by own: 99.884%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.add('model_own', train_time=timer.get_processing_time(), **history_this.get_best())\n",
    "history_this.generate_report('model_own_original')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2: Xception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xception( num_class, epochs,savepath='./xception.h5',history=history_this,input_shape=INPUT_SIZE,timer=timer):\n",
    "    model_fine_tune = Xception(include_top=False, weights='imagenet', input_shape=input_shape)\n",
    "    for layer in model_fine_tune.layers[:131]:\t\t#could be tuned to be 50, 100, or 131\n",
    "        layer.trainable = False\n",
    "    for layer in model_fine_tune.layers[131:]:\n",
    "        layer.trainable = True\n",
    "    model = GlobalAveragePooling2D()(model_fine_tune.output)\n",
    "    model=Dense(units=256,activation='relu')(model)\n",
    "    model=Dropout(0.5)(model)\n",
    "    model = Dense(num_class, activation='softmax')(model)\n",
    "    model = Model(model_fine_tune.input, model, name='xception')\n",
    "    opt = keras.optimizers.Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "    #train model\n",
    "    earlyStopping = kcallbacks.EarlyStopping(\n",
    "        monitor='val_accuracy', patience=3, verbose=1, mode='auto')\t#patience could be tuned by 2 and 3\n",
    "    saveBestModel = kcallbacks.ModelCheckpoint(\n",
    "        filepath=savepath,\n",
    "        monitor='val_accuracy',\n",
    "        verbose=1,\n",
    "        save_best_only=True,\n",
    "        mode='auto')\n",
    "    hist = model.fit(\n",
    "        train_generator,\n",
    "        steps_per_epoch=len(train_generator),\n",
    "        epochs=epochs,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=len(validation_generator),\n",
    "        #use_multiprocessing=True, \n",
    "        callbacks=[history, timer, earlyStopping, saveBestModel],\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Software\\anaconda3\\envs\\IDSml_cnn_2\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py:374: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": " OOM when allocating tensor with shape[128,128,109,109] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node xception/block2_sepconv1/separable_conv2d (defined at C:\\Users\\xht30\\AppData\\Local\\Temp\\ipykernel_51316\\2818243488.py:23) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n [Op:__inference_train_function_8336]\n\nFunction call stack:\ntrain_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [15], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m#default only 50, tf36cnn 99\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m xception(num_class\u001b[39m=\u001b[39;49mnum_class,epochs\u001b[39m=\u001b[39;49m\u001b[39m20\u001b[39;49m)\n\u001b[0;32m      3\u001b[0m history_this\u001b[39m.\u001b[39mloss_plot(\u001b[39m'\u001b[39m\u001b[39mepoch\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      4\u001b[0m history_this\u001b[39m.\u001b[39mloss_plot(\u001b[39m'\u001b[39m\u001b[39mbatch\u001b[39m\u001b[39m'\u001b[39m)\n",
      "Cell \u001b[1;32mIn [14], line 23\u001b[0m, in \u001b[0;36mxception\u001b[1;34m(num_class, epochs, savepath, history, input_shape, timer)\u001b[0m\n\u001b[0;32m     15\u001b[0m earlyStopping \u001b[39m=\u001b[39m kcallbacks\u001b[39m.\u001b[39mEarlyStopping(\n\u001b[0;32m     16\u001b[0m     monitor\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mval_acc\u001b[39m\u001b[39m'\u001b[39m, patience\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m, verbose\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, mode\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mauto\u001b[39m\u001b[39m'\u001b[39m)\t\u001b[39m#patience could be tuned by 2 and 3\u001b[39;00m\n\u001b[0;32m     17\u001b[0m saveBestModel \u001b[39m=\u001b[39m kcallbacks\u001b[39m.\u001b[39mModelCheckpoint(\n\u001b[0;32m     18\u001b[0m     filepath\u001b[39m=\u001b[39msavepath,\n\u001b[0;32m     19\u001b[0m     monitor\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mval_acc\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m     20\u001b[0m     verbose\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[0;32m     21\u001b[0m     save_best_only\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[0;32m     22\u001b[0m     mode\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mauto\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m---> 23\u001b[0m hist \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit_generator(\n\u001b[0;32m     24\u001b[0m     train_generator,\n\u001b[0;32m     25\u001b[0m     steps_per_epoch\u001b[39m=\u001b[39;49m\u001b[39mlen\u001b[39;49m(train_generator),\n\u001b[0;32m     26\u001b[0m     epochs\u001b[39m=\u001b[39;49mepochs,\n\u001b[0;32m     27\u001b[0m     validation_data\u001b[39m=\u001b[39;49mvalidation_generator,\n\u001b[0;32m     28\u001b[0m     validation_steps\u001b[39m=\u001b[39;49m\u001b[39mlen\u001b[39;49m(validation_generator),\n\u001b[0;32m     29\u001b[0m     \u001b[39m#use_multiprocessing=True, \u001b[39;49;00m\n\u001b[0;32m     30\u001b[0m     callbacks\u001b[39m=\u001b[39;49m[history, timer, earlyStopping, saveBestModel],\n\u001b[0;32m     31\u001b[0m )\n",
      "File \u001b[1;32md:\\Software\\anaconda3\\envs\\IDSml_cnn_2\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1943\u001b[0m, in \u001b[0;36mModel.fit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   1934\u001b[0m \u001b[39m\"\"\"Fits the model on data yielded batch-by-batch by a Python generator.\u001b[39;00m\n\u001b[0;32m   1935\u001b[0m \n\u001b[0;32m   1936\u001b[0m \u001b[39mDEPRECATED:\u001b[39;00m\n\u001b[0;32m   1937\u001b[0m \u001b[39m  `Model.fit` now supports generators, so there is no longer any need to use\u001b[39;00m\n\u001b[0;32m   1938\u001b[0m \u001b[39m  this endpoint.\u001b[39;00m\n\u001b[0;32m   1939\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1940\u001b[0m warnings\u001b[39m.\u001b[39mwarn(\u001b[39m'\u001b[39m\u001b[39m`Model.fit_generator` is deprecated and \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m   1941\u001b[0m               \u001b[39m'\u001b[39m\u001b[39mwill be removed in a future version. \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m   1942\u001b[0m               \u001b[39m'\u001b[39m\u001b[39mPlease use `Model.fit`, which supports generators.\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m-> 1943\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfit(\n\u001b[0;32m   1944\u001b[0m     generator,\n\u001b[0;32m   1945\u001b[0m     steps_per_epoch\u001b[39m=\u001b[39;49msteps_per_epoch,\n\u001b[0;32m   1946\u001b[0m     epochs\u001b[39m=\u001b[39;49mepochs,\n\u001b[0;32m   1947\u001b[0m     verbose\u001b[39m=\u001b[39;49mverbose,\n\u001b[0;32m   1948\u001b[0m     callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[0;32m   1949\u001b[0m     validation_data\u001b[39m=\u001b[39;49mvalidation_data,\n\u001b[0;32m   1950\u001b[0m     validation_steps\u001b[39m=\u001b[39;49mvalidation_steps,\n\u001b[0;32m   1951\u001b[0m     validation_freq\u001b[39m=\u001b[39;49mvalidation_freq,\n\u001b[0;32m   1952\u001b[0m     class_weight\u001b[39m=\u001b[39;49mclass_weight,\n\u001b[0;32m   1953\u001b[0m     max_queue_size\u001b[39m=\u001b[39;49mmax_queue_size,\n\u001b[0;32m   1954\u001b[0m     workers\u001b[39m=\u001b[39;49mworkers,\n\u001b[0;32m   1955\u001b[0m     use_multiprocessing\u001b[39m=\u001b[39;49muse_multiprocessing,\n\u001b[0;32m   1956\u001b[0m     shuffle\u001b[39m=\u001b[39;49mshuffle,\n\u001b[0;32m   1957\u001b[0m     initial_epoch\u001b[39m=\u001b[39;49minitial_epoch)\n",
      "File \u001b[1;32md:\\Software\\anaconda3\\envs\\IDSml_cnn_2\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1183\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1176\u001b[0m \u001b[39mwith\u001b[39;00m trace\u001b[39m.\u001b[39mTrace(\n\u001b[0;32m   1177\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m   1178\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[0;32m   1179\u001b[0m     step_num\u001b[39m=\u001b[39mstep,\n\u001b[0;32m   1180\u001b[0m     batch_size\u001b[39m=\u001b[39mbatch_size,\n\u001b[0;32m   1181\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[0;32m   1182\u001b[0m   callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1183\u001b[0m   tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[0;32m   1184\u001b[0m   \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[0;32m   1185\u001b[0m     context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[1;32md:\\Software\\anaconda3\\envs\\IDSml_cnn_2\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:889\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    886\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    888\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 889\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[0;32m    891\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    892\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32md:\\Software\\anaconda3\\envs\\IDSml_cnn_2\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:950\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    946\u001b[0m     \u001b[39mpass\u001b[39;00m  \u001b[39m# Fall through to cond-based initialization.\u001b[39;00m\n\u001b[0;32m    947\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    948\u001b[0m     \u001b[39m# Lifting succeeded, so variables are initialized and we can run the\u001b[39;00m\n\u001b[0;32m    949\u001b[0m     \u001b[39m# stateless function.\u001b[39;00m\n\u001b[1;32m--> 950\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_stateless_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[0;32m    951\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    952\u001b[0m   _, _, _, filtered_flat_args \u001b[39m=\u001b[39m \\\n\u001b[0;32m    953\u001b[0m       \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn\u001b[39m.\u001b[39m_function_spec\u001b[39m.\u001b[39mcanonicalize_function_inputs(  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    954\u001b[0m           \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n",
      "File \u001b[1;32md:\\Software\\anaconda3\\envs\\IDSml_cnn_2\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3023\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3020\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m   3021\u001b[0m   (graph_function,\n\u001b[0;32m   3022\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 3023\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[0;32m   3024\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[1;32md:\\Software\\anaconda3\\envs\\IDSml_cnn_2\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1960\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1956\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1957\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1958\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1959\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1960\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[0;32m   1961\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[0;32m   1962\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1963\u001b[0m     args,\n\u001b[0;32m   1964\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1965\u001b[0m     executing_eagerly)\n\u001b[0;32m   1966\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[1;32md:\\Software\\anaconda3\\envs\\IDSml_cnn_2\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:591\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    589\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[0;32m    590\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 591\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[0;32m    592\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[0;32m    593\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[0;32m    594\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[0;32m    595\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[0;32m    596\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[0;32m    597\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    598\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    599\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[0;32m    600\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    603\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[0;32m    604\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32md:\\Software\\anaconda3\\envs\\IDSml_cnn_2\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:59\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     58\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 59\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[0;32m     60\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     62\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m:  OOM when allocating tensor with shape[128,128,109,109] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node xception/block2_sepconv1/separable_conv2d (defined at C:\\Users\\xht30\\AppData\\Local\\Temp\\ipykernel_51316\\2818243488.py:23) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n [Op:__inference_train_function_8336]\n\nFunction call stack:\ntrain_function\n"
     ]
    }
   ],
   "source": [
    "#default only 50, tf36cnn 99\n",
    "xception(num_class=num_class,epochs=20)\n",
    "history_this.loss_plot('epoch')\n",
    "history_this.loss_plot('batch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validation accuracy of Xception: 100.0%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.add('Xception', train_time=timer.get_processing_time(), **history_this.get_best())\n",
    "history_this.generate_report('Xception_original')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 3: VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def vgg16( num_class, epochs,savepath='./VGG16.h5',history=history_this,input_shape=INPUT_SIZE,timer=timer):\n",
    "    model_fine_tune = VGG16(include_top=False, weights='imagenet', input_shape=input_shape)\n",
    "    for layer in model_fine_tune.layers[:15]:\t#the number of frozen layers for transfer learning, have tuned from 5-18\n",
    "        layer.trainable = False\n",
    "    for layer in model_fine_tune.layers[15:]:\n",
    "        layer.trainable = True\n",
    "    model = GlobalAveragePooling2D()(model_fine_tune.output) #GlobalAveragePooling2D layer to convert the features to a single 1280-element vector per image\n",
    "    model=Dense(units=256,activation='relu')(model)\n",
    "    model=Dropout(0.5)(model)\n",
    "    model = Dense(num_class, activation='softmax')(model)\n",
    "    model = Model(model_fine_tune.input, model, name='vgg')\n",
    "    opt = keras.optimizers.Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\t#tuned learning rate to be 0.001\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\t#set the loss function to be binary crossentropy\n",
    "    #train model\n",
    "    earlyStopping = kcallbacks.EarlyStopping(\n",
    "        monitor='val_accuracy', patience=2, verbose=1, mode='auto')\t#set early stop patience to save training time\n",
    "    saveBestModel = kcallbacks.ModelCheckpoint(\n",
    "        filepath=savepath,\n",
    "        monitor='val_accuracy',\n",
    "        verbose=1,\n",
    "        save_best_only=True,\n",
    "        mode='auto')\n",
    "    hist = model.fit(\n",
    "        train_generator,\n",
    "        steps_per_epoch=len(train_generator),\n",
    "        epochs=epochs,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=len(validation_generator),\n",
    "        #use_multiprocessing=True, \n",
    "        #workers=2,\n",
    "        callbacks=[history, timer, earlyStopping, saveBestModel],\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": " OOM when allocating tensor with shape[128,64,224,224] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node vgg/block1_conv1/Relu (defined at C:\\Users\\xht30\\AppData\\Local\\Temp\\ipykernel_51316\\738096641.py:23) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n [Op:__inference_train_function_9798]\n\nFunction call stack:\ntrain_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [17], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m vgg16(num_class\u001b[39m=\u001b[39;49mnum_class,epochs\u001b[39m=\u001b[39;49m\u001b[39m20\u001b[39;49m)\t\u001b[39m#tf36cnn\u001b[39;00m\n\u001b[0;32m      2\u001b[0m history_this\u001b[39m.\u001b[39mloss_plot(\u001b[39m'\u001b[39m\u001b[39mepoch\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      3\u001b[0m history_this\u001b[39m.\u001b[39mloss_plot(\u001b[39m'\u001b[39m\u001b[39mbatch\u001b[39m\u001b[39m'\u001b[39m)\n",
      "Cell \u001b[1;32mIn [16], line 23\u001b[0m, in \u001b[0;36mvgg16\u001b[1;34m(num_class, epochs, savepath, history, input_shape, timer)\u001b[0m\n\u001b[0;32m     15\u001b[0m earlyStopping \u001b[39m=\u001b[39m kcallbacks\u001b[39m.\u001b[39mEarlyStopping(\n\u001b[0;32m     16\u001b[0m     monitor\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mval_acc\u001b[39m\u001b[39m'\u001b[39m, patience\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m, verbose\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, mode\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mauto\u001b[39m\u001b[39m'\u001b[39m)\t\u001b[39m#set early stop patience to save training time\u001b[39;00m\n\u001b[0;32m     17\u001b[0m saveBestModel \u001b[39m=\u001b[39m kcallbacks\u001b[39m.\u001b[39mModelCheckpoint(\n\u001b[0;32m     18\u001b[0m     filepath\u001b[39m=\u001b[39msavepath,\n\u001b[0;32m     19\u001b[0m     monitor\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mval_acc\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m     20\u001b[0m     verbose\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[0;32m     21\u001b[0m     save_best_only\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[0;32m     22\u001b[0m     mode\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mauto\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m---> 23\u001b[0m hist \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit_generator(\n\u001b[0;32m     24\u001b[0m     train_generator,\n\u001b[0;32m     25\u001b[0m     steps_per_epoch\u001b[39m=\u001b[39;49m\u001b[39mlen\u001b[39;49m(train_generator),\n\u001b[0;32m     26\u001b[0m     epochs\u001b[39m=\u001b[39;49mepochs,\n\u001b[0;32m     27\u001b[0m     validation_data\u001b[39m=\u001b[39;49mvalidation_generator,\n\u001b[0;32m     28\u001b[0m     validation_steps\u001b[39m=\u001b[39;49m\u001b[39mlen\u001b[39;49m(validation_generator),\n\u001b[0;32m     29\u001b[0m     \u001b[39m#use_multiprocessing=True, \u001b[39;49;00m\n\u001b[0;32m     30\u001b[0m     \u001b[39m#workers=2,\u001b[39;49;00m\n\u001b[0;32m     31\u001b[0m     callbacks\u001b[39m=\u001b[39;49m[history, timer, earlyStopping, saveBestModel],\n\u001b[0;32m     32\u001b[0m )\n",
      "File \u001b[1;32md:\\Software\\anaconda3\\envs\\IDSml_cnn_2\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1943\u001b[0m, in \u001b[0;36mModel.fit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   1934\u001b[0m \u001b[39m\"\"\"Fits the model on data yielded batch-by-batch by a Python generator.\u001b[39;00m\n\u001b[0;32m   1935\u001b[0m \n\u001b[0;32m   1936\u001b[0m \u001b[39mDEPRECATED:\u001b[39;00m\n\u001b[0;32m   1937\u001b[0m \u001b[39m  `Model.fit` now supports generators, so there is no longer any need to use\u001b[39;00m\n\u001b[0;32m   1938\u001b[0m \u001b[39m  this endpoint.\u001b[39;00m\n\u001b[0;32m   1939\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1940\u001b[0m warnings\u001b[39m.\u001b[39mwarn(\u001b[39m'\u001b[39m\u001b[39m`Model.fit_generator` is deprecated and \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m   1941\u001b[0m               \u001b[39m'\u001b[39m\u001b[39mwill be removed in a future version. \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m   1942\u001b[0m               \u001b[39m'\u001b[39m\u001b[39mPlease use `Model.fit`, which supports generators.\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m-> 1943\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfit(\n\u001b[0;32m   1944\u001b[0m     generator,\n\u001b[0;32m   1945\u001b[0m     steps_per_epoch\u001b[39m=\u001b[39;49msteps_per_epoch,\n\u001b[0;32m   1946\u001b[0m     epochs\u001b[39m=\u001b[39;49mepochs,\n\u001b[0;32m   1947\u001b[0m     verbose\u001b[39m=\u001b[39;49mverbose,\n\u001b[0;32m   1948\u001b[0m     callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[0;32m   1949\u001b[0m     validation_data\u001b[39m=\u001b[39;49mvalidation_data,\n\u001b[0;32m   1950\u001b[0m     validation_steps\u001b[39m=\u001b[39;49mvalidation_steps,\n\u001b[0;32m   1951\u001b[0m     validation_freq\u001b[39m=\u001b[39;49mvalidation_freq,\n\u001b[0;32m   1952\u001b[0m     class_weight\u001b[39m=\u001b[39;49mclass_weight,\n\u001b[0;32m   1953\u001b[0m     max_queue_size\u001b[39m=\u001b[39;49mmax_queue_size,\n\u001b[0;32m   1954\u001b[0m     workers\u001b[39m=\u001b[39;49mworkers,\n\u001b[0;32m   1955\u001b[0m     use_multiprocessing\u001b[39m=\u001b[39;49muse_multiprocessing,\n\u001b[0;32m   1956\u001b[0m     shuffle\u001b[39m=\u001b[39;49mshuffle,\n\u001b[0;32m   1957\u001b[0m     initial_epoch\u001b[39m=\u001b[39;49minitial_epoch)\n",
      "File \u001b[1;32md:\\Software\\anaconda3\\envs\\IDSml_cnn_2\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1183\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1176\u001b[0m \u001b[39mwith\u001b[39;00m trace\u001b[39m.\u001b[39mTrace(\n\u001b[0;32m   1177\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m   1178\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[0;32m   1179\u001b[0m     step_num\u001b[39m=\u001b[39mstep,\n\u001b[0;32m   1180\u001b[0m     batch_size\u001b[39m=\u001b[39mbatch_size,\n\u001b[0;32m   1181\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[0;32m   1182\u001b[0m   callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1183\u001b[0m   tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[0;32m   1184\u001b[0m   \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[0;32m   1185\u001b[0m     context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[1;32md:\\Software\\anaconda3\\envs\\IDSml_cnn_2\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:889\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    886\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    888\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 889\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[0;32m    891\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    892\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32md:\\Software\\anaconda3\\envs\\IDSml_cnn_2\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:950\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    946\u001b[0m     \u001b[39mpass\u001b[39;00m  \u001b[39m# Fall through to cond-based initialization.\u001b[39;00m\n\u001b[0;32m    947\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    948\u001b[0m     \u001b[39m# Lifting succeeded, so variables are initialized and we can run the\u001b[39;00m\n\u001b[0;32m    949\u001b[0m     \u001b[39m# stateless function.\u001b[39;00m\n\u001b[1;32m--> 950\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_stateless_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[0;32m    951\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    952\u001b[0m   _, _, _, filtered_flat_args \u001b[39m=\u001b[39m \\\n\u001b[0;32m    953\u001b[0m       \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn\u001b[39m.\u001b[39m_function_spec\u001b[39m.\u001b[39mcanonicalize_function_inputs(  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    954\u001b[0m           \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n",
      "File \u001b[1;32md:\\Software\\anaconda3\\envs\\IDSml_cnn_2\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3023\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3020\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m   3021\u001b[0m   (graph_function,\n\u001b[0;32m   3022\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 3023\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[0;32m   3024\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[1;32md:\\Software\\anaconda3\\envs\\IDSml_cnn_2\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1960\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1956\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1957\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1958\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1959\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1960\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[0;32m   1961\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[0;32m   1962\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1963\u001b[0m     args,\n\u001b[0;32m   1964\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1965\u001b[0m     executing_eagerly)\n\u001b[0;32m   1966\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[1;32md:\\Software\\anaconda3\\envs\\IDSml_cnn_2\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:591\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    589\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[0;32m    590\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 591\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[0;32m    592\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[0;32m    593\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[0;32m    594\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[0;32m    595\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[0;32m    596\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[0;32m    597\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    598\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    599\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[0;32m    600\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    603\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[0;32m    604\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32md:\\Software\\anaconda3\\envs\\IDSml_cnn_2\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:59\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     58\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 59\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[0;32m     60\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     62\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m:  OOM when allocating tensor with shape[128,64,224,224] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node vgg/block1_conv1/Relu (defined at C:\\Users\\xht30\\AppData\\Local\\Temp\\ipykernel_51316\\738096641.py:23) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n [Op:__inference_train_function_9798]\n\nFunction call stack:\ntrain_function\n"
     ]
    }
   ],
   "source": [
    "vgg16(num_class=num_class,epochs=20)\t#tf36cnn\n",
    "history_this.loss_plot('epoch')\n",
    "history_this.loss_plot('batch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validation accuracy of VGG16: 100.0%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.add('VGG16', train_time=timer.get_processing_time(), **history_this.get_best())\n",
    "history_this.generate_report('VGG16_original')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 4: VGG19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def vgg19( num_class, epochs,savepath='./VGG19.h5',history=history_this,input_shape=INPUT_SIZE,timer=timer):\n",
    "    model_fine_tune = VGG19(include_top=False, weights='imagenet', input_shape=input_shape)\n",
    "    for layer in model_fine_tune.layers[:19]:\t#the number of frozen layers for transfer learning, have tuned from 5-18\n",
    "        layer.trainable = False\n",
    "    for layer in model_fine_tune.layers[19:]:\n",
    "        layer.trainable = True\n",
    "    model = GlobalAveragePooling2D()(model_fine_tune.output)\n",
    "    model=Dense(units=256,activation='relu')(model)\n",
    "    model=Dropout(0.5)(model)\n",
    "    model = Dense(num_class, activation='softmax')(model)\n",
    "    model = Model(model_fine_tune.input, model, name='vgg')\n",
    "    opt = keras.optimizers.Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\t#tuned learning rate to be 0.001\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\t#set the loss function to be binary crossentropy\n",
    "    #train model\n",
    "    earlyStopping = kcallbacks.EarlyStopping(\n",
    "        monitor='val_accuracy', patience=2, verbose=1, mode='auto')\t#set early stop patience to save training time\n",
    "    saveBestModel = kcallbacks.ModelCheckpoint(\n",
    "        filepath=savepath,\n",
    "        monitor='val_accuracy',\n",
    "        verbose=1,\n",
    "        save_best_only=True,\n",
    "        mode='auto')\n",
    "    hist = model.fit(\n",
    "        train_generator,\n",
    "        steps_per_epoch=len(train_generator),\n",
    "        epochs=epochs,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=len(validation_generator),\n",
    "        #use_multiprocessing=True, \n",
    "        #workers=2,\n",
    "        callbacks=[history, timer, earlyStopping, saveBestModel],\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg19/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "80142336/80134624 [==============================] - 22s 0us/step\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": " OOM when allocating tensor with shape[128,64,224,224] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node vgg/block1_conv1/Relu (defined at C:\\Users\\xht30\\AppData\\Local\\Temp\\ipykernel_51316\\1240161684.py:23) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n [Op:__inference_train_function_11381]\n\nFunction call stack:\ntrain_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [19], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m vgg19(num_class\u001b[39m=\u001b[39;49mnum_class,epochs\u001b[39m=\u001b[39;49m\u001b[39m20\u001b[39;49m)\t\u001b[39m#binary classificaiton\u001b[39;00m\n\u001b[0;32m      2\u001b[0m history_this\u001b[39m.\u001b[39mloss_plot(\u001b[39m'\u001b[39m\u001b[39mepoch\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      3\u001b[0m history_this\u001b[39m.\u001b[39mloss_plot(\u001b[39m'\u001b[39m\u001b[39mbatch\u001b[39m\u001b[39m'\u001b[39m)\n",
      "Cell \u001b[1;32mIn [18], line 23\u001b[0m, in \u001b[0;36mvgg19\u001b[1;34m(num_class, epochs, savepath, history, input_shape, timer)\u001b[0m\n\u001b[0;32m     15\u001b[0m earlyStopping \u001b[39m=\u001b[39m kcallbacks\u001b[39m.\u001b[39mEarlyStopping(\n\u001b[0;32m     16\u001b[0m     monitor\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mval_acc\u001b[39m\u001b[39m'\u001b[39m, patience\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m, verbose\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, mode\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mauto\u001b[39m\u001b[39m'\u001b[39m)\t\u001b[39m#set early stop patience to save training time\u001b[39;00m\n\u001b[0;32m     17\u001b[0m saveBestModel \u001b[39m=\u001b[39m kcallbacks\u001b[39m.\u001b[39mModelCheckpoint(\n\u001b[0;32m     18\u001b[0m     filepath\u001b[39m=\u001b[39msavepath,\n\u001b[0;32m     19\u001b[0m     monitor\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mval_acc\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m     20\u001b[0m     verbose\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[0;32m     21\u001b[0m     save_best_only\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[0;32m     22\u001b[0m     mode\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mauto\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m---> 23\u001b[0m hist \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit_generator(\n\u001b[0;32m     24\u001b[0m     train_generator,\n\u001b[0;32m     25\u001b[0m     steps_per_epoch\u001b[39m=\u001b[39;49m\u001b[39mlen\u001b[39;49m(train_generator),\n\u001b[0;32m     26\u001b[0m     epochs\u001b[39m=\u001b[39;49mepochs,\n\u001b[0;32m     27\u001b[0m     validation_data\u001b[39m=\u001b[39;49mvalidation_generator,\n\u001b[0;32m     28\u001b[0m     validation_steps\u001b[39m=\u001b[39;49m\u001b[39mlen\u001b[39;49m(validation_generator),\n\u001b[0;32m     29\u001b[0m     \u001b[39m#use_multiprocessing=True, \u001b[39;49;00m\n\u001b[0;32m     30\u001b[0m     \u001b[39m#workers=2,\u001b[39;49;00m\n\u001b[0;32m     31\u001b[0m     callbacks\u001b[39m=\u001b[39;49m[history, timer, earlyStopping, saveBestModel],\n\u001b[0;32m     32\u001b[0m )\n",
      "File \u001b[1;32md:\\Software\\anaconda3\\envs\\IDSml_cnn_2\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1943\u001b[0m, in \u001b[0;36mModel.fit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   1934\u001b[0m \u001b[39m\"\"\"Fits the model on data yielded batch-by-batch by a Python generator.\u001b[39;00m\n\u001b[0;32m   1935\u001b[0m \n\u001b[0;32m   1936\u001b[0m \u001b[39mDEPRECATED:\u001b[39;00m\n\u001b[0;32m   1937\u001b[0m \u001b[39m  `Model.fit` now supports generators, so there is no longer any need to use\u001b[39;00m\n\u001b[0;32m   1938\u001b[0m \u001b[39m  this endpoint.\u001b[39;00m\n\u001b[0;32m   1939\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1940\u001b[0m warnings\u001b[39m.\u001b[39mwarn(\u001b[39m'\u001b[39m\u001b[39m`Model.fit_generator` is deprecated and \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m   1941\u001b[0m               \u001b[39m'\u001b[39m\u001b[39mwill be removed in a future version. \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m   1942\u001b[0m               \u001b[39m'\u001b[39m\u001b[39mPlease use `Model.fit`, which supports generators.\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m-> 1943\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfit(\n\u001b[0;32m   1944\u001b[0m     generator,\n\u001b[0;32m   1945\u001b[0m     steps_per_epoch\u001b[39m=\u001b[39;49msteps_per_epoch,\n\u001b[0;32m   1946\u001b[0m     epochs\u001b[39m=\u001b[39;49mepochs,\n\u001b[0;32m   1947\u001b[0m     verbose\u001b[39m=\u001b[39;49mverbose,\n\u001b[0;32m   1948\u001b[0m     callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[0;32m   1949\u001b[0m     validation_data\u001b[39m=\u001b[39;49mvalidation_data,\n\u001b[0;32m   1950\u001b[0m     validation_steps\u001b[39m=\u001b[39;49mvalidation_steps,\n\u001b[0;32m   1951\u001b[0m     validation_freq\u001b[39m=\u001b[39;49mvalidation_freq,\n\u001b[0;32m   1952\u001b[0m     class_weight\u001b[39m=\u001b[39;49mclass_weight,\n\u001b[0;32m   1953\u001b[0m     max_queue_size\u001b[39m=\u001b[39;49mmax_queue_size,\n\u001b[0;32m   1954\u001b[0m     workers\u001b[39m=\u001b[39;49mworkers,\n\u001b[0;32m   1955\u001b[0m     use_multiprocessing\u001b[39m=\u001b[39;49muse_multiprocessing,\n\u001b[0;32m   1956\u001b[0m     shuffle\u001b[39m=\u001b[39;49mshuffle,\n\u001b[0;32m   1957\u001b[0m     initial_epoch\u001b[39m=\u001b[39;49minitial_epoch)\n",
      "File \u001b[1;32md:\\Software\\anaconda3\\envs\\IDSml_cnn_2\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1183\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1176\u001b[0m \u001b[39mwith\u001b[39;00m trace\u001b[39m.\u001b[39mTrace(\n\u001b[0;32m   1177\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m   1178\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[0;32m   1179\u001b[0m     step_num\u001b[39m=\u001b[39mstep,\n\u001b[0;32m   1180\u001b[0m     batch_size\u001b[39m=\u001b[39mbatch_size,\n\u001b[0;32m   1181\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[0;32m   1182\u001b[0m   callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1183\u001b[0m   tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[0;32m   1184\u001b[0m   \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[0;32m   1185\u001b[0m     context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[1;32md:\\Software\\anaconda3\\envs\\IDSml_cnn_2\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:889\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    886\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    888\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 889\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[0;32m    891\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    892\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32md:\\Software\\anaconda3\\envs\\IDSml_cnn_2\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:950\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    946\u001b[0m     \u001b[39mpass\u001b[39;00m  \u001b[39m# Fall through to cond-based initialization.\u001b[39;00m\n\u001b[0;32m    947\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    948\u001b[0m     \u001b[39m# Lifting succeeded, so variables are initialized and we can run the\u001b[39;00m\n\u001b[0;32m    949\u001b[0m     \u001b[39m# stateless function.\u001b[39;00m\n\u001b[1;32m--> 950\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_stateless_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[0;32m    951\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    952\u001b[0m   _, _, _, filtered_flat_args \u001b[39m=\u001b[39m \\\n\u001b[0;32m    953\u001b[0m       \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn\u001b[39m.\u001b[39m_function_spec\u001b[39m.\u001b[39mcanonicalize_function_inputs(  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    954\u001b[0m           \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n",
      "File \u001b[1;32md:\\Software\\anaconda3\\envs\\IDSml_cnn_2\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3023\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3020\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m   3021\u001b[0m   (graph_function,\n\u001b[0;32m   3022\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 3023\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[0;32m   3024\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[1;32md:\\Software\\anaconda3\\envs\\IDSml_cnn_2\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1960\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1956\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1957\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1958\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1959\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1960\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[0;32m   1961\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[0;32m   1962\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1963\u001b[0m     args,\n\u001b[0;32m   1964\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1965\u001b[0m     executing_eagerly)\n\u001b[0;32m   1966\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[1;32md:\\Software\\anaconda3\\envs\\IDSml_cnn_2\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:591\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    589\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[0;32m    590\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 591\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[0;32m    592\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[0;32m    593\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[0;32m    594\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[0;32m    595\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[0;32m    596\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[0;32m    597\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    598\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    599\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[0;32m    600\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    603\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[0;32m    604\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32md:\\Software\\anaconda3\\envs\\IDSml_cnn_2\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:59\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     58\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 59\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[0;32m     60\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     62\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m:  OOM when allocating tensor with shape[128,64,224,224] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node vgg/block1_conv1/Relu (defined at C:\\Users\\xht30\\AppData\\Local\\Temp\\ipykernel_51316\\1240161684.py:23) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n [Op:__inference_train_function_11381]\n\nFunction call stack:\ntrain_function\n"
     ]
    }
   ],
   "source": [
    "vgg19(num_class=num_class,epochs=20)\t#binary classificaiton\n",
    "history_this.loss_plot('epoch')\n",
    "history_this.loss_plot('batch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validation accuracy of VGG19: 100.0%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.add('VGG19', train_time=timer.get_processing_time(), **history_this.get_best())\n",
    "history_this.generate_report('VGG19_original')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 5: ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def resnet( num_class, epochs,savepath='./resnet.h5',history=history_this,input_shape=INPUT_SIZE,timer=timer):\n",
    "    model_fine_tune = ResNet50(include_top=False, weights='imagenet', input_shape=input_shape)\n",
    "    for layer in model_fine_tune.layers[:120]:\t#the number of frozen layers for transfer learning, have tuned from 50-150\n",
    "        layer.trainable = False\n",
    "    for layer in model_fine_tune.layers[120:]:\t#the number of trainable layers for transfer learning\n",
    "        layer.trainable = True\n",
    "    model = GlobalAveragePooling2D()(model_fine_tune.output)\n",
    "    model=Dense(units=256,activation='relu')(model)\n",
    "    model=Dropout(0.5)(model)\n",
    "    model = Dense(num_class, activation='softmax')(model)\n",
    "    model = Model(model_fine_tune.input, model, name='resnet')\n",
    "    opt = keras.optimizers.Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\t#tuned learning rate to be 0.001\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy']) #set the loss function to be binary crossentropy\n",
    "    #train model\n",
    "    earlyStopping = kcallbacks.EarlyStopping(\n",
    "        monitor='val_accuracy', patience=2, verbose=1, mode='auto')\t#set early stop patience to save training time\n",
    "    saveBestModel = kcallbacks.ModelCheckpoint(\n",
    "        filepath=savepath,\n",
    "        monitor='val_accuracy',\n",
    "        verbose=1,\n",
    "        save_best_only=True,\n",
    "        mode='auto')\n",
    "    hist = model.fit(\n",
    "        train_generator,\n",
    "        steps_per_epoch=len(train_generator),\n",
    "        epochs=epochs,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=len(validation_generator),\n",
    "        #use_multiprocessing=True, \n",
    "        callbacks=[history, timer, earlyStopping, saveBestModel],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "94773248/94765736 [==============================] - 39s 0us/step\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": " OOM when allocating tensor with shape[8192,114,114] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node resnet/pool1_pad/Pad (defined at C:\\Users\\xht30\\AppData\\Local\\Temp\\ipykernel_51316\\1254716126.py:23) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n [Op:__inference_train_function_21151]\n\nFunction call stack:\ntrain_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [21], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m resnet(num_class\u001b[39m=\u001b[39;49mnum_class,epochs\u001b[39m=\u001b[39;49m\u001b[39m20\u001b[39;49m)\t\u001b[39m#binary classificaiton\u001b[39;00m\n\u001b[0;32m      2\u001b[0m history_this\u001b[39m.\u001b[39mloss_plot(\u001b[39m'\u001b[39m\u001b[39mepoch\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      3\u001b[0m history_this\u001b[39m.\u001b[39mloss_plot(\u001b[39m'\u001b[39m\u001b[39mbatch\u001b[39m\u001b[39m'\u001b[39m)\n",
      "Cell \u001b[1;32mIn [20], line 23\u001b[0m, in \u001b[0;36mresnet\u001b[1;34m(num_class, epochs, savepath, history, input_shape, timer)\u001b[0m\n\u001b[0;32m     15\u001b[0m earlyStopping \u001b[39m=\u001b[39m kcallbacks\u001b[39m.\u001b[39mEarlyStopping(\n\u001b[0;32m     16\u001b[0m     monitor\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mval_acc\u001b[39m\u001b[39m'\u001b[39m, patience\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m, verbose\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, mode\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mauto\u001b[39m\u001b[39m'\u001b[39m)\t\u001b[39m#set early stop patience to save training time\u001b[39;00m\n\u001b[0;32m     17\u001b[0m saveBestModel \u001b[39m=\u001b[39m kcallbacks\u001b[39m.\u001b[39mModelCheckpoint(\n\u001b[0;32m     18\u001b[0m     filepath\u001b[39m=\u001b[39msavepath,\n\u001b[0;32m     19\u001b[0m     monitor\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mval_acc\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m     20\u001b[0m     verbose\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[0;32m     21\u001b[0m     save_best_only\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[0;32m     22\u001b[0m     mode\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mauto\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m---> 23\u001b[0m hist \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit_generator(\n\u001b[0;32m     24\u001b[0m     train_generator,\n\u001b[0;32m     25\u001b[0m     steps_per_epoch\u001b[39m=\u001b[39;49m\u001b[39mlen\u001b[39;49m(train_generator),\n\u001b[0;32m     26\u001b[0m     epochs\u001b[39m=\u001b[39;49mepochs,\n\u001b[0;32m     27\u001b[0m     validation_data\u001b[39m=\u001b[39;49mvalidation_generator,\n\u001b[0;32m     28\u001b[0m     validation_steps\u001b[39m=\u001b[39;49m\u001b[39mlen\u001b[39;49m(validation_generator),\n\u001b[0;32m     29\u001b[0m     \u001b[39m#use_multiprocessing=True, \u001b[39;49;00m\n\u001b[0;32m     30\u001b[0m     callbacks\u001b[39m=\u001b[39;49m[history, timer, earlyStopping, saveBestModel],\n\u001b[0;32m     31\u001b[0m )\n",
      "File \u001b[1;32md:\\Software\\anaconda3\\envs\\IDSml_cnn_2\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1943\u001b[0m, in \u001b[0;36mModel.fit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   1934\u001b[0m \u001b[39m\"\"\"Fits the model on data yielded batch-by-batch by a Python generator.\u001b[39;00m\n\u001b[0;32m   1935\u001b[0m \n\u001b[0;32m   1936\u001b[0m \u001b[39mDEPRECATED:\u001b[39;00m\n\u001b[0;32m   1937\u001b[0m \u001b[39m  `Model.fit` now supports generators, so there is no longer any need to use\u001b[39;00m\n\u001b[0;32m   1938\u001b[0m \u001b[39m  this endpoint.\u001b[39;00m\n\u001b[0;32m   1939\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1940\u001b[0m warnings\u001b[39m.\u001b[39mwarn(\u001b[39m'\u001b[39m\u001b[39m`Model.fit_generator` is deprecated and \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m   1941\u001b[0m               \u001b[39m'\u001b[39m\u001b[39mwill be removed in a future version. \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m   1942\u001b[0m               \u001b[39m'\u001b[39m\u001b[39mPlease use `Model.fit`, which supports generators.\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m-> 1943\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfit(\n\u001b[0;32m   1944\u001b[0m     generator,\n\u001b[0;32m   1945\u001b[0m     steps_per_epoch\u001b[39m=\u001b[39;49msteps_per_epoch,\n\u001b[0;32m   1946\u001b[0m     epochs\u001b[39m=\u001b[39;49mepochs,\n\u001b[0;32m   1947\u001b[0m     verbose\u001b[39m=\u001b[39;49mverbose,\n\u001b[0;32m   1948\u001b[0m     callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[0;32m   1949\u001b[0m     validation_data\u001b[39m=\u001b[39;49mvalidation_data,\n\u001b[0;32m   1950\u001b[0m     validation_steps\u001b[39m=\u001b[39;49mvalidation_steps,\n\u001b[0;32m   1951\u001b[0m     validation_freq\u001b[39m=\u001b[39;49mvalidation_freq,\n\u001b[0;32m   1952\u001b[0m     class_weight\u001b[39m=\u001b[39;49mclass_weight,\n\u001b[0;32m   1953\u001b[0m     max_queue_size\u001b[39m=\u001b[39;49mmax_queue_size,\n\u001b[0;32m   1954\u001b[0m     workers\u001b[39m=\u001b[39;49mworkers,\n\u001b[0;32m   1955\u001b[0m     use_multiprocessing\u001b[39m=\u001b[39;49muse_multiprocessing,\n\u001b[0;32m   1956\u001b[0m     shuffle\u001b[39m=\u001b[39;49mshuffle,\n\u001b[0;32m   1957\u001b[0m     initial_epoch\u001b[39m=\u001b[39;49minitial_epoch)\n",
      "File \u001b[1;32md:\\Software\\anaconda3\\envs\\IDSml_cnn_2\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1183\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1176\u001b[0m \u001b[39mwith\u001b[39;00m trace\u001b[39m.\u001b[39mTrace(\n\u001b[0;32m   1177\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m   1178\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[0;32m   1179\u001b[0m     step_num\u001b[39m=\u001b[39mstep,\n\u001b[0;32m   1180\u001b[0m     batch_size\u001b[39m=\u001b[39mbatch_size,\n\u001b[0;32m   1181\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[0;32m   1182\u001b[0m   callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1183\u001b[0m   tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[0;32m   1184\u001b[0m   \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[0;32m   1185\u001b[0m     context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[1;32md:\\Software\\anaconda3\\envs\\IDSml_cnn_2\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:889\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    886\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    888\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 889\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[0;32m    891\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    892\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32md:\\Software\\anaconda3\\envs\\IDSml_cnn_2\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:950\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    946\u001b[0m     \u001b[39mpass\u001b[39;00m  \u001b[39m# Fall through to cond-based initialization.\u001b[39;00m\n\u001b[0;32m    947\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    948\u001b[0m     \u001b[39m# Lifting succeeded, so variables are initialized and we can run the\u001b[39;00m\n\u001b[0;32m    949\u001b[0m     \u001b[39m# stateless function.\u001b[39;00m\n\u001b[1;32m--> 950\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_stateless_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[0;32m    951\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    952\u001b[0m   _, _, _, filtered_flat_args \u001b[39m=\u001b[39m \\\n\u001b[0;32m    953\u001b[0m       \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn\u001b[39m.\u001b[39m_function_spec\u001b[39m.\u001b[39mcanonicalize_function_inputs(  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    954\u001b[0m           \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n",
      "File \u001b[1;32md:\\Software\\anaconda3\\envs\\IDSml_cnn_2\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3023\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3020\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m   3021\u001b[0m   (graph_function,\n\u001b[0;32m   3022\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 3023\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[0;32m   3024\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[1;32md:\\Software\\anaconda3\\envs\\IDSml_cnn_2\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1960\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1956\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1957\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1958\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1959\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1960\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[0;32m   1961\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[0;32m   1962\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1963\u001b[0m     args,\n\u001b[0;32m   1964\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1965\u001b[0m     executing_eagerly)\n\u001b[0;32m   1966\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[1;32md:\\Software\\anaconda3\\envs\\IDSml_cnn_2\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:591\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    589\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[0;32m    590\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 591\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[0;32m    592\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[0;32m    593\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[0;32m    594\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[0;32m    595\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[0;32m    596\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[0;32m    597\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    598\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    599\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[0;32m    600\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    603\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[0;32m    604\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32md:\\Software\\anaconda3\\envs\\IDSml_cnn_2\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:59\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     58\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 59\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[0;32m     60\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     62\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m:  OOM when allocating tensor with shape[8192,114,114] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node resnet/pool1_pad/Pad (defined at C:\\Users\\xht30\\AppData\\Local\\Temp\\ipykernel_51316\\1254716126.py:23) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n [Op:__inference_train_function_21151]\n\nFunction call stack:\ntrain_function\n"
     ]
    }
   ],
   "source": [
    "resnet(num_class=num_class,epochs=20)\t#binary classificaiton\n",
    "history_this.loss_plot('epoch')\n",
    "history_this.loss_plot('batch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validation accuracy of Resnet: 98.652%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.add('Resnet', train_time=timer.get_processing_time(), **history_this.get_best())\n",
    "history_this.generate_report('ResNet_original')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 6: Inception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def inception( num_class, epochs,savepath='./inception.h5',history=history_this,input_shape=INPUT_SIZE, timer=timer):\n",
    "    model_fine_tune = InceptionV3(include_top=False, weights='imagenet', input_shape=input_shape)\n",
    "    for layer in model_fine_tune.layers[:35]:\t#the number of frozen layers for transfer learning, have tuned from 50-150\n",
    "        layer.trainable = False\n",
    "    for layer in model_fine_tune.layers[35:]:\t#the number of trainable layers for transfer learning\n",
    "        layer.trainable = True\n",
    "    model = GlobalAveragePooling2D()(model_fine_tune.output)\n",
    "    model=Dense(units=256,activation='relu')(model)\n",
    "    model=Dropout(0.5)(model)\n",
    "    model = Dense(num_class, activation='softmax')(model)\n",
    "    model = Model(model_fine_tune.input, model, name='resnet')\n",
    "    opt = keras.optimizers.Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\t#tuned learning rate to be 0.001\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy']) #set the loss function to be binary crossentropy\n",
    "    #train model\n",
    "    earlyStopping = kcallbacks.EarlyStopping(\n",
    "        monitor='val_accuracy', patience=2, verbose=1, mode='auto')\t#set early stop patience to save training time\n",
    "    saveBestModel = kcallbacks.ModelCheckpoint(\n",
    "        filepath=savepath,\n",
    "        monitor='val_accuracy',\n",
    "        verbose=1,\n",
    "        save_best_only=True,\n",
    "        mode='auto')\n",
    "    hist = model.fit(\n",
    "        train_generator,\n",
    "        steps_per_epoch=len(train_generator),\n",
    "        epochs=epochs,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=len(validation_generator),\n",
    "        #use_multiprocessing=True, \n",
    "        callbacks=[history, timer, earlyStopping, saveBestModel],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "87916544/87910968 [==============================] - 17s 0us/step\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": " OOM when allocating tensor with shape[128,64,109,109] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node resnet/conv2d_13/Conv2D (defined at C:\\Users\\xht30\\AppData\\Local\\Temp\\ipykernel_51316\\885599727.py:23) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n [Op:__inference_train_function_36235]\n\nFunction call stack:\ntrain_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [23], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m inception(num_class\u001b[39m=\u001b[39;49mnum_class,epochs\u001b[39m=\u001b[39;49m\u001b[39m20\u001b[39;49m)\t\u001b[39m#binary classificaiton\u001b[39;00m\n\u001b[0;32m      2\u001b[0m history_this\u001b[39m.\u001b[39mloss_plot(\u001b[39m'\u001b[39m\u001b[39mepoch\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      3\u001b[0m history_this\u001b[39m.\u001b[39mloss_plot(\u001b[39m'\u001b[39m\u001b[39mbatch\u001b[39m\u001b[39m'\u001b[39m)\n",
      "Cell \u001b[1;32mIn [22], line 23\u001b[0m, in \u001b[0;36minception\u001b[1;34m(num_class, epochs, savepath, history, input_shape, timer)\u001b[0m\n\u001b[0;32m     15\u001b[0m earlyStopping \u001b[39m=\u001b[39m kcallbacks\u001b[39m.\u001b[39mEarlyStopping(\n\u001b[0;32m     16\u001b[0m     monitor\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mval_acc\u001b[39m\u001b[39m'\u001b[39m, patience\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m, verbose\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, mode\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mauto\u001b[39m\u001b[39m'\u001b[39m)\t\u001b[39m#set early stop patience to save training time\u001b[39;00m\n\u001b[0;32m     17\u001b[0m saveBestModel \u001b[39m=\u001b[39m kcallbacks\u001b[39m.\u001b[39mModelCheckpoint(\n\u001b[0;32m     18\u001b[0m     filepath\u001b[39m=\u001b[39msavepath,\n\u001b[0;32m     19\u001b[0m     monitor\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mval_acc\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m     20\u001b[0m     verbose\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[0;32m     21\u001b[0m     save_best_only\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[0;32m     22\u001b[0m     mode\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mauto\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m---> 23\u001b[0m hist \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit_generator(\n\u001b[0;32m     24\u001b[0m     train_generator,\n\u001b[0;32m     25\u001b[0m     steps_per_epoch\u001b[39m=\u001b[39;49m\u001b[39mlen\u001b[39;49m(train_generator),\n\u001b[0;32m     26\u001b[0m     epochs\u001b[39m=\u001b[39;49mepochs,\n\u001b[0;32m     27\u001b[0m     validation_data\u001b[39m=\u001b[39;49mvalidation_generator,\n\u001b[0;32m     28\u001b[0m     validation_steps\u001b[39m=\u001b[39;49m\u001b[39mlen\u001b[39;49m(validation_generator),\n\u001b[0;32m     29\u001b[0m     \u001b[39m#use_multiprocessing=True, \u001b[39;49;00m\n\u001b[0;32m     30\u001b[0m     callbacks\u001b[39m=\u001b[39;49m[history, timer, earlyStopping, saveBestModel],\n\u001b[0;32m     31\u001b[0m )\n",
      "File \u001b[1;32md:\\Software\\anaconda3\\envs\\IDSml_cnn_2\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1943\u001b[0m, in \u001b[0;36mModel.fit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   1934\u001b[0m \u001b[39m\"\"\"Fits the model on data yielded batch-by-batch by a Python generator.\u001b[39;00m\n\u001b[0;32m   1935\u001b[0m \n\u001b[0;32m   1936\u001b[0m \u001b[39mDEPRECATED:\u001b[39;00m\n\u001b[0;32m   1937\u001b[0m \u001b[39m  `Model.fit` now supports generators, so there is no longer any need to use\u001b[39;00m\n\u001b[0;32m   1938\u001b[0m \u001b[39m  this endpoint.\u001b[39;00m\n\u001b[0;32m   1939\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1940\u001b[0m warnings\u001b[39m.\u001b[39mwarn(\u001b[39m'\u001b[39m\u001b[39m`Model.fit_generator` is deprecated and \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m   1941\u001b[0m               \u001b[39m'\u001b[39m\u001b[39mwill be removed in a future version. \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m   1942\u001b[0m               \u001b[39m'\u001b[39m\u001b[39mPlease use `Model.fit`, which supports generators.\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m-> 1943\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfit(\n\u001b[0;32m   1944\u001b[0m     generator,\n\u001b[0;32m   1945\u001b[0m     steps_per_epoch\u001b[39m=\u001b[39;49msteps_per_epoch,\n\u001b[0;32m   1946\u001b[0m     epochs\u001b[39m=\u001b[39;49mepochs,\n\u001b[0;32m   1947\u001b[0m     verbose\u001b[39m=\u001b[39;49mverbose,\n\u001b[0;32m   1948\u001b[0m     callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[0;32m   1949\u001b[0m     validation_data\u001b[39m=\u001b[39;49mvalidation_data,\n\u001b[0;32m   1950\u001b[0m     validation_steps\u001b[39m=\u001b[39;49mvalidation_steps,\n\u001b[0;32m   1951\u001b[0m     validation_freq\u001b[39m=\u001b[39;49mvalidation_freq,\n\u001b[0;32m   1952\u001b[0m     class_weight\u001b[39m=\u001b[39;49mclass_weight,\n\u001b[0;32m   1953\u001b[0m     max_queue_size\u001b[39m=\u001b[39;49mmax_queue_size,\n\u001b[0;32m   1954\u001b[0m     workers\u001b[39m=\u001b[39;49mworkers,\n\u001b[0;32m   1955\u001b[0m     use_multiprocessing\u001b[39m=\u001b[39;49muse_multiprocessing,\n\u001b[0;32m   1956\u001b[0m     shuffle\u001b[39m=\u001b[39;49mshuffle,\n\u001b[0;32m   1957\u001b[0m     initial_epoch\u001b[39m=\u001b[39;49minitial_epoch)\n",
      "File \u001b[1;32md:\\Software\\anaconda3\\envs\\IDSml_cnn_2\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1183\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1176\u001b[0m \u001b[39mwith\u001b[39;00m trace\u001b[39m.\u001b[39mTrace(\n\u001b[0;32m   1177\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m   1178\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[0;32m   1179\u001b[0m     step_num\u001b[39m=\u001b[39mstep,\n\u001b[0;32m   1180\u001b[0m     batch_size\u001b[39m=\u001b[39mbatch_size,\n\u001b[0;32m   1181\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[0;32m   1182\u001b[0m   callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1183\u001b[0m   tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[0;32m   1184\u001b[0m   \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[0;32m   1185\u001b[0m     context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[1;32md:\\Software\\anaconda3\\envs\\IDSml_cnn_2\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:889\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    886\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    888\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 889\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[0;32m    891\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    892\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32md:\\Software\\anaconda3\\envs\\IDSml_cnn_2\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:950\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    946\u001b[0m     \u001b[39mpass\u001b[39;00m  \u001b[39m# Fall through to cond-based initialization.\u001b[39;00m\n\u001b[0;32m    947\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    948\u001b[0m     \u001b[39m# Lifting succeeded, so variables are initialized and we can run the\u001b[39;00m\n\u001b[0;32m    949\u001b[0m     \u001b[39m# stateless function.\u001b[39;00m\n\u001b[1;32m--> 950\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_stateless_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[0;32m    951\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    952\u001b[0m   _, _, _, filtered_flat_args \u001b[39m=\u001b[39m \\\n\u001b[0;32m    953\u001b[0m       \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn\u001b[39m.\u001b[39m_function_spec\u001b[39m.\u001b[39mcanonicalize_function_inputs(  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    954\u001b[0m           \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n",
      "File \u001b[1;32md:\\Software\\anaconda3\\envs\\IDSml_cnn_2\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3023\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3020\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m   3021\u001b[0m   (graph_function,\n\u001b[0;32m   3022\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 3023\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[0;32m   3024\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[1;32md:\\Software\\anaconda3\\envs\\IDSml_cnn_2\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1960\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1956\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1957\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1958\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1959\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1960\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[0;32m   1961\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[0;32m   1962\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1963\u001b[0m     args,\n\u001b[0;32m   1964\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1965\u001b[0m     executing_eagerly)\n\u001b[0;32m   1966\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[1;32md:\\Software\\anaconda3\\envs\\IDSml_cnn_2\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:591\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    589\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[0;32m    590\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 591\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[0;32m    592\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[0;32m    593\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[0;32m    594\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[0;32m    595\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[0;32m    596\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[0;32m    597\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    598\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    599\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[0;32m    600\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    603\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[0;32m    604\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32md:\\Software\\anaconda3\\envs\\IDSml_cnn_2\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:59\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     58\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 59\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[0;32m     60\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     62\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m:  OOM when allocating tensor with shape[128,64,109,109] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node resnet/conv2d_13/Conv2D (defined at C:\\Users\\xht30\\AppData\\Local\\Temp\\ipykernel_51316\\885599727.py:23) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n [Op:__inference_train_function_36235]\n\nFunction call stack:\ntrain_function\n"
     ]
    }
   ],
   "source": [
    "inception(num_class=num_class,epochs=20)\t#binary classificaiton\n",
    "history_this.loss_plot('epoch')\n",
    "history_this.loss_plot('batch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validation accuracy of Inception: 100.0%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.add('Inception', train_time=timer.get_processing_time(), **history_this.get_best())\n",
    "history_this.generate_report('Inception_original')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 7: InceptionResnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def inceptionresnet( num_class, epochs,savepath='./inceptionresnet.h5',history=history_this,input_shape=INPUT_SIZE, timer=timer):\n",
    "    model_fine_tune = InceptionResNetV2(include_top=False, weights='imagenet', input_shape=input_shape)\n",
    "    for layer in model_fine_tune.layers[:500]:\t#the number of frozen layers for transfer learning, have tuned from 400-550\n",
    "        layer.trainable = False\n",
    "    for layer in model_fine_tune.layers[500:]:\t#the number of trainable layers for transfer learning\n",
    "        layer.trainable = True\n",
    "    model = GlobalAveragePooling2D()(model_fine_tune.output)\n",
    "    model=Dense(units=256,activation='relu')(model)\n",
    "    model=Dropout(0.5)(model)\n",
    "    model = Dense(num_class, activation='softmax')(model)\n",
    "    model = Model(model_fine_tune.input, model, name='resnet')\n",
    "    opt = keras.optimizers.Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\t#tuned learning rate to be 0.001\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy']) #set the loss function to be binary crossentropy\n",
    "    #train model\n",
    "    earlyStopping = kcallbacks.EarlyStopping(\n",
    "        monitor='val_accuracy', patience=2, verbose=1, mode='auto')\t#set early stop patience to save training time\n",
    "    saveBestModel = kcallbacks.ModelCheckpoint(\n",
    "        filepath=savepath,\n",
    "        monitor='val_accuracy',\n",
    "        verbose=1,\n",
    "        save_best_only=True,\n",
    "        mode='auto')\n",
    "    hist = model.fit(\n",
    "        train_generator,\n",
    "        steps_per_epoch=len(train_generator),\n",
    "        epochs=epochs,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=len(validation_generator),\n",
    "        #use_multiprocessing=True, \n",
    "        callbacks=[history, timer, earlyStopping, saveBestModel],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_resnet_v2/inception_resnet_v2_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "219062272/219055592 [==============================] - 27s 0us/step\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": " OOM when allocating tensor with shape[128,32,111,111] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node resnet/batch_normalization_98/FusedBatchNormV3 (defined at C:\\Users\\xht30\\AppData\\Local\\Temp\\ipykernel_51316\\1805849801.py:23) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n [Op:__inference_train_function_68493]\n\nFunction call stack:\ntrain_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [25], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m inceptionresnet(num_class\u001b[39m=\u001b[39;49mnum_class,epochs\u001b[39m=\u001b[39;49m\u001b[39m20\u001b[39;49m)\t\u001b[39m# 5-class classificaiton\u001b[39;00m\n\u001b[0;32m      2\u001b[0m history_this\u001b[39m.\u001b[39mloss_plot(\u001b[39m'\u001b[39m\u001b[39mepoch\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      3\u001b[0m history_this\u001b[39m.\u001b[39mloss_plot(\u001b[39m'\u001b[39m\u001b[39mbatch\u001b[39m\u001b[39m'\u001b[39m)\n",
      "Cell \u001b[1;32mIn [24], line 23\u001b[0m, in \u001b[0;36minceptionresnet\u001b[1;34m(num_class, epochs, savepath, history, input_shape, timer)\u001b[0m\n\u001b[0;32m     15\u001b[0m earlyStopping \u001b[39m=\u001b[39m kcallbacks\u001b[39m.\u001b[39mEarlyStopping(\n\u001b[0;32m     16\u001b[0m     monitor\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mval_acc\u001b[39m\u001b[39m'\u001b[39m, patience\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m, verbose\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, mode\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mauto\u001b[39m\u001b[39m'\u001b[39m)\t\u001b[39m#set early stop patience to save training time\u001b[39;00m\n\u001b[0;32m     17\u001b[0m saveBestModel \u001b[39m=\u001b[39m kcallbacks\u001b[39m.\u001b[39mModelCheckpoint(\n\u001b[0;32m     18\u001b[0m     filepath\u001b[39m=\u001b[39msavepath,\n\u001b[0;32m     19\u001b[0m     monitor\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mval_acc\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m     20\u001b[0m     verbose\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[0;32m     21\u001b[0m     save_best_only\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[0;32m     22\u001b[0m     mode\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mauto\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m---> 23\u001b[0m hist \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit_generator(\n\u001b[0;32m     24\u001b[0m     train_generator,\n\u001b[0;32m     25\u001b[0m     steps_per_epoch\u001b[39m=\u001b[39;49m\u001b[39mlen\u001b[39;49m(train_generator),\n\u001b[0;32m     26\u001b[0m     epochs\u001b[39m=\u001b[39;49mepochs,\n\u001b[0;32m     27\u001b[0m     validation_data\u001b[39m=\u001b[39;49mvalidation_generator,\n\u001b[0;32m     28\u001b[0m     validation_steps\u001b[39m=\u001b[39;49m\u001b[39mlen\u001b[39;49m(validation_generator),\n\u001b[0;32m     29\u001b[0m     \u001b[39m#use_multiprocessing=True, \u001b[39;49;00m\n\u001b[0;32m     30\u001b[0m     callbacks\u001b[39m=\u001b[39;49m[history, timer, earlyStopping, saveBestModel],\n\u001b[0;32m     31\u001b[0m )\n",
      "File \u001b[1;32md:\\Software\\anaconda3\\envs\\IDSml_cnn_2\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1943\u001b[0m, in \u001b[0;36mModel.fit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   1934\u001b[0m \u001b[39m\"\"\"Fits the model on data yielded batch-by-batch by a Python generator.\u001b[39;00m\n\u001b[0;32m   1935\u001b[0m \n\u001b[0;32m   1936\u001b[0m \u001b[39mDEPRECATED:\u001b[39;00m\n\u001b[0;32m   1937\u001b[0m \u001b[39m  `Model.fit` now supports generators, so there is no longer any need to use\u001b[39;00m\n\u001b[0;32m   1938\u001b[0m \u001b[39m  this endpoint.\u001b[39;00m\n\u001b[0;32m   1939\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1940\u001b[0m warnings\u001b[39m.\u001b[39mwarn(\u001b[39m'\u001b[39m\u001b[39m`Model.fit_generator` is deprecated and \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m   1941\u001b[0m               \u001b[39m'\u001b[39m\u001b[39mwill be removed in a future version. \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m   1942\u001b[0m               \u001b[39m'\u001b[39m\u001b[39mPlease use `Model.fit`, which supports generators.\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m-> 1943\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfit(\n\u001b[0;32m   1944\u001b[0m     generator,\n\u001b[0;32m   1945\u001b[0m     steps_per_epoch\u001b[39m=\u001b[39;49msteps_per_epoch,\n\u001b[0;32m   1946\u001b[0m     epochs\u001b[39m=\u001b[39;49mepochs,\n\u001b[0;32m   1947\u001b[0m     verbose\u001b[39m=\u001b[39;49mverbose,\n\u001b[0;32m   1948\u001b[0m     callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[0;32m   1949\u001b[0m     validation_data\u001b[39m=\u001b[39;49mvalidation_data,\n\u001b[0;32m   1950\u001b[0m     validation_steps\u001b[39m=\u001b[39;49mvalidation_steps,\n\u001b[0;32m   1951\u001b[0m     validation_freq\u001b[39m=\u001b[39;49mvalidation_freq,\n\u001b[0;32m   1952\u001b[0m     class_weight\u001b[39m=\u001b[39;49mclass_weight,\n\u001b[0;32m   1953\u001b[0m     max_queue_size\u001b[39m=\u001b[39;49mmax_queue_size,\n\u001b[0;32m   1954\u001b[0m     workers\u001b[39m=\u001b[39;49mworkers,\n\u001b[0;32m   1955\u001b[0m     use_multiprocessing\u001b[39m=\u001b[39;49muse_multiprocessing,\n\u001b[0;32m   1956\u001b[0m     shuffle\u001b[39m=\u001b[39;49mshuffle,\n\u001b[0;32m   1957\u001b[0m     initial_epoch\u001b[39m=\u001b[39;49minitial_epoch)\n",
      "File \u001b[1;32md:\\Software\\anaconda3\\envs\\IDSml_cnn_2\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1183\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1176\u001b[0m \u001b[39mwith\u001b[39;00m trace\u001b[39m.\u001b[39mTrace(\n\u001b[0;32m   1177\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m   1178\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[0;32m   1179\u001b[0m     step_num\u001b[39m=\u001b[39mstep,\n\u001b[0;32m   1180\u001b[0m     batch_size\u001b[39m=\u001b[39mbatch_size,\n\u001b[0;32m   1181\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[0;32m   1182\u001b[0m   callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1183\u001b[0m   tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[0;32m   1184\u001b[0m   \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[0;32m   1185\u001b[0m     context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[1;32md:\\Software\\anaconda3\\envs\\IDSml_cnn_2\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:889\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    886\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    888\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 889\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[0;32m    891\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    892\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32md:\\Software\\anaconda3\\envs\\IDSml_cnn_2\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:950\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    946\u001b[0m     \u001b[39mpass\u001b[39;00m  \u001b[39m# Fall through to cond-based initialization.\u001b[39;00m\n\u001b[0;32m    947\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    948\u001b[0m     \u001b[39m# Lifting succeeded, so variables are initialized and we can run the\u001b[39;00m\n\u001b[0;32m    949\u001b[0m     \u001b[39m# stateless function.\u001b[39;00m\n\u001b[1;32m--> 950\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_stateless_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[0;32m    951\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    952\u001b[0m   _, _, _, filtered_flat_args \u001b[39m=\u001b[39m \\\n\u001b[0;32m    953\u001b[0m       \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn\u001b[39m.\u001b[39m_function_spec\u001b[39m.\u001b[39mcanonicalize_function_inputs(  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    954\u001b[0m           \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n",
      "File \u001b[1;32md:\\Software\\anaconda3\\envs\\IDSml_cnn_2\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3023\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3020\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m   3021\u001b[0m   (graph_function,\n\u001b[0;32m   3022\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 3023\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[0;32m   3024\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[1;32md:\\Software\\anaconda3\\envs\\IDSml_cnn_2\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1960\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1956\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1957\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1958\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1959\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1960\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[0;32m   1961\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[0;32m   1962\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1963\u001b[0m     args,\n\u001b[0;32m   1964\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1965\u001b[0m     executing_eagerly)\n\u001b[0;32m   1966\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[1;32md:\\Software\\anaconda3\\envs\\IDSml_cnn_2\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:591\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    589\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[0;32m    590\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 591\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[0;32m    592\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[0;32m    593\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[0;32m    594\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[0;32m    595\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[0;32m    596\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[0;32m    597\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    598\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    599\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[0;32m    600\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    603\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[0;32m    604\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32md:\\Software\\anaconda3\\envs\\IDSml_cnn_2\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:59\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     58\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 59\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[0;32m     60\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     62\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m:  OOM when allocating tensor with shape[128,32,111,111] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node resnet/batch_normalization_98/FusedBatchNormV3 (defined at C:\\Users\\xht30\\AppData\\Local\\Temp\\ipykernel_51316\\1805849801.py:23) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n [Op:__inference_train_function_68493]\n\nFunction call stack:\ntrain_function\n"
     ]
    }
   ],
   "source": [
    "inceptionresnet(num_class=num_class,epochs=20)\t# 5-class classificaiton\n",
    "history_this.loss_plot('epoch')\n",
    "history_this.loss_plot('batch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validation accuracy of InceptionResnet: 99.993%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.add('InceptionResnet', train_time=timer.get_processing_time(), **history_this.get_best())\n",
    "history_this.generate_report('InceptionResnet_original')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Optimization \n",
    "Use VGG16 as an example.  \n",
    "\n",
    "Tuned hyperparameters of CNN: \n",
    "1. The number of frozen layers\n",
    "2. The number of epochs\n",
    "3. Early stop patience\n",
    "4. Learning rate\n",
    "5. Dropout rate\n",
    "\n",
    "Hyperparameter optimization methods:\n",
    "1. Random search\n",
    "2. Bayesian optimization - Tree Parzen Estimator(BO-TPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def prediction(model, test_labels=test_labels, test_images=test_images, label=label):\n",
    "#read images from validation folder\n",
    "    # test_labels = []\n",
    "    # test_images=[]\n",
    "    # for subdir, dirs, files in os.walk(rootdir):\n",
    "    #     for file in files:\n",
    "    #         if not (file.endswith(\".jpeg\"))|(file.endswith(\".jpg\"))|(file.endswith(\".png\")):\n",
    "    #             continue\n",
    "    #         test_labels.append(subdir.split('/')[-1])\n",
    "    #         test_images.append(os.path.join(subdir, file))\n",
    "\n",
    "    # label=validation_generator.class_indices\n",
    "    # label={v: k for k, v in label.items()}\n",
    "    # predict=[]\n",
    "    # length=len(test_images)\n",
    "    # for i in range(length):\n",
    "    #     inputimg=test_images[i]\n",
    "    #     test_batch=[]\n",
    "    #     thisimg=np.array(Image.open(inputimg))/255 #read all the images in validation set\n",
    "    #     #print(thisimg)\n",
    "    #     test_shape=(1,)+thisimg.shape\n",
    "    #     thisimg=thisimg.reshape(test_shape)\n",
    "    #     model_batch=model.predict(thisimg) #use master model to process the input image\n",
    "    #     #generate result by model 1\n",
    "    #     prob=model_batch[0,np.argmax(model_batch,axis=1)[0]]\n",
    "    #     res=label[np.argmax(model_batch,axis=1)[0]]\n",
    "    #     predict.append(res)\n",
    "    acc=accuracy_score(test_labels, get_prediction(model=model, test_images=test_images, label=label))\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model by Own"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_by_own(num_class,input_shape=INPUT_SIZE,epochs=20,patience=2, dropout_rate=0.5,verbose=0,savepath='./model_own.h5',history=history_this,timer=timer):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(64,(3,3),strides=(1,1),input_shape=input_shape,padding='same',activation='relu',kernel_initializer='glorot_uniform'))\n",
    "    model.add(Conv2D(64,(3,3),strides=(1,1),padding='same',activation='relu',kernel_initializer='glorot_uniform'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Conv2D(128,(3,3),strides=(1,1),padding='same',activation='relu',kernel_initializer='glorot_uniform'))\n",
    "    model.add(Conv2D(128,(3,3),strides=(1,1),padding='same',activation='relu',kernel_initializer='glorot_uniform'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Conv2D(256,(3,3),strides=(1,1),padding='same',activation='relu',kernel_initializer='glorot_uniform'))\n",
    "    model.add(Conv2D(256,(3,3),strides=(1,1),padding='same',activation='relu',kernel_initializer='glorot_uniform'))\n",
    "    model.add(Conv2D(256,(3,3),strides=(1,1),padding='same',activation='relu',kernel_initializer='glorot_uniform'))\n",
    "    model.add(GlobalAveragePooling2D())\n",
    "    model.add(Dense(256,activation='relu'))\n",
    "    model.add(Dropout(rate=dropout_rate))\n",
    "    model.add(Dense(num_class,activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "    #train model\n",
    "    earlyStopping=kcallbacks.EarlyStopping(monitor='val_accuracy', patience=patience, verbose=verbose, mode='auto', restore_best_weights=True)\n",
    "    saveBestModel = kcallbacks.ModelCheckpoint(filepath=savepath, monitor='val_accuracy', verbose=verbose, save_best_only=True, mode='auto')\n",
    "    hist=model.fit(\n",
    "        train_generator,\n",
    "        steps_per_epoch=len(train_generator),\n",
    "        epochs=epochs,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=len(validation_generator),\n",
    "        callbacks=[history, timer, earlyStopping, saveBestModel],\n",
    "        verbose=verbose\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the objective function to be optimized\n",
    "import time\n",
    "from hyperopt import hp, fmin, tpe, rand, STATUS_OK, Trials\n",
    "import matplotlib.pyplot as plt\n",
    "import statistics \n",
    "\n",
    "def objective(params, num_class=num_class, history=history_hpo):\n",
    "    \n",
    "    params = {\n",
    "        'epochs': int(params['epochs']),\n",
    "        'patience': int(params['patience']),\n",
    "        'dropout_rate': abs(float(params['dropout_rate'])),\n",
    "    }\n",
    "    # frozen=params['frozen']\n",
    "    # epochs=params['epochs']\n",
    "    # patience=params['patience']\n",
    "    # learning_rate=params['learning_rate']\n",
    "    # dropout_rate=params['dropout_rate']\n",
    "\n",
    "    # vgg16(num_class=num_class, frozen=frozen,epochs=epochs,patience=patience, learning_rate=learning_rate, dropout_rate=dropout_rate)\n",
    "\n",
    "    model = cnn_by_own(num_class=num_class, history=history, **params)\n",
    "\n",
    "    acc=prediction(model=model)\n",
    "\n",
    "    print('accuracy:%s'%acc)\n",
    "    return {'loss': -acc, 'status': STATUS_OK }\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BO-TPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyperparameter optimization by Bayesian optimization - Tree Parzen Estimator\n",
    "space = {\n",
    "    'epochs': hp.quniform('epochs', 5, 21, 5),\n",
    "    'patience': hp.quniform('patience', 2, 4, 1),\n",
    "    'dropout_rate': hp.quniform('dropout_rate', 0.3, 0.6, 0.1),\n",
    "}\n",
    "\n",
    "t1=time.time()\n",
    "best = fmin(fn=objective,\n",
    "            space=space,\n",
    "            algo=tpe.suggest,\n",
    "            max_evals=10)\n",
    "print(\"Hyperopt estimated optimum {}\".format(best))\n",
    "t2=time.time()\n",
    "print(\"Time: \"+str(t2-t1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrain the model by using the best hyperparameter values to obtain the best model\n",
    "params = {\n",
    "        'epochs': int(best['epochs']),\n",
    "        'patience': int(best['patience']),\n",
    "        'dropout_rate': abs(float(best['dropout_rate'])),\n",
    "    }\n",
    "cnn_by_own(input_shape=INPUT_SIZE, num_class=num_class, verbose=1, **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.add('model_own (BO-TPE)', hpo_time=t2-t1, train_time=timer.get_processing_time(), **history_this.get_best())\n",
    "history_this.generate_report('model_own_BO-TPE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyperparameter optimization by Random search\n",
    "space = {\n",
    "    'epochs': hp.quniform('epochs', 5, 21, 5),\n",
    "    'patience': hp.quniform('patience', 2, 4, 1),\n",
    "    'dropout_rate': hp.quniform('dropout_rate', 0.3, 0.6, 0.1),\n",
    "}\n",
    "\n",
    "t1=time.time()\n",
    "best = fmin(fn=objective,\n",
    "            space=space,\n",
    "            algo=rand.suggest,\n",
    "            max_evals=10)\n",
    "print(\"Hyperopt estimated optimum {}\".format(best))\n",
    "t2=time.time()\n",
    "print(\"Time: \"+str(t2-t1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrain the model by using the best hyperparameter values to obtain the best model\n",
    "params = {\n",
    "        'epochs': int(best['epochs']),\n",
    "        'patience': int(best['patience']),\n",
    "        'dropout_rate': abs(float(best['dropout_rate'])),\n",
    "    }\n",
    "cnn_by_own(input_shape=INPUT_SIZE, num_class=num_class, verbose=1, **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.add('model_own (Random Search)', hpo_time=t2-t1, train_time=timer.get_processing_time(), **history_this.get_best())\n",
    "history_this.generate_report('model_own_Random_Search')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Xception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xception( num_class,epochs=20,frozen=15,learning_rate=0.001,patience=2, dropout_rate=0.5,verbose=0,savepath='./xception.h5',history=history_this,input_shape=INPUT_SIZE,timer=timer):\n",
    "    model_fine_tune = Xception(include_top=False, weights='imagenet', input_shape=input_shape)\n",
    "    for layer in model_fine_tune.layers[:frozen]:\t\t#could be tuned to be 50, 100, or 131\n",
    "        layer.trainable = False\n",
    "    for layer in model_fine_tune.layers[frozen:]:\n",
    "        layer.trainable = True\n",
    "    model = GlobalAveragePooling2D()(model_fine_tune.output)\n",
    "    model=Dense(units=256,activation='relu')(model)\n",
    "    model=Dropout(dropout_rate)(model)\n",
    "    model = Dense(num_class, activation='softmax')(model)\n",
    "    model = Model(model_fine_tune.input, model, name='xception')\n",
    "    opt = keras.optimizers.Adam(learning_rate=learning_rate, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "    #train model\n",
    "    earlyStopping = kcallbacks.EarlyStopping(\n",
    "        monitor='val_accuracy', patience=patience, verbose=verbose, mode='auto', restore_best_weights=True)\t#patience could be tuned by 2 and 3\n",
    "    saveBestModel = kcallbacks.ModelCheckpoint(\n",
    "        filepath=savepath,\n",
    "        monitor='val_accuracy',\n",
    "        verbose=verbose,\n",
    "        save_best_only=True,\n",
    "        mode='auto')\n",
    "    hist = model.fit(\n",
    "        train_generator,\n",
    "        steps_per_epoch=len(train_generator),\n",
    "        epochs=epochs,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=len(validation_generator),\n",
    "        #use_multiprocessing=True, \n",
    "        verbose=verbose,\n",
    "        callbacks=[history, timer, earlyStopping, saveBestModel],\n",
    "    )\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the objective function to be optimized\n",
    "import time\n",
    "from hyperopt import hp, fmin, tpe, rand, STATUS_OK, Trials\n",
    "import matplotlib.pyplot as plt\n",
    "import statistics \n",
    "\n",
    "def objective(params, num_class=num_class, history=history_hpo):\n",
    "    \n",
    "    params = {\n",
    "        'frozen': int(params['frozen']),\n",
    "        'epochs': int(params['epochs']),\n",
    "        'patience': int(params['patience']),\n",
    "        'learning_rate': abs(float(params['learning_rate'])),\n",
    "        'dropout_rate': abs(float(params['dropout_rate'])),\n",
    "    }\n",
    "    # frozen=params['frozen']\n",
    "    # epochs=params['epochs']\n",
    "    # patience=params['patience']\n",
    "    # learning_rate=params['learning_rate']\n",
    "    # dropout_rate=params['dropout_rate']\n",
    "\n",
    "    # vgg16(num_class=num_class, frozen=frozen,epochs=epochs,patience=patience, learning_rate=learning_rate, dropout_rate=dropout_rate)\n",
    "\n",
    "    model = xception(num_class=num_class, history=history, **params)\n",
    "\n",
    "    acc=prediction(model=model)\n",
    "\n",
    "    print('accuracy:%s'%acc)\n",
    "    return {'loss': -acc, 'status': STATUS_OK }\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BO-TPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyperparameter optimization by Bayesian optimization - Tree Parzen Estimator\n",
    "available_frozen = [50, 100, 131]\n",
    "space = {\n",
    "    'frozen': hp.choice('frozen', available_frozen),\n",
    "    'epochs': hp.quniform('epochs', 5, 21, 5),\n",
    "    'patience': hp.quniform('patience', 2, 4, 1),\n",
    "    'learning_rate': hp.quniform('learning_rate', 0.001, 0.006, 0.001),\n",
    "    'dropout_rate': hp.quniform('dropout_rate', 0.3, 0.6, 0.1),\n",
    "}\n",
    "\n",
    "t1=time.time()\n",
    "best = fmin(fn=objective,\n",
    "            space=space,\n",
    "            algo=tpe.suggest,\n",
    "            max_evals=10)\n",
    "print(\"Hyperopt estimated optimum {}\".format(best))\n",
    "t2=time.time()\n",
    "print(\"Time: \"+str(t2-t1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrain the model by using the best hyperparameter values to obtain the best model\n",
    "params = {\n",
    "        'frozen': available_frozen[int(best['frozen'])],\n",
    "        'epochs': int(best['epochs']),\n",
    "        'patience': int(best['patience']),\n",
    "        'learning_rate': abs(float(best['learning_rate'])),\n",
    "        'dropout_rate': abs(float(best['dropout_rate'])),\n",
    "    }\n",
    "xception(num_class=num_class, verbose=1, **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.add('Xception (BO-TPE)', hpo_time=t2-t1, train_time=timer.get_processing_time(), **history_this.get_best())\n",
    "history_this.generate_report('Xception_BO-TPE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyperparameter optimization by Random search\n",
    "available_frozen = [50, 100, 131]\n",
    "space = {\n",
    "    'frozen': hp.choice('frozen', available_frozen),\n",
    "    'epochs': hp.quniform('epochs', 5, 21, 5),\n",
    "    'patience': hp.quniform('patience', 2, 4, 1),\n",
    "    'learning_rate': hp.quniform('learning_rate', 0.001, 0.006, 0.001),\n",
    "    'dropout_rate': hp.quniform('dropout_rate', 0.3, 0.6, 0.1),\n",
    "}\n",
    "\n",
    "t1=time.time()\n",
    "best = fmin(fn=objective,\n",
    "            space=space,\n",
    "            algo=rand.suggest,\n",
    "            max_evals=10)\n",
    "print(\"Hyperopt estimated optimum {}\".format(best))\n",
    "t2=time.time()\n",
    "print(\"Time: \"+str(t2-t1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrain the model by using the best hyperparameter values to obtain the best model\n",
    "params = {\n",
    "        'frozen': available_frozen[int(best['frozen'])],\n",
    "        'epochs': int(best['epochs']),\n",
    "        'patience': int(best['patience']),\n",
    "        'learning_rate': abs(float(best['learning_rate'])),\n",
    "        'dropout_rate': abs(float(best['dropout_rate'])),\n",
    "    }\n",
    "xception(num_class=num_class, verbose=1, **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.add('Xception (Random Search)', hpo_time=t2-t1, train_time=timer.get_processing_time(), **history_this.get_best())\n",
    "history_this.generate_report('Xception_Random_Search')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def vgg16(num_class,epochs=20,frozen=15,learning_rate=0.001,patience=2, dropout_rate=0.5,verbose=0, savepath='./VGG16.h5',history=history_this,timer=timer,input_shape=INPUT_SIZE):\n",
    "    model_fine_tune = VGG16(include_top=False, weights='imagenet', input_shape=input_shape)\n",
    "    for layer in model_fine_tune.layers[:frozen]:\t#the number of frozen layers for transfer learning, have tuned from 5-18\n",
    "        layer.trainable = False\n",
    "    for layer in model_fine_tune.layers[frozen:]:\n",
    "        layer.trainable = True\n",
    "    model = GlobalAveragePooling2D()(model_fine_tune.output)\n",
    "    model=Dense(units=256,activation='relu')(model)\n",
    "    model=Dropout(dropout_rate)(model)\n",
    "    model = Dense(num_class, activation='softmax')(model)\n",
    "    model = Model(model_fine_tune.input, model, name='vgg')\n",
    "    opt = keras.optimizers.Adam(learning_rate=learning_rate, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\t#tuned learning rate to be 0.001\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\t#set the loss function to be binary crossentropy\n",
    "    #train model\n",
    "    earlyStopping = kcallbacks.EarlyStopping(\n",
    "        monitor='val_accuracy', patience=patience, verbose=verbose, mode='auto', restore_best_weights=True)\t#set early stop patience to save training time\n",
    "    saveBestModel = kcallbacks.ModelCheckpoint(\n",
    "        filepath=savepath,\n",
    "        monitor='val_accuracy',\n",
    "        verbose=verbose,\n",
    "        save_best_only=True,\n",
    "        mode='auto')\n",
    "    hist = model.fit(\n",
    "        train_generator,\n",
    "        steps_per_epoch=len(train_generator),\n",
    "        epochs=epochs,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=len(validation_generator),\n",
    "        #use_multiprocessing=True, \n",
    "        #workers=2,\n",
    "        callbacks=[history, timer, earlyStopping, saveBestModel],\n",
    "        verbose = verbose\n",
    "    )\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "#define the objective function to be optimized\n",
    "import time\n",
    "from hyperopt import hp, fmin, tpe, rand, STATUS_OK, Trials\n",
    "import matplotlib.pyplot as plt\n",
    "import statistics \n",
    "\n",
    "def objective(params, num_class=num_class, history=history_hpo):\n",
    "    \n",
    "    params = {\n",
    "        'frozen': int(params['frozen']),\n",
    "        'epochs': int(params['epochs']),\n",
    "        'patience': int(params['patience']),\n",
    "        'learning_rate': abs(float(params['learning_rate'])),\n",
    "        'dropout_rate': abs(float(params['dropout_rate'])),\n",
    "    }\n",
    "    # frozen=params['frozen']\n",
    "    # epochs=params['epochs']\n",
    "    # patience=params['patience']\n",
    "    # learning_rate=params['learning_rate']\n",
    "    # dropout_rate=params['dropout_rate']\n",
    "\n",
    "    # vgg16(num_class=num_class, frozen=frozen,epochs=epochs,patience=patience, learning_rate=learning_rate, dropout_rate=dropout_rate)\n",
    "\n",
    "    model = vgg16(num_class=num_class, history=history, **params)\n",
    "\n",
    "    acc=prediction(model=model)\n",
    "\n",
    "    print('accuracy:%s'%acc)\n",
    "    return {'loss': -acc, 'status': STATUS_OK }\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BO-TPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?trial/s, best loss=?]WARNING:tensorflow:Large dropout rate: 0.6 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Large dropout rate: 0.6 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Large dropout rate: 0.6 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Large dropout rate: 0.6 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:0.9842406876790831                           \n",
      "accuracy:0.9598853868194842                                                         \n",
      "accuracy:0.9756446991404012                                                         \n",
      "accuracy:0.9713467048710601                                                       \n",
      " 40%|████      | 4/10 [20:47<29:57, 299.59s/trial, best loss: -0.9842406876790831]WARNING:tensorflow:Large dropout rate: 0.6 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Large dropout rate: 0.6 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Large dropout rate: 0.6 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Large dropout rate: 0.6 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:0.9684813753581661                                                       \n",
      "accuracy:0.9570200573065902                                                       \n",
      " 60%|██████    | 6/10 [31:07<20:06, 301.50s/trial, best loss: -0.9842406876790831]WARNING:tensorflow:Large dropout rate: 0.6 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Large dropout rate: 0.6 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:0.9749283667621776                                                       \n",
      "accuracy:0.9777936962750716                                                       \n",
      "accuracy:0.9799426934097422                                                       \n",
      "accuracy:0.9634670487106017                                                       \n",
      "100%|██████████| 10/10 [51:03<00:00, 306.39s/trial, best loss: -0.9842406876790831]\n",
      "Hyperopt estimated optimum {'dropout_rate': 0.6000000000000001, 'epochs': 15.0, 'frozen': 16.0, 'lr': 0.002, 'patience': 3.0}\n",
      "Time: 3063.9442534446716\n"
     ]
    }
   ],
   "source": [
    "#Hyperparameter optimization by Bayesian optimization - Tree Parzen Estimator\n",
    "space = {\n",
    "    'frozen': hp.quniform('frozen', 15, 18, 1),\n",
    "    'epochs': hp.quniform('epochs', 5, 21, 5),\n",
    "    'patience': hp.quniform('patience', 2, 4, 1),\n",
    "    'learning_rate': hp.quniform('learning_rate', 0.001, 0.006, 0.001),\n",
    "    'dropout_rate': hp.quniform('dropout_rate', 0.3, 0.6, 0.1),\n",
    "}\n",
    "\n",
    "t1=time.time()\n",
    "best = fmin(fn=objective,\n",
    "            space=space,\n",
    "            algo=tpe.suggest,\n",
    "            max_evals=10)\n",
    "print(\"Hyperopt estimated optimum {}\".format(best))\n",
    "t2=time.time()\n",
    "print(\"Time: \"+str(t2-t1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "43/44 [============================>.] - ETA: 0s - loss: 0.8648 - acc: 0.8201Epoch 1/15\n",
      "11/44 [======>.......................] - ETA: 20s - loss: 0.2106 - acc: 0.9384\n",
      "Epoch 00001: val_acc improved from -inf to 0.93840, saving model to ./VGG16.h5\n",
      "44/44 [==============================] - 36s 825ms/step - loss: 0.8529 - acc: 0.8219 - val_loss: 0.2106 - val_acc: 0.9384\n",
      "Epoch 2/15\n",
      "43/44 [============================>.] - ETA: 0s - loss: 0.1812 - acc: 0.9374Epoch 1/15\n",
      "11/44 [======>.......................] - ETA: 19s - loss: 0.1864 - acc: 0.9384\n",
      "Epoch 00002: val_acc did not improve from 0.93840\n",
      "44/44 [==============================] - 26s 601ms/step - loss: 0.1814 - acc: 0.9370 - val_loss: 0.1864 - val_acc: 0.9384\n",
      "Epoch 3/15\n",
      "43/44 [============================>.] - ETA: 0s - loss: 0.1543 - acc: 0.9474Epoch 1/15\n",
      "11/44 [======>.......................] - ETA: 21s - loss: 0.1434 - acc: 0.9477\n",
      "Epoch 00003: val_acc improved from 0.93840 to 0.94771, saving model to ./VGG16.h5\n",
      "44/44 [==============================] - 28s 631ms/step - loss: 0.1554 - acc: 0.9472 - val_loss: 0.1434 - val_acc: 0.9477\n",
      "Epoch 4/15\n",
      "43/44 [============================>.] - ETA: 0s - loss: 0.1378 - acc: 0.9498Epoch 1/15\n",
      "11/44 [======>.......................] - ETA: 21s - loss: 0.1229 - acc: 0.9506\n",
      "Epoch 00004: val_acc improved from 0.94771 to 0.95057, saving model to ./VGG16.h5\n",
      "44/44 [==============================] - 28s 629ms/step - loss: 0.1387 - acc: 0.9497 - val_loss: 0.1229 - val_acc: 0.9506\n",
      "Epoch 5/15\n",
      "43/44 [============================>.] - ETA: 0s - loss: 0.1316 - acc: 0.9520Epoch 1/15\n",
      "11/44 [======>.......................] - ETA: 19s - loss: 0.1185 - acc: 0.9556\n",
      "Epoch 00005: val_acc improved from 0.95057 to 0.95559, saving model to ./VGG16.h5\n",
      "44/44 [==============================] - 27s 612ms/step - loss: 0.1330 - acc: 0.9519 - val_loss: 0.1185 - val_acc: 0.9556\n",
      "Epoch 6/15\n",
      "43/44 [============================>.] - ETA: 0s - loss: 0.1272 - acc: 0.9562Epoch 1/15\n",
      "11/44 [======>.......................] - ETA: 20s - loss: 0.1329 - acc: 0.9542\n",
      "Epoch 00006: val_acc did not improve from 0.95559\n",
      "44/44 [==============================] - 27s 604ms/step - loss: 0.1288 - acc: 0.9554 - val_loss: 0.1329 - val_acc: 0.9542\n",
      "Epoch 7/15\n",
      "43/44 [============================>.] - ETA: 0s - loss: 0.1224 - acc: 0.9590Epoch 1/15\n",
      "11/44 [======>.......................] - ETA: 19s - loss: 0.1121 - acc: 0.9592\n",
      "Epoch 00007: val_acc improved from 0.95559 to 0.95917, saving model to ./VGG16.h5\n",
      "44/44 [==============================] - 27s 607ms/step - loss: 0.1214 - acc: 0.9594 - val_loss: 0.1121 - val_acc: 0.9592\n",
      "Epoch 8/15\n",
      "43/44 [============================>.] - ETA: 0s - loss: 0.1118 - acc: 0.9595Epoch 1/15\n",
      "11/44 [======>.......................] - ETA: 19s - loss: 0.1060 - acc: 0.9570\n",
      "Epoch 00008: val_acc did not improve from 0.95917\n",
      "44/44 [==============================] - 27s 603ms/step - loss: 0.1126 - acc: 0.9594 - val_loss: 0.1060 - val_acc: 0.9570\n",
      "Epoch 9/15\n",
      "43/44 [============================>.] - ETA: 0s - loss: 0.1098 - acc: 0.9592Epoch 1/15\n",
      "11/44 [======>.......................] - ETA: 19s - loss: 0.1077 - acc: 0.9635\n",
      "Epoch 00009: val_acc improved from 0.95917 to 0.96347, saving model to ./VGG16.h5\n",
      "44/44 [==============================] - 27s 615ms/step - loss: 0.1083 - acc: 0.9597 - val_loss: 0.1077 - val_acc: 0.9635\n",
      "Epoch 10/15\n",
      "43/44 [============================>.] - ETA: 0s - loss: 0.1038 - acc: 0.9630Epoch 1/15\n",
      "11/44 [======>.......................] - ETA: 19s - loss: 0.0936 - acc: 0.9663\n",
      "Epoch 00010: val_acc improved from 0.96347 to 0.96633, saving model to ./VGG16.h5\n",
      "44/44 [==============================] - 27s 605ms/step - loss: 0.1032 - acc: 0.9631 - val_loss: 0.0936 - val_acc: 0.9663\n",
      "Epoch 11/15\n",
      "43/44 [============================>.] - ETA: 0s - loss: 0.1018 - acc: 0.9654Epoch 1/15\n",
      "11/44 [======>.......................] - ETA: 19s - loss: 0.0882 - acc: 0.9656\n",
      "Epoch 00011: val_acc did not improve from 0.96633\n",
      "44/44 [==============================] - 27s 608ms/step - loss: 0.1011 - acc: 0.9656 - val_loss: 0.0882 - val_acc: 0.9656\n",
      "Epoch 12/15\n",
      "43/44 [============================>.] - ETA: 0s - loss: 0.0915 - acc: 0.9689Epoch 1/15\n",
      "11/44 [======>.......................] - ETA: 19s - loss: 0.0780 - acc: 0.9721\n",
      "Epoch 00012: val_acc improved from 0.96633 to 0.97206, saving model to ./VGG16.h5\n",
      "44/44 [==============================] - 27s 610ms/step - loss: 0.0917 - acc: 0.9689 - val_loss: 0.0780 - val_acc: 0.9721\n",
      "Epoch 13/15\n",
      "43/44 [============================>.] - ETA: 0s - loss: 0.0960 - acc: 0.9672Epoch 1/15\n",
      "11/44 [======>.......................] - ETA: 19s - loss: 0.0799 - acc: 0.9699\n",
      "Epoch 00013: val_acc did not improve from 0.97206\n",
      "44/44 [==============================] - 27s 608ms/step - loss: 0.0959 - acc: 0.9673 - val_loss: 0.0799 - val_acc: 0.9699\n",
      "Epoch 14/15\n",
      "43/44 [============================>.] - ETA: 0s - loss: 0.0746 - acc: 0.9723Epoch 1/15\n",
      "11/44 [======>.......................] - ETA: 19s - loss: 0.0605 - acc: 0.9742\n",
      "Epoch 00014: val_acc improved from 0.97206 to 0.97421, saving model to ./VGG16.h5\n",
      "44/44 [==============================] - 27s 611ms/step - loss: 0.0742 - acc: 0.9726 - val_loss: 0.0605 - val_acc: 0.9742\n",
      "Epoch 15/15\n",
      "43/44 [============================>.] - ETA: 0s - loss: 0.0741 - acc: 0.9709Epoch 1/15\n",
      "11/44 [======>.......................] - ETA: 20s - loss: 0.0607 - acc: 0.9814\n",
      "Epoch 00015: val_acc improved from 0.97421 to 0.98138, saving model to ./VGG16.h5\n",
      "44/44 [==============================] - 27s 616ms/step - loss: 0.0734 - acc: 0.9712 - val_loss: 0.0607 - val_acc: 0.9814\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fa04a616bb0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retrain the model by using the best hyperparameter values to obtain the best model\n",
    "params = {\n",
    "        'frozen': int(best['frozen']),\n",
    "        'epochs': int(best['epochs']),\n",
    "        'patience': int(best['patience']),\n",
    "        'learning_rate': abs(float(best['learning_rate'])),\n",
    "        'dropout_rate': abs(float(best['dropout_rate'])),\n",
    "    }\n",
    "vgg16(num_class=num_class, verbose=1, **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.add('VGG16 (BO-TPE)', hpo_time=t2-t1, train_time=timer.get_processing_time(), **history_this.get_best())\n",
    "history_this.generate_report('VGG16_BO-TPE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:0.9684813753581661                           \n",
      "accuracy:0.9684813753581661                                                       \n",
      "accuracy:0.9756446991404012                                                       \n",
      "accuracy:0.9670487106017192                                                       \n",
      "accuracy:0.9806590257879656                                                       \n",
      "accuracy:0.9813753581661891                                                       \n",
      "accuracy:0.9820916905444126                                                       \n",
      "accuracy:0.9792263610315186                                                       \n",
      "accuracy:0.9584527220630372                                                       \n",
      "accuracy:0.9777936962750716                                                       \n",
      "100%|██████████| 10/10 [54:06<00:00, 324.61s/trial, best loss: -0.9820916905444126]\n",
      "Hyperopt estimated optimum {'dropout_rate': 0.4, 'epochs': 15.0, 'frozen': 18.0, 'lr': 0.004, 'patience': 4.0}\n",
      "Time: 3246.0730514526367\n"
     ]
    }
   ],
   "source": [
    "#Hyperparameter optimization by Random search\n",
    "space = {\n",
    "    'frozen': hp.quniform('frozen', 15, 18, 1),\n",
    "    'epochs': hp.quniform('epochs', 5, 21, 5),\n",
    "    'patience': hp.quniform('patience', 2, 4, 1),\n",
    "    'learning_rate': hp.quniform('learning_rate', 0.001, 0.006, 0.001),\n",
    "    'dropout_rate': hp.quniform('dropout_rate', 0.3, 0.6, 0.1),\n",
    "}\n",
    "\n",
    "t1=time.time()\n",
    "best = fmin(fn=objective,\n",
    "            space=space,\n",
    "            algo=rand.suggest,\n",
    "            max_evals=10)\n",
    "print(\"Hyperopt estimated optimum {}\".format(best))\n",
    "t2=time.time()\n",
    "print(\"Time: \"+str(t2-t1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "43/44 [============================>.] - ETA: 0s - loss: 0.6046 - acc: 0.8401Epoch 1/15\n",
      "11/44 [======>.......................] - ETA: 19s - loss: 0.2843 - acc: 0.9463\n",
      "Epoch 00001: val_acc improved from -inf to 0.94628, saving model to ./VGG16.h5\n",
      "44/44 [==============================] - 41s 924ms/step - loss: 0.5985 - acc: 0.8416 - val_loss: 0.2843 - val_acc: 0.9463\n",
      "Epoch 2/15\n",
      "43/44 [============================>.] - ETA: 0s - loss: 0.2380 - acc: 0.9412Epoch 1/15\n",
      "11/44 [======>.......................] - ETA: 19s - loss: 0.1756 - acc: 0.9542\n",
      "Epoch 00002: val_acc improved from 0.94628 to 0.95415, saving model to ./VGG16.h5\n",
      "44/44 [==============================] - 27s 613ms/step - loss: 0.2357 - acc: 0.9418 - val_loss: 0.1756 - val_acc: 0.9542\n",
      "Epoch 3/15\n",
      "43/44 [============================>.] - ETA: 0s - loss: 0.1641 - acc: 0.9590Epoch 1/15\n",
      "11/44 [======>.......................] - ETA: 19s - loss: 0.1313 - acc: 0.9620\n",
      "Epoch 00003: val_acc improved from 0.95415 to 0.96203, saving model to ./VGG16.h5\n",
      "44/44 [==============================] - 27s 609ms/step - loss: 0.1636 - acc: 0.9588 - val_loss: 0.1313 - val_acc: 0.9620\n",
      "Epoch 4/15\n",
      "43/44 [============================>.] - ETA: 0s - loss: 0.1363 - acc: 0.9625Epoch 1/15\n",
      "11/44 [======>.......................] - ETA: 19s - loss: 0.1156 - acc: 0.9642\n",
      "Epoch 00004: val_acc improved from 0.96203 to 0.96418, saving model to ./VGG16.h5\n",
      "44/44 [==============================] - 27s 610ms/step - loss: 0.1356 - acc: 0.9626 - val_loss: 0.1156 - val_acc: 0.9642\n",
      "Epoch 5/15\n",
      "43/44 [============================>.] - ETA: 0s - loss: 0.1144 - acc: 0.9643Epoch 1/15\n",
      "11/44 [======>.......................] - ETA: 20s - loss: 0.0976 - acc: 0.9685\n",
      "Epoch 00005: val_acc improved from 0.96418 to 0.96848, saving model to ./VGG16.h5\n",
      "44/44 [==============================] - 27s 617ms/step - loss: 0.1145 - acc: 0.9644 - val_loss: 0.0976 - val_acc: 0.9685\n",
      "Epoch 6/15\n",
      "43/44 [============================>.] - ETA: 0s - loss: 0.1091 - acc: 0.9667Epoch 1/15\n",
      "11/44 [======>.......................] - ETA: 19s - loss: 0.0992 - acc: 0.9699\n",
      "Epoch 00006: val_acc improved from 0.96848 to 0.96991, saving model to ./VGG16.h5\n",
      "44/44 [==============================] - 27s 606ms/step - loss: 0.1106 - acc: 0.9658 - val_loss: 0.0992 - val_acc: 0.9699\n",
      "Epoch 7/15\n",
      "43/44 [============================>.] - ETA: 0s - loss: 0.0987 - acc: 0.9698Epoch 1/15\n",
      "11/44 [======>.......................] - ETA: 20s - loss: 0.0852 - acc: 0.9699\n",
      "Epoch 00007: val_acc did not improve from 0.96991\n",
      "44/44 [==============================] - 27s 616ms/step - loss: 0.0999 - acc: 0.9694 - val_loss: 0.0852 - val_acc: 0.9699\n",
      "Epoch 8/15\n",
      "43/44 [============================>.] - ETA: 0s - loss: 0.0955 - acc: 0.9685Epoch 1/15\n",
      "11/44 [======>.......................] - ETA: 20s - loss: 0.0798 - acc: 0.9721\n",
      "Epoch 00008: val_acc improved from 0.96991 to 0.97206, saving model to ./VGG16.h5\n",
      "44/44 [==============================] - 28s 627ms/step - loss: 0.0948 - acc: 0.9690 - val_loss: 0.0798 - val_acc: 0.9721\n",
      "Epoch 9/15\n",
      "43/44 [============================>.] - ETA: 0s - loss: 0.0872 - acc: 0.9706Epoch 1/15\n",
      "11/44 [======>.......................] - ETA: 20s - loss: 0.0792 - acc: 0.9699\n",
      "Epoch 00009: val_acc did not improve from 0.97206\n",
      "44/44 [==============================] - 27s 616ms/step - loss: 0.0874 - acc: 0.9705 - val_loss: 0.0792 - val_acc: 0.9699\n",
      "Epoch 10/15\n",
      "43/44 [============================>.] - ETA: 0s - loss: 0.0822 - acc: 0.9720Epoch 1/15\n",
      "11/44 [======>.......................] - ETA: 20s - loss: 0.0718 - acc: 0.9764\n",
      "Epoch 00010: val_acc improved from 0.97206 to 0.97636, saving model to ./VGG16.h5\n",
      "44/44 [==============================] - 27s 625ms/step - loss: 0.0831 - acc: 0.9715 - val_loss: 0.0718 - val_acc: 0.9764\n",
      "Epoch 11/15\n",
      "43/44 [============================>.] - ETA: 0s - loss: 0.0783 - acc: 0.9745Epoch 1/15\n",
      "11/44 [======>.......................] - ETA: 20s - loss: 0.0692 - acc: 0.9778\n",
      "Epoch 00011: val_acc improved from 0.97636 to 0.97779, saving model to ./VGG16.h5\n",
      "44/44 [==============================] - 28s 629ms/step - loss: 0.0791 - acc: 0.9742 - val_loss: 0.0692 - val_acc: 0.9778\n",
      "Epoch 12/15\n",
      "43/44 [============================>.] - ETA: 0s - loss: 0.0707 - acc: 0.9762Epoch 1/15\n",
      "11/44 [======>.......................] - ETA: 20s - loss: 0.0656 - acc: 0.9792\n",
      "Epoch 00012: val_acc improved from 0.97779 to 0.97923, saving model to ./VGG16.h5\n",
      "44/44 [==============================] - 28s 630ms/step - loss: 0.0707 - acc: 0.9762 - val_loss: 0.0656 - val_acc: 0.9792\n",
      "Epoch 13/15\n",
      "43/44 [============================>.] - ETA: 0s - loss: 0.0663 - acc: 0.9766Epoch 1/15\n",
      "11/44 [======>.......................] - ETA: 20s - loss: 0.0631 - acc: 0.9792\n",
      "Epoch 00013: val_acc did not improve from 0.97923\n",
      "44/44 [==============================] - 27s 617ms/step - loss: 0.0665 - acc: 0.9766 - val_loss: 0.0631 - val_acc: 0.9792\n",
      "Epoch 14/15\n",
      "43/44 [============================>.] - ETA: 0s - loss: 0.0689 - acc: 0.9780Epoch 1/15\n",
      "11/44 [======>.......................] - ETA: 20s - loss: 0.0671 - acc: 0.9792\n",
      "Epoch 00014: val_acc did not improve from 0.97923\n",
      "44/44 [==============================] - 27s 620ms/step - loss: 0.0688 - acc: 0.9778 - val_loss: 0.0671 - val_acc: 0.9792\n",
      "Epoch 15/15\n",
      "43/44 [============================>.] - ETA: 0s - loss: 0.0645 - acc: 0.9802Epoch 1/15\n",
      "11/44 [======>.......................] - ETA: 20s - loss: 0.0610 - acc: 0.9764\n",
      "Epoch 00015: val_acc did not improve from 0.97923\n",
      "44/44 [==============================] - 27s 620ms/step - loss: 0.0654 - acc: 0.9796 - val_loss: 0.0610 - val_acc: 0.9764\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fa03ddc2100>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retrain the model by using the best hyperparameter values to obtain the best model\n",
    "params = {\n",
    "        'frozen': int(best['frozen']),\n",
    "        'epochs': int(best['epochs']),\n",
    "        'patience': int(best['patience']),\n",
    "        'learning_rate': abs(float(best['learning_rate'])),\n",
    "        'dropout_rate': abs(float(best['dropout_rate'])),\n",
    "    }\n",
    "vgg16(num_class=num_class, verbose=1, **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.add('VGG16 (Random Search)', hpo_time=t2-t1, train_time=timer.get_processing_time(), **history_this.get_best())\n",
    "history_this.generate_report('VGG16_Random_Search')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VGG19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vgg19( num_class,epochs=20,frozen=15,learning_rate=0.001,patience=2, dropout_rate=0.5,verbose=0,savepath='./VGG19.h5',history=history_this,input_shape=INPUT_SIZE,timer=timer):\n",
    "    model_fine_tune = VGG19(include_top=False, weights='imagenet', input_shape=input_shape)\n",
    "    for layer in model_fine_tune.layers[:frozen]:\t#the number of frozen layers for transfer learning, have tuned from 5-18\n",
    "        layer.trainable = False\n",
    "    for layer in model_fine_tune.layers[frozen:]:\n",
    "        layer.trainable = True\n",
    "    model = GlobalAveragePooling2D()(model_fine_tune.output)\n",
    "    model=Dense(units=256,activation='relu')(model)\n",
    "    model=Dropout(dropout_rate)(model)\n",
    "    model = Dense(num_class, activation='softmax')(model)\n",
    "    model = Model(model_fine_tune.input, model, name='vgg')\n",
    "    opt = keras.optimizers.Adam(learning_rate=learning_rate, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\t#tuned learning rate to be 0.001\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\t#set the loss function to be binary crossentropy\n",
    "    #train model\n",
    "    earlyStopping = kcallbacks.EarlyStopping(\n",
    "        monitor='val_accuracy', patience=patience, verbose=verbose, mode='auto', restore_best_weights=True)\t#set early stop patience to save training time\n",
    "    saveBestModel = kcallbacks.ModelCheckpoint(\n",
    "        filepath=savepath,\n",
    "        monitor='val_accuracy',\n",
    "        verbose=verbose,\n",
    "        save_best_only=True,\n",
    "        mode='auto')\n",
    "    hist = model.fit(\n",
    "        train_generator,\n",
    "        steps_per_epoch=len(train_generator),\n",
    "        epochs=epochs,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=len(validation_generator),\n",
    "        verbose=verbose,\n",
    "        #use_multiprocessing=True, \n",
    "        #workers=2,\n",
    "        callbacks=[history, timer, earlyStopping, saveBestModel],\n",
    "    )\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the objective function to be optimized\n",
    "import time\n",
    "from hyperopt import hp, fmin, tpe, rand, STATUS_OK, Trials\n",
    "import matplotlib.pyplot as plt\n",
    "import statistics \n",
    "\n",
    "def objective(params, num_class=num_class, history=history_hpo):\n",
    "    \n",
    "    params = {\n",
    "        'frozen': int(params['frozen']),\n",
    "        'epochs': int(params['epochs']),\n",
    "        'patience': int(params['patience']),\n",
    "        'learning_rate': abs(float(params['learning_rate'])),\n",
    "        'dropout_rate': abs(float(params['dropout_rate'])),\n",
    "    }\n",
    "    # frozen=params['frozen']\n",
    "    # epochs=params['epochs']\n",
    "    # patience=params['patience']\n",
    "    # learning_rate=params['learning_rate']\n",
    "    # dropout_rate=params['dropout_rate']\n",
    "\n",
    "    # vgg16(num_class=num_class, frozen=frozen,epochs=epochs,patience=patience, learning_rate=learning_rate, dropout_rate=dropout_rate)\n",
    "\n",
    "    model = vgg19(num_class=num_class, history=history, **params)\n",
    "\n",
    "    acc=prediction(model=model)\n",
    "\n",
    "    print('accuracy:%s'%acc)\n",
    "    return {'loss': -acc, 'status': STATUS_OK }\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BO-TPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyperparameter optimization by Bayesian optimization - Tree Parzen Estimator\n",
    "space = {\n",
    "    'frozen': hp.quniform('frozen', 15, 18, 1),\n",
    "    'epochs': hp.quniform('epochs', 5, 21, 5),\n",
    "    'patience': hp.quniform('patience', 2, 4, 1),\n",
    "    'learning_rate': hp.quniform('learning_rate', 0.001, 0.006, 0.001),\n",
    "    'dropout_rate': hp.quniform('dropout_rate', 0.3, 0.6, 0.1),\n",
    "}\n",
    "\n",
    "t1=time.time()\n",
    "best = fmin(fn=objective,\n",
    "            space=space,\n",
    "            algo=tpe.suggest,\n",
    "            max_evals=10)\n",
    "print(\"Hyperopt estimated optimum {}\".format(best))\n",
    "t2=time.time()\n",
    "print(\"Time: \"+str(t2-t1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrain the model by using the best hyperparameter values to obtain the best model\n",
    "params = {\n",
    "        'frozen': int(best['frozen']),\n",
    "        'epochs': int(best['epochs']),\n",
    "        'patience': int(best['patience']),\n",
    "        'learning_rate': abs(float(best['learning_rate'])),\n",
    "        'dropout_rate': abs(float(best['dropout_rate'])),\n",
    "    }\n",
    "vgg19(num_class=num_class, verbose=1, **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.add('VGG19 (BO-TPE)', hpo_time=t2-t1, train_time=timer.get_processing_time(), **history_this.get_best())\n",
    "history_this.generate_report('VGG19_BO-TPE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyperparameter optimization by Random search\n",
    "space = {\n",
    "    'frozen': hp.quniform('frozen', 15, 18, 1),\n",
    "    'epochs': hp.quniform('epochs', 5, 21, 5),\n",
    "    'patience': hp.quniform('patience', 2, 4, 1),\n",
    "    'learning_rate': hp.quniform('learning_rate', 0.001, 0.006, 0.001),\n",
    "    'dropout_rate': hp.quniform('dropout_rate', 0.3, 0.6, 0.1),\n",
    "}\n",
    "\n",
    "t1=time.time()\n",
    "best = fmin(fn=objective,\n",
    "            space=space,\n",
    "            algo=rand.suggest,\n",
    "            max_evals=10)\n",
    "print(\"Hyperopt estimated optimum {}\".format(best))\n",
    "t2=time.time()\n",
    "print(\"Time: \"+str(t2-t1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrain the model by using the best hyperparameter values to obtain the best model\n",
    "params = {\n",
    "        'frozen': int(best['frozen']),\n",
    "        'epochs': int(best['epochs']),\n",
    "        'patience': int(best['patience']),\n",
    "        'learning_rate': abs(float(best['learning_rate'])),\n",
    "        'dropout_rate': abs(float(best['dropout_rate'])),\n",
    "    }\n",
    "vgg19(num_class=num_class, verbose=1, **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.add('VGG19 (Random Search)', hpo_time=t2-t1, train_time=timer.get_processing_time(), **history_this.get_best())\n",
    "history_this.generate_report('VGG19_Random_Search')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resnet( num_class, epochs=20,frozen=120,learning_rate=0.001,patience=2, dropout_rate=0.5,verbose=0,savepath='./resnet.h5',history=history_this,input_shape=INPUT_SIZE,timer=timer):\n",
    "    model_fine_tune = ResNet50(include_top=False, weights='imagenet', input_shape=input_shape)\n",
    "    for layer in model_fine_tune.layers[:frozen]:\t#the number of frozen layers for transfer learning, have tuned from 50-150\n",
    "        layer.trainable = False\n",
    "    for layer in model_fine_tune.layers[frozen:]:\t#the number of trainable layers for transfer learning\n",
    "        layer.trainable = True\n",
    "    model = GlobalAveragePooling2D()(model_fine_tune.output)\n",
    "    model=Dense(units=256,activation='relu')(model)\n",
    "    model=Dropout(dropout_rate)(model)\n",
    "    model = Dense(num_class, activation='softmax')(model)\n",
    "    model = Model(model_fine_tune.input, model, name='resnet')\n",
    "    opt = keras.optimizers.Adam(learning_rate=learning_rate, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\t#tuned learning rate to be 0.001\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy']) #set the loss function to be binary crossentropy\n",
    "    #train model\n",
    "    earlyStopping = kcallbacks.EarlyStopping(\n",
    "        monitor='val_accuracy', patience=patience, verbose=verbose, mode='auto', restore_best_weights=True)\t#set early stop patience to save training time\n",
    "    saveBestModel = kcallbacks.ModelCheckpoint(\n",
    "        filepath=savepath,\n",
    "        monitor='val_accuracy',\n",
    "        verbose=verbose,\n",
    "        save_best_only=True,\n",
    "        mode='auto')\n",
    "    hist = model.fit(\n",
    "        train_generator,\n",
    "        steps_per_epoch=len(train_generator),\n",
    "        epochs=epochs,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=len(validation_generator),\n",
    "        #use_multiprocessing=True, \n",
    "        verbose=verbose,\n",
    "        callbacks=[history, timer, earlyStopping, saveBestModel],\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the objective function to be optimized\n",
    "import time\n",
    "from hyperopt import hp, fmin, tpe, rand, STATUS_OK, Trials\n",
    "import matplotlib.pyplot as plt\n",
    "import statistics \n",
    "\n",
    "def objective(params, num_class=num_class, history=history_hpo):\n",
    "    \n",
    "    params = {\n",
    "        'frozen': int(params['frozen']),\n",
    "        'epochs': int(params['epochs']),\n",
    "        'patience': int(params['patience']),\n",
    "        'learning_rate': abs(float(params['learning_rate'])),\n",
    "        'dropout_rate': abs(float(params['dropout_rate'])),\n",
    "    }\n",
    "    # frozen=params['frozen']\n",
    "    # epochs=params['epochs']\n",
    "    # patience=params['patience']\n",
    "    # learning_rate=params['learning_rate']\n",
    "    # dropout_rate=params['dropout_rate']\n",
    "\n",
    "    # vgg16(num_class=num_class, frozen=frozen,epochs=epochs,patience=patience, learning_rate=learning_rate, dropout_rate=dropout_rate)\n",
    "\n",
    "    model = resnet(num_class=num_class, history=history, **params)\n",
    "\n",
    "    acc=prediction(model=model)\n",
    "\n",
    "    print('accuracy:%s'%acc)\n",
    "    return {'loss': -acc, 'status': STATUS_OK }\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BO-TPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyperparameter optimization by Bayesian optimization - Tree Parzen Estimator\n",
    "space = {\n",
    "    'frozen': hp.quniform('frozen', 50, 150, 10),\n",
    "    'epochs': hp.quniform('epochs', 5, 21, 5),\n",
    "    'patience': hp.quniform('patience', 2, 4, 1),\n",
    "    'learning_rate': hp.quniform('learning_rate', 0.001, 0.006, 0.001),\n",
    "    'dropout_rate': hp.quniform('dropout_rate', 0.3, 0.6, 0.1),\n",
    "}\n",
    "\n",
    "t1=time.time()\n",
    "best = fmin(fn=objective,\n",
    "            space=space,\n",
    "            algo=tpe.suggest,\n",
    "            max_evals=10)\n",
    "print(\"Hyperopt estimated optimum {}\".format(best))\n",
    "t2=time.time()\n",
    "print(\"Time: \"+str(t2-t1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrain the model by using the best hyperparameter values to obtain the best model\n",
    "params = {\n",
    "        'frozen': int(best['frozen']),\n",
    "        'epochs': int(best['epochs']),\n",
    "        'patience': int(best['patience']),\n",
    "        'learning_rate': abs(float(best['learning_rate'])),\n",
    "        'dropout_rate': abs(float(best['dropout_rate'])),\n",
    "    }\n",
    "resnet(num_class=num_class, verbose=1, **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.add('ResNet (BO-TPE)', hpo_time=t2-t1, train_time=timer.get_processing_time(), **history_this.get_best())\n",
    "history_this.generate_report('ResNet_BO-TPE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyperparameter optimization by Random search\n",
    "space = {\n",
    "    'frozen': hp.quniform('frozen', 50, 150, 10),\n",
    "    'epochs': hp.quniform('epochs', 5, 21, 5),\n",
    "    'patience': hp.quniform('patience', 2, 4, 1),\n",
    "    'learning_rate': hp.quniform('learning_rate', 0.001, 0.006, 0.001),\n",
    "    'dropout_rate': hp.quniform('dropout_rate', 0.3, 0.6, 0.1),\n",
    "}\n",
    "\n",
    "t1=time.time()\n",
    "best = fmin(fn=objective,\n",
    "            space=space,\n",
    "            algo=rand.suggest,\n",
    "            max_evals=10)\n",
    "print(\"Hyperopt estimated optimum {}\".format(best))\n",
    "t2=time.time()\n",
    "print(\"Time: \"+str(t2-t1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrain the model by using the best hyperparameter values to obtain the best model\n",
    "params = {\n",
    "        'frozen': int(best['frozen']),\n",
    "        'epochs': int(best['epochs']),\n",
    "        'patience': int(best['patience']),\n",
    "        'learning_rate': abs(float(best['learning_rate'])),\n",
    "        'dropout_rate': abs(float(best['dropout_rate'])),\n",
    "    }\n",
    "resnet(num_class=num_class, verbose=1, **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.add('ResNet (Random Search)', hpo_time=t2-t1, train_time=timer.get_processing_time(), **history_this.get_best())\n",
    "history_this.generate_report('ResNet_Random_Search')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inception( num_class, epochs=20,frozen=120,learning_rate=0.001,patience=2, dropout_rate=0.5,verbose=0,savepath='./inception.h5',history=history_this,input_shape=INPUT_SIZE, timer=timer):\n",
    "    model_fine_tune = InceptionV3(include_top=False, weights='imagenet', input_shape=input_shape)\n",
    "    for layer in model_fine_tune.layers[:frozen]:\t#the number of frozen layers for transfer learning, have tuned from 50-150\n",
    "        layer.trainable = False\n",
    "    for layer in model_fine_tune.layers[frozen:]:\t#the number of trainable layers for transfer learning\n",
    "        layer.trainable = True\n",
    "    model = GlobalAveragePooling2D()(model_fine_tune.output)\n",
    "    model=Dense(units=256,activation='relu')(model)\n",
    "    model=Dropout(dropout_rate)(model)\n",
    "    model = Dense(num_class, activation='softmax')(model)\n",
    "    model = Model(model_fine_tune.input, model, name='resnet')\n",
    "    opt = keras.optimizers.Adam(learning_rate=learning_rate, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\t#tuned learning rate to be 0.001\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy']) #set the loss function to be binary crossentropy\n",
    "    #train model\n",
    "    earlyStopping = kcallbacks.EarlyStopping(\n",
    "        monitor='val_accuracy', patience=patience, verbose=verbose, mode='auto', restore_best_weights=True)\t#set early stop patience to save training time\n",
    "    saveBestModel = kcallbacks.ModelCheckpoint(\n",
    "        filepath=savepath,\n",
    "        monitor='val_accuracy',\n",
    "        verbose=verbose,\n",
    "        save_best_only=True,\n",
    "        mode='auto')\n",
    "    hist = model.fit(\n",
    "        train_generator,\n",
    "        steps_per_epoch=len(train_generator),\n",
    "        epochs=epochs,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=len(validation_generator),\n",
    "        #use_multiprocessing=True, \n",
    "        verbose=verbose,\n",
    "        callbacks=[history, timer, earlyStopping, saveBestModel],\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the objective function to be optimized\n",
    "import time\n",
    "from hyperopt import hp, fmin, tpe, rand, STATUS_OK, Trials\n",
    "import matplotlib.pyplot as plt\n",
    "import statistics \n",
    "\n",
    "def objective(params, num_class=num_class, history=history_hpo):\n",
    "    \n",
    "    params = {\n",
    "        'frozen': int(params['frozen']),\n",
    "        'epochs': int(params['epochs']),\n",
    "        'patience': int(params['patience']),\n",
    "        'learning_rate': abs(float(params['learning_rate'])),\n",
    "        'dropout_rate': abs(float(params['dropout_rate'])),\n",
    "    }\n",
    "    # frozen=params['frozen']\n",
    "    # epochs=params['epochs']\n",
    "    # patience=params['patience']\n",
    "    # learning_rate=params['learning_rate']\n",
    "    # dropout_rate=params['dropout_rate']\n",
    "\n",
    "    # vgg16(num_class=num_class, frozen=frozen,epochs=epochs,patience=patience, learning_rate=learning_rate, dropout_rate=dropout_rate)\n",
    "\n",
    "    model = inception(num_class=num_class, history=history, **params)\n",
    "\n",
    "    acc=prediction(model=model)\n",
    "\n",
    "    print('accuracy:%s'%acc)\n",
    "    return {'loss': -acc, 'status': STATUS_OK }\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BO-TPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyperparameter optimization by Bayesian optimization - Tree Parzen Estimator\n",
    "space = {\n",
    "    'frozen': hp.quniform('frozen', 50, 150, 10),\n",
    "    'epochs': hp.quniform('epochs', 5, 21, 5),\n",
    "    'patience': hp.quniform('patience', 2, 4, 1),\n",
    "    'learning_rate': hp.quniform('learning_rate', 0.001, 0.006, 0.001),\n",
    "    'dropout_rate': hp.quniform('dropout_rate', 0.3, 0.6, 0.1),\n",
    "}\n",
    "\n",
    "t1=time.time()\n",
    "best = fmin(fn=objective,\n",
    "            space=space,\n",
    "            algo=tpe.suggest,\n",
    "            max_evals=10)\n",
    "print(\"Hyperopt estimated optimum {}\".format(best))\n",
    "t2=time.time()\n",
    "print(\"Time: \"+str(t2-t1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrain the model by using the best hyperparameter values to obtain the best model\n",
    "params = {\n",
    "        'frozen': int(best['frozen']),\n",
    "        'epochs': int(best['epochs']),\n",
    "        'patience': int(best['patience']),\n",
    "        'learning_rate': abs(float(best['learning_rate'])),\n",
    "        'dropout_rate': abs(float(best['dropout_rate'])),\n",
    "    }\n",
    "inception(num_class=num_class, verbose=1, **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.add('Inception (BO-TPE)', hpo_time=t2-t1, train_time=timer.get_processing_time(), **history_this.get_best())\n",
    "history_this.generate_report('Inception_BO-TPE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyperparameter optimization by Random search\n",
    "space = {\n",
    "    'frozen': hp.quniform('frozen', 50, 150, 10),\n",
    "    'epochs': hp.quniform('epochs', 5, 21, 5),\n",
    "    'patience': hp.quniform('patience', 2, 4, 1),\n",
    "    'learning_rate': hp.quniform('learning_rate', 0.001, 0.006, 0.001),\n",
    "    'dropout_rate': hp.quniform('dropout_rate', 0.3, 0.6, 0.1),\n",
    "}\n",
    "\n",
    "t1=time.time()\n",
    "best = fmin(fn=objective,\n",
    "            space=space,\n",
    "            algo=rand.suggest,\n",
    "            max_evals=10)\n",
    "print(\"Hyperopt estimated optimum {}\".format(best))\n",
    "t2=time.time()\n",
    "print(\"Time: \"+str(t2-t1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrain the model by using the best hyperparameter values to obtain the best model\n",
    "params = {\n",
    "        'frozen': int(best['frozen']),\n",
    "        'epochs': int(best['epochs']),\n",
    "        'patience': int(best['patience']),\n",
    "        'learning_rate': abs(float(best['learning_rate'])),\n",
    "        'dropout_rate': abs(float(best['dropout_rate'])),\n",
    "    }\n",
    "inception(num_class=num_class, verbose=1, **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.add('Inception (Random Search)', hpo_time=t2-t1, train_time=timer.get_processing_time(), **history_this.get_best())\n",
    "history_this.generate_report('Inception_Random_Search')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## InceptionResnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inceptionresnet( num_class, epochs=20,frozen=120,learning_rate=0.001,patience=2, dropout_rate=0.5,verbose=0,savepath='./inceptionresnet.h5',history=history_this,input_shape=INPUT_SIZE, timer=timer):\n",
    "    model_fine_tune = InceptionResNetV2(include_top=False, weights='imagenet', input_shape=input_shape)\n",
    "    for layer in model_fine_tune.layers[:frozen]:\t#the number of frozen layers for transfer learning, have tuned from 400-550\n",
    "        layer.trainable = False\n",
    "    for layer in model_fine_tune.layers[frozen:]:\t#the number of trainable layers for transfer learning\n",
    "        layer.trainable = True\n",
    "    model = GlobalAveragePooling2D()(model_fine_tune.output)\n",
    "    model=Dense(units=256,activation='relu')(model)\n",
    "    model=Dropout(dropout_rate)(model)\n",
    "    model = Dense(num_class, activation='softmax')(model)\n",
    "    model = Model(model_fine_tune.input, model, name='resnet')\n",
    "    opt = keras.optimizers.Adam(learning_rate=learning_rate, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\t#tuned learning rate to be 0.001\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy']) #set the loss function to be binary crossentropy\n",
    "    #train model\n",
    "    earlyStopping = kcallbacks.EarlyStopping(\n",
    "        monitor='val_accuracy', patience=patience, verbose=verbose, mode='auto', restore_best_weights=True)\t#set early stop patience to save training time\n",
    "    saveBestModel = kcallbacks.ModelCheckpoint(\n",
    "        filepath=savepath,\n",
    "        monitor='val_accuracy',\n",
    "        verbose=verbose,\n",
    "        save_best_only=True,\n",
    "        mode='auto')\n",
    "    hist = model.fit(\n",
    "        train_generator,\n",
    "        steps_per_epoch=len(train_generator),\n",
    "        epochs=epochs,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=len(validation_generator),\n",
    "        #use_multiprocessing=True, \n",
    "        verbose=verbose,\n",
    "        callbacks=[history, timer, earlyStopping, saveBestModel],\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the objective function to be optimized\n",
    "import time\n",
    "from hyperopt import hp, fmin, tpe, rand, STATUS_OK, Trials\n",
    "import matplotlib.pyplot as plt\n",
    "import statistics \n",
    "\n",
    "def objective(params, num_class=num_class, history=history_hpo):\n",
    "    \n",
    "    params = {\n",
    "        'frozen': int(params['frozen']),\n",
    "        'epochs': int(params['epochs']),\n",
    "        'patience': int(params['patience']),\n",
    "        'learning_rate': abs(float(params['learning_rate'])),\n",
    "        'dropout_rate': abs(float(params['dropout_rate'])),\n",
    "    }\n",
    "    # frozen=params['frozen']\n",
    "    # epochs=params['epochs']\n",
    "    # patience=params['patience']\n",
    "    # learning_rate=params['learning_rate']\n",
    "    # dropout_rate=params['dropout_rate']\n",
    "\n",
    "    # vgg16(num_class=num_class, frozen=frozen,epochs=epochs,patience=patience, learning_rate=learning_rate, dropout_rate=dropout_rate)\n",
    "\n",
    "    model = inceptionresnet(num_class=num_class, history=history, **params)\n",
    "\n",
    "    acc=prediction(model=model)\n",
    "\n",
    "    print('accuracy:%s'%acc)\n",
    "    return {'loss': -acc, 'status': STATUS_OK }\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BO-TPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyperparameter optimization by Bayesian optimization - Tree Parzen Estimator\n",
    "space = {\n",
    "    'frozen': hp.quniform('frozen', 400, 500, 10),\n",
    "    'epochs': hp.quniform('epochs', 5, 21, 5),\n",
    "    'patience': hp.quniform('patience', 2, 4, 1),\n",
    "    'learning_rate': hp.quniform('learning_rate', 0.001, 0.006, 0.001),\n",
    "    'dropout_rate': hp.quniform('dropout_rate', 0.3, 0.6, 0.1),\n",
    "}\n",
    "\n",
    "t1=time.time()\n",
    "best = fmin(fn=objective,\n",
    "            space=space,\n",
    "            algo=tpe.suggest,\n",
    "            max_evals=10)\n",
    "print(\"Hyperopt estimated optimum {}\".format(best))\n",
    "t2=time.time()\n",
    "print(\"Time: \"+str(t2-t1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrain the model by using the best hyperparameter values to obtain the best model\n",
    "params = {\n",
    "        'frozen': int(best['frozen']),\n",
    "        'epochs': int(best['epochs']),\n",
    "        'patience': int(best['patience']),\n",
    "        'learning_rate': abs(float(best['learning_rate'])),\n",
    "        'dropout_rate': abs(float(best['dropout_rate'])),\n",
    "    }\n",
    "inceptionresnet(num_class=num_class, verbose=1, **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.add('InceptionResnet (BO-TPE)', hpo_time=t2-t1, train_time=timer.get_processing_time(), **history_this.get_best())\n",
    "history_this.generate_report('InceptionResnet_BO-TPE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyperparameter optimization by Random search\n",
    "space = {\n",
    "    'frozen': hp.quniform('frozen', 400, 500, 10),\n",
    "    'epochs': hp.quniform('epochs', 5, 21, 5),\n",
    "    'patience': hp.quniform('patience', 2, 4, 1),\n",
    "    'learning_rate': hp.quniform('learning_rate', 0.001, 0.006, 0.001),\n",
    "    'dropout_rate': hp.quniform('dropout_rate', 0.3, 0.6, 0.1),\n",
    "}\n",
    "\n",
    "t1=time.time()\n",
    "best = fmin(fn=objective,\n",
    "            space=space,\n",
    "            algo=rand.suggest,\n",
    "            max_evals=10)\n",
    "print(\"Hyperopt estimated optimum {}\".format(best))\n",
    "t2=time.time()\n",
    "print(\"Time: \"+str(t2-t1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrain the model by using the best hyperparameter values to obtain the best model\n",
    "params = {\n",
    "        'frozen': int(best['frozen']),\n",
    "        'epochs': int(best['epochs']),\n",
    "        'patience': int(best['patience']),\n",
    "        'learning_rate': abs(float(best['learning_rate'])),\n",
    "        'dropout_rate': abs(float(best['dropout_rate'])),\n",
    "    }\n",
    "inceptionresnet(num_class=num_class, verbose=1, **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.add('InceptionResnet (Random Search)', hpo_time=t2-t1, train_time=timer.get_processing_time(), **history_this.get_best())\n",
    "history_this.generate_report('InceptionResnet_Random_Search')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.to_excel()\n",
    "log_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Online GPU renting platform specification\n",
    "# # WeChat Message\n",
    "# import requests\n",
    "# resp = requests.get(\n",
    "#     \"https://www.autodl.com/api/v1/wechat/message/push?token={token}&title={title}&name={name}&content={content}\".format(\n",
    "#         token=\"\",\n",
    "#         title=\"From AutoDL\",\n",
    "#         name=\"UNSW-NB15 CNN\",\n",
    "#         content=\"Training Complete\")\n",
    "# )\n",
    "# print(resp.content.decode())\n",
    "# # Shutdown\n",
    "# !shutdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "7433aad5856aa069d06b9f622f042b0ba1f51348e8d64f8739ef1543b182edd5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
